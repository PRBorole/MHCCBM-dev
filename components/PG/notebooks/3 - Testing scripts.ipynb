{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0949990",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import argparse\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from Bio import SeqIO\n",
    "import esm\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "\n",
    "from torchinfo import summary\n",
    "\n",
    "from sklearn.metrics import f1_score, roc_auc_score, roc_curve, auc, precision_recall_curve\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import wandb\n",
    "\n",
    "sys.path.append('./../../../src/')\n",
    "\n",
    "from utils import *\n",
    "from utils_torch import * \n",
    "from MHCCBM import *\n",
    "from PGPredictor_CNN import *\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07c3b779",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>peptide</th>\n",
       "      <th>hit</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>1270</th>\n",
       "      <th>1271</th>\n",
       "      <th>1272</th>\n",
       "      <th>1273</th>\n",
       "      <th>1274</th>\n",
       "      <th>1275</th>\n",
       "      <th>1276</th>\n",
       "      <th>1277</th>\n",
       "      <th>1278</th>\n",
       "      <th>1279</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ILRPKPDYF</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.533767</td>\n",
       "      <td>1.457934</td>\n",
       "      <td>1.779880</td>\n",
       "      <td>1.169885</td>\n",
       "      <td>-0.719667</td>\n",
       "      <td>1.368618</td>\n",
       "      <td>-0.419608</td>\n",
       "      <td>0.639073</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.299567</td>\n",
       "      <td>1.581104</td>\n",
       "      <td>-0.044787</td>\n",
       "      <td>0.533028</td>\n",
       "      <td>-0.205300</td>\n",
       "      <td>0.492291</td>\n",
       "      <td>-0.345337</td>\n",
       "      <td>-0.407906</td>\n",
       "      <td>0.564666</td>\n",
       "      <td>-0.563590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IYPPGFSYL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.680211</td>\n",
       "      <td>0.295262</td>\n",
       "      <td>1.714029</td>\n",
       "      <td>1.323705</td>\n",
       "      <td>-0.237892</td>\n",
       "      <td>1.272062</td>\n",
       "      <td>-0.181969</td>\n",
       "      <td>0.669378</td>\n",
       "      <td>...</td>\n",
       "      <td>0.072727</td>\n",
       "      <td>2.108028</td>\n",
       "      <td>0.541240</td>\n",
       "      <td>0.055342</td>\n",
       "      <td>-0.848335</td>\n",
       "      <td>0.260021</td>\n",
       "      <td>-0.807489</td>\n",
       "      <td>0.198852</td>\n",
       "      <td>0.629822</td>\n",
       "      <td>-0.655833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RYMPQNPCII</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.246705</td>\n",
       "      <td>0.606267</td>\n",
       "      <td>1.848789</td>\n",
       "      <td>1.179841</td>\n",
       "      <td>0.466007</td>\n",
       "      <td>-0.020620</td>\n",
       "      <td>-0.366055</td>\n",
       "      <td>0.944435</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.581674</td>\n",
       "      <td>1.101377</td>\n",
       "      <td>0.572914</td>\n",
       "      <td>0.947558</td>\n",
       "      <td>0.473713</td>\n",
       "      <td>-0.519548</td>\n",
       "      <td>-1.464290</td>\n",
       "      <td>0.026348</td>\n",
       "      <td>0.093463</td>\n",
       "      <td>0.058640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NYSVNGNCEW</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.919065</td>\n",
       "      <td>0.869667</td>\n",
       "      <td>0.985458</td>\n",
       "      <td>0.445299</td>\n",
       "      <td>0.271855</td>\n",
       "      <td>0.105966</td>\n",
       "      <td>0.492187</td>\n",
       "      <td>-0.248743</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.638702</td>\n",
       "      <td>-1.316010</td>\n",
       "      <td>0.213583</td>\n",
       "      <td>1.149094</td>\n",
       "      <td>0.373075</td>\n",
       "      <td>-0.711103</td>\n",
       "      <td>-0.847282</td>\n",
       "      <td>0.016607</td>\n",
       "      <td>1.334911</td>\n",
       "      <td>-0.414205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LFCDFGEEM</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.277201</td>\n",
       "      <td>2.439435</td>\n",
       "      <td>0.759459</td>\n",
       "      <td>0.604564</td>\n",
       "      <td>-1.739369</td>\n",
       "      <td>0.803881</td>\n",
       "      <td>0.101670</td>\n",
       "      <td>-0.449408</td>\n",
       "      <td>...</td>\n",
       "      <td>0.290795</td>\n",
       "      <td>1.325325</td>\n",
       "      <td>1.342853</td>\n",
       "      <td>1.117716</td>\n",
       "      <td>0.400609</td>\n",
       "      <td>0.980317</td>\n",
       "      <td>0.538834</td>\n",
       "      <td>0.267250</td>\n",
       "      <td>0.730641</td>\n",
       "      <td>-1.842685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297543</th>\n",
       "      <td>AIIHGQMAYI</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.204722</td>\n",
       "      <td>0.361943</td>\n",
       "      <td>0.376750</td>\n",
       "      <td>0.218967</td>\n",
       "      <td>0.053348</td>\n",
       "      <td>-0.406903</td>\n",
       "      <td>-1.334947</td>\n",
       "      <td>1.373394</td>\n",
       "      <td>...</td>\n",
       "      <td>0.680224</td>\n",
       "      <td>2.435557</td>\n",
       "      <td>0.793749</td>\n",
       "      <td>1.056151</td>\n",
       "      <td>-0.783031</td>\n",
       "      <td>-0.228265</td>\n",
       "      <td>-1.012242</td>\n",
       "      <td>0.847001</td>\n",
       "      <td>-0.322014</td>\n",
       "      <td>0.437284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297544</th>\n",
       "      <td>GLPEYLSKT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.987672</td>\n",
       "      <td>0.042746</td>\n",
       "      <td>0.537548</td>\n",
       "      <td>1.322701</td>\n",
       "      <td>-0.548914</td>\n",
       "      <td>-0.227333</td>\n",
       "      <td>0.410077</td>\n",
       "      <td>0.104871</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.025391</td>\n",
       "      <td>1.265950</td>\n",
       "      <td>-0.156332</td>\n",
       "      <td>0.253393</td>\n",
       "      <td>-1.491441</td>\n",
       "      <td>-0.875211</td>\n",
       "      <td>0.134408</td>\n",
       "      <td>-0.503012</td>\n",
       "      <td>0.850081</td>\n",
       "      <td>-0.875928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297545</th>\n",
       "      <td>RLYPELPSQL</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.939923</td>\n",
       "      <td>0.162232</td>\n",
       "      <td>0.693979</td>\n",
       "      <td>0.949450</td>\n",
       "      <td>-0.567565</td>\n",
       "      <td>0.443507</td>\n",
       "      <td>-0.485680</td>\n",
       "      <td>0.758387</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.276031</td>\n",
       "      <td>2.206114</td>\n",
       "      <td>0.142970</td>\n",
       "      <td>-0.075833</td>\n",
       "      <td>-1.424216</td>\n",
       "      <td>-0.885639</td>\n",
       "      <td>0.603988</td>\n",
       "      <td>-0.622470</td>\n",
       "      <td>0.679971</td>\n",
       "      <td>-1.805622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297546</th>\n",
       "      <td>HLAKLKEAV</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.050682</td>\n",
       "      <td>1.284589</td>\n",
       "      <td>-0.609613</td>\n",
       "      <td>0.696779</td>\n",
       "      <td>-0.943364</td>\n",
       "      <td>-0.633307</td>\n",
       "      <td>-0.708188</td>\n",
       "      <td>-0.545659</td>\n",
       "      <td>...</td>\n",
       "      <td>0.070686</td>\n",
       "      <td>1.785624</td>\n",
       "      <td>0.075044</td>\n",
       "      <td>1.157744</td>\n",
       "      <td>-1.672122</td>\n",
       "      <td>-0.336969</td>\n",
       "      <td>1.009572</td>\n",
       "      <td>-0.394122</td>\n",
       "      <td>0.312486</td>\n",
       "      <td>-0.375061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297547</th>\n",
       "      <td>RLIAWKGGA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.283276</td>\n",
       "      <td>1.179801</td>\n",
       "      <td>0.015649</td>\n",
       "      <td>0.356761</td>\n",
       "      <td>-1.306724</td>\n",
       "      <td>-0.941171</td>\n",
       "      <td>-0.398600</td>\n",
       "      <td>0.320063</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.470787</td>\n",
       "      <td>1.545029</td>\n",
       "      <td>-0.782975</td>\n",
       "      <td>0.188683</td>\n",
       "      <td>-1.970819</td>\n",
       "      <td>-0.350554</td>\n",
       "      <td>-0.278030</td>\n",
       "      <td>1.467628</td>\n",
       "      <td>0.849500</td>\n",
       "      <td>0.147296</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>297548 rows × 1282 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           peptide  hit         0         1         2         3         4  \\\n",
       "0        ILRPKPDYF  0.0  0.533767  1.457934  1.779880  1.169885 -0.719667   \n",
       "1        IYPPGFSYL  0.0  0.680211  0.295262  1.714029  1.323705 -0.237892   \n",
       "2       RYMPQNPCII  1.0  1.246705  0.606267  1.848789  1.179841  0.466007   \n",
       "3       NYSVNGNCEW  0.0  1.919065  0.869667  0.985458  0.445299  0.271855   \n",
       "4        LFCDFGEEM  0.0  1.277201  2.439435  0.759459  0.604564 -1.739369   \n",
       "...            ...  ...       ...       ...       ...       ...       ...   \n",
       "297543  AIIHGQMAYI  0.0 -0.204722  0.361943  0.376750  0.218967  0.053348   \n",
       "297544   GLPEYLSKT  0.0  0.987672  0.042746  0.537548  1.322701 -0.548914   \n",
       "297545  RLYPELPSQL  1.0  0.939923  0.162232  0.693979  0.949450 -0.567565   \n",
       "297546   HLAKLKEAV  0.0  1.050682  1.284589 -0.609613  0.696779 -0.943364   \n",
       "297547   RLIAWKGGA  0.0  0.283276  1.179801  0.015649  0.356761 -1.306724   \n",
       "\n",
       "               5         6         7  ...      1270      1271      1272  \\\n",
       "0       1.368618 -0.419608  0.639073  ... -0.299567  1.581104 -0.044787   \n",
       "1       1.272062 -0.181969  0.669378  ...  0.072727  2.108028  0.541240   \n",
       "2      -0.020620 -0.366055  0.944435  ... -0.581674  1.101377  0.572914   \n",
       "3       0.105966  0.492187 -0.248743  ... -0.638702 -1.316010  0.213583   \n",
       "4       0.803881  0.101670 -0.449408  ...  0.290795  1.325325  1.342853   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "297543 -0.406903 -1.334947  1.373394  ...  0.680224  2.435557  0.793749   \n",
       "297544 -0.227333  0.410077  0.104871  ... -0.025391  1.265950 -0.156332   \n",
       "297545  0.443507 -0.485680  0.758387  ... -0.276031  2.206114  0.142970   \n",
       "297546 -0.633307 -0.708188 -0.545659  ...  0.070686  1.785624  0.075044   \n",
       "297547 -0.941171 -0.398600  0.320063  ... -0.470787  1.545029 -0.782975   \n",
       "\n",
       "            1273      1274      1275      1276      1277      1278      1279  \n",
       "0       0.533028 -0.205300  0.492291 -0.345337 -0.407906  0.564666 -0.563590  \n",
       "1       0.055342 -0.848335  0.260021 -0.807489  0.198852  0.629822 -0.655833  \n",
       "2       0.947558  0.473713 -0.519548 -1.464290  0.026348  0.093463  0.058640  \n",
       "3       1.149094  0.373075 -0.711103 -0.847282  0.016607  1.334911 -0.414205  \n",
       "4       1.117716  0.400609  0.980317  0.538834  0.267250  0.730641 -1.842685  \n",
       "...          ...       ...       ...       ...       ...       ...       ...  \n",
       "297543  1.056151 -0.783031 -0.228265 -1.012242  0.847001 -0.322014  0.437284  \n",
       "297544  0.253393 -1.491441 -0.875211  0.134408 -0.503012  0.850081 -0.875928  \n",
       "297545 -0.075833 -1.424216 -0.885639  0.603988 -0.622470  0.679971 -1.805622  \n",
       "297546  1.157744 -1.672122 -0.336969  1.009572 -0.394122  0.312486 -0.375061  \n",
       "297547  0.188683 -1.970819 -0.350554 -0.278030  1.467628  0.849500  0.147296  \n",
       "\n",
       "[297548 rows x 1282 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read peptides list\n",
    "flank0_df = pd.read_csv('./../../../data/PG/esm1b/flank'+str(0)+'_peptides_esm1b.csv',index_col=0)\n",
    "flank0_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b14a02c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make  and y\n",
    "X = flank0_df.drop(['peptide','hit'],axis=1).to_numpy()\n",
    "y = flank0_df['hit'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37850d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X.squeeze())\n",
    "X = torch.tensor(X, dtype=torch.float32).reshape(X.shape[0],1,X.shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b89749b",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "config_dict = { \"config\" : {\n",
    "                    \"hidden_channels\" : [32],\n",
    "                    \"kernel_size\":512,\n",
    "                    \"pool_kernel_size\":512,\n",
    "                    \"epochs\" : 1000,\n",
    "                    \"batch_size\" : 1024,\n",
    "                    \"lr\" : 1e-3,\n",
    "                    \"dropout_p\" : 0.,\n",
    "                    \"architecture\" : \"CNN\"\n",
    "                }\n",
    "        }\n",
    "config = config_dict['config']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e64eaee1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "PGPredictor                              [1024, 1]                 --\n",
       "├─Sequential: 1-1                        [1024, 1]                 --\n",
       "│    └─Conv1d: 2-1                       [1024, 32, 769]           16,416\n",
       "│    └─BatchNorm1d: 2-2                  [1024, 32, 769]           64\n",
       "│    └─Tanh: 2-3                         [1024, 32, 769]           --\n",
       "│    └─MaxPool1d: 2-4                    [1024, 32, 1]             --\n",
       "│    └─Dropout: 2-5                      [1024, 32, 1]             --\n",
       "│    └─Flatten: 2-6                      [1024, 32]                --\n",
       "│    └─Linear: 2-7                       [1024, 1]                 33\n",
       "==========================================================================================\n",
       "Total params: 16,513\n",
       "Trainable params: 16,513\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 12.93\n",
       "==========================================================================================\n",
       "Input size (MB): 5.24\n",
       "Forward/backward pass size (MB): 403.19\n",
       "Params size (MB): 0.07\n",
       "Estimated Total Size (MB): 408.49\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the data\n",
    "train_sequences, test_sequences, train_labels, test_labels = train_test_split(X, y, \n",
    "                                                                              test_size=0.2, random_state=seed)\n",
    "\n",
    "# Create dataset and dataloaders\n",
    "train_dataset = ProteinSequenceDataset(train_sequences, train_labels)\n",
    "test_dataset = ProteinSequenceDataset(test_sequences, test_labels)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=config['batch_size'], shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=config['batch_size'], shuffle=False)\n",
    "\n",
    "#### model training\n",
    "input_size = X.shape[-1] #embedding size for esm2_t33_650M_UR50D (allele + peptide)\n",
    "model = PGPredictor(input_size, config['hidden_channels'], \n",
    "                                 config['kernel_size'], config['pool_kernel_size'], config['dropout_p'])\n",
    "\n",
    "# Calculate class weights\n",
    "labels_tensor = torch.tensor(train_labels, dtype=torch.int16)\n",
    "class_counts = torch.bincount(labels_tensor)\n",
    "pos_weight = class_counts[0]/class_counts[1]\n",
    "pos_weight = pos_weight.to(dtype=torch.float32)\n",
    "\n",
    "summary(model, input_size=(config['batch_size'],1,input_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf47fd2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0\n",
      "[Epoch 1, Batch 10] loss: 1.561\n",
      "[Epoch 1, Batch 20] loss: 1.357\n",
      "[Epoch 1, Batch 30] loss: 1.250\n",
      "[Epoch 1, Batch 40] loss: 1.118\n",
      "[Epoch 1, Batch 50] loss: 1.039\n",
      "[Epoch 1, Batch 60] loss: 0.960\n",
      "[Epoch 1, Batch 70] loss: 0.938\n",
      "[Epoch 1, Batch 80] loss: 0.912\n",
      "[Epoch 1, Batch 90] loss: 0.916\n",
      "[Epoch 1, Batch 100] loss: 0.920\n",
      "[Epoch 1, Batch 110] loss: 0.912\n",
      "[Epoch 1, Batch 120] loss: 0.913\n",
      "[Epoch 1, Batch 130] loss: 0.908\n",
      "[Epoch 1, Batch 140] loss: 0.904\n",
      "[Epoch 1, Batch 150] loss: 0.909\n",
      "[Epoch 1, Batch 160] loss: 0.904\n",
      "[Epoch 1, Batch 170] loss: 0.901\n",
      "[Epoch 1, Batch 180] loss: 0.904\n",
      "[Epoch 1, Batch 190] loss: 0.907\n",
      "[Epoch 1, Batch 200] loss: 0.899\n",
      "[Epoch 1, Batch 210] loss: 0.904\n",
      "[Epoch 1, Batch 220] loss: 0.905\n",
      "[Epoch 1, Batch 230] loss: 0.905\n",
      "epoch:  1 val_f1:  0.6064339884131245 val_auroc:  0.6011333125048586 val_auprc:  0.41222767186962994\n",
      "epoch:  1\n",
      "[Epoch 2, Batch 10] loss: 0.907\n",
      "[Epoch 2, Batch 20] loss: 0.902\n",
      "[Epoch 2, Batch 30] loss: 0.894\n",
      "[Epoch 2, Batch 40] loss: 0.894\n",
      "[Epoch 2, Batch 50] loss: 0.898\n",
      "[Epoch 2, Batch 60] loss: 0.889\n",
      "[Epoch 2, Batch 70] loss: 0.894\n",
      "[Epoch 2, Batch 80] loss: 0.888\n",
      "[Epoch 2, Batch 90] loss: 0.890\n",
      "[Epoch 2, Batch 100] loss: 0.889\n",
      "[Epoch 2, Batch 110] loss: 0.891\n",
      "[Epoch 2, Batch 120] loss: 0.882\n",
      "[Epoch 2, Batch 130] loss: 0.877\n",
      "[Epoch 2, Batch 140] loss: 0.881\n",
      "[Epoch 2, Batch 150] loss: 0.881\n",
      "[Epoch 2, Batch 160] loss: 0.884\n",
      "[Epoch 2, Batch 170] loss: 0.875\n",
      "[Epoch 2, Batch 180] loss: 0.883\n",
      "[Epoch 2, Batch 190] loss: 0.884\n",
      "[Epoch 2, Batch 200] loss: 0.877\n",
      "[Epoch 2, Batch 210] loss: 0.875\n",
      "[Epoch 2, Batch 220] loss: 0.883\n",
      "[Epoch 2, Batch 230] loss: 0.879\n",
      "epoch:  2 val_f1:  0.5731116342661523 val_auroc:  0.6429559101650733 val_auprc:  0.4482124470431168\n",
      "Validation loss improved to 51.786041\n",
      "epoch:  2\n",
      "[Epoch 3, Batch 10] loss: 0.876\n",
      "[Epoch 3, Batch 20] loss: 0.878\n",
      "[Epoch 3, Batch 30] loss: 0.864\n",
      "[Epoch 3, Batch 40] loss: 0.870\n",
      "[Epoch 3, Batch 50] loss: 0.872\n",
      "[Epoch 3, Batch 60] loss: 0.874\n",
      "[Epoch 3, Batch 70] loss: 0.872\n",
      "[Epoch 3, Batch 80] loss: 0.870\n",
      "[Epoch 3, Batch 90] loss: 0.877\n",
      "[Epoch 3, Batch 100] loss: 0.870\n",
      "[Epoch 3, Batch 110] loss: 0.876\n",
      "[Epoch 3, Batch 120] loss: 0.870\n",
      "[Epoch 3, Batch 130] loss: 0.874\n",
      "[Epoch 3, Batch 140] loss: 0.870\n",
      "[Epoch 3, Batch 150] loss: 0.868\n",
      "[Epoch 3, Batch 160] loss: 0.875\n",
      "[Epoch 3, Batch 170] loss: 0.871\n",
      "[Epoch 3, Batch 180] loss: 0.865\n",
      "[Epoch 3, Batch 190] loss: 0.865\n",
      "[Epoch 3, Batch 200] loss: 0.871\n",
      "[Epoch 3, Batch 210] loss: 0.870\n",
      "[Epoch 3, Batch 220] loss: 0.865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "model.train_loop(train_loader=train_loader, valid_loader=test_loader, test_loader=None,\n",
    "                 config_dict=config_dict, pos_weight=pos_weight)\n",
    "end = time.time()\n",
    "time_elapsed = end - start\n",
    "print(\"Time for training: \", time_elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591d79bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
