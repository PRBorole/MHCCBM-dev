{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61fc039d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor,RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import torch\n",
    "import esm\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "from torchinfo import summary\n",
    "\n",
    "from sklearn.metrics import f1_score, roc_auc_score, roc_curve, auc, precision_recall_curve\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "import sys\n",
    "sys.path.append('./../../src/')\n",
    "\n",
    "\n",
    "from utils import *\n",
    "from TDPredictor_CNN import *\n",
    "# from TDPredictor_MLP import *\n",
    "from MHCCBM import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6132194",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>allele</th>\n",
       "      <th>HLA</th>\n",
       "      <th>MFI_ratio</th>\n",
       "      <th>SD</th>\n",
       "      <th>Source</th>\n",
       "      <th>ID</th>\n",
       "      <th>Sequence</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HLA-A*01:01</td>\n",
       "      <td>A*01:01</td>\n",
       "      <td>32.11</td>\n",
       "      <td>13.77</td>\n",
       "      <td>Bashirova</td>\n",
       "      <td>HLA:HLA00001</td>\n",
       "      <td>MAVMAPRTLLLLLSGALALTQTWAGSHSMRYFFTSVSRPGRGEPRF...</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HLA-A*01:02</td>\n",
       "      <td>A*01:02</td>\n",
       "      <td>109.86</td>\n",
       "      <td>35.04</td>\n",
       "      <td>Bashirova</td>\n",
       "      <td>HLA:HLA00002</td>\n",
       "      <td>MAVMAPRTLLLLLSGALALTQTWAGSHSMRYFSTSVSRPGSGEPRF...</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HLA-A*02:01</td>\n",
       "      <td>A*02:01</td>\n",
       "      <td>2.02</td>\n",
       "      <td>0.22</td>\n",
       "      <td>Bashirova</td>\n",
       "      <td>HLA:HLA00005</td>\n",
       "      <td>MAVMAPRTLVLLLSGALALTQTWAGSHSMRYFFTSVSRPGRGEPRF...</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HLA-A*02:02</td>\n",
       "      <td>A*02:02</td>\n",
       "      <td>1.45</td>\n",
       "      <td>0.16</td>\n",
       "      <td>Bashirova</td>\n",
       "      <td>HLA:HLA00007</td>\n",
       "      <td>MAVMAPRTLVLLLSGALALTQTWAGSHSMRYFFTSVSRPGRGEPRF...</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HLA-A*02:05</td>\n",
       "      <td>A*02:05</td>\n",
       "      <td>1.49</td>\n",
       "      <td>0.12</td>\n",
       "      <td>Bashirova</td>\n",
       "      <td>HLA:HLA00010</td>\n",
       "      <td>MAVMAPRTLVLLLSGALALTQTWAGSHSMRYFYTSVSRPGRGEPRF...</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>HLA-C*16:01</td>\n",
       "      <td>C*16:01</td>\n",
       "      <td>5.98</td>\n",
       "      <td>1.33</td>\n",
       "      <td>Bashirova</td>\n",
       "      <td>HLA:HLA00475</td>\n",
       "      <td>MRVMAPRTLILLLSGALALTETWACSHSMRYFYTAVSRPGRGEPRF...</td>\n",
       "      <td>366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>HLA-C*17:01</td>\n",
       "      <td>C*17:01</td>\n",
       "      <td>2.92</td>\n",
       "      <td>0.98</td>\n",
       "      <td>Bashirova</td>\n",
       "      <td>HLA:HLA04311</td>\n",
       "      <td>MRVMAPQALLLLLSGALALIETWAGSHSMRYFYTAVSRPGRGEPRF...</td>\n",
       "      <td>372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>HLA-C*17:03</td>\n",
       "      <td>C*17:03</td>\n",
       "      <td>3.63</td>\n",
       "      <td>1.29</td>\n",
       "      <td>Bashirova</td>\n",
       "      <td>HLA:HLA00993</td>\n",
       "      <td>MRVMAPQALLLLLSGALALIETWTGSHSMRYFYTAVSRPGRGEPRF...</td>\n",
       "      <td>372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>HLA-C*18:01</td>\n",
       "      <td>C*18:01</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.80</td>\n",
       "      <td>Bashirova</td>\n",
       "      <td>HLA:HLA00483</td>\n",
       "      <td>MRVMAPRALLLLLSGGLALTETWACSHSMRYFDTAVSRPGRGEPRF...</td>\n",
       "      <td>366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>HLA-C*18:02</td>\n",
       "      <td>C*18:02</td>\n",
       "      <td>2.28</td>\n",
       "      <td>0.66</td>\n",
       "      <td>Bashirova</td>\n",
       "      <td>HLA:HLA00484</td>\n",
       "      <td>MRVMAPRALLLLLSGGLALTETWACSHSMRYFDTAVSRPGRGEPRF...</td>\n",
       "      <td>366</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>97 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         allele      HLA  MFI_ratio     SD     Source            ID  \\\n",
       "0   HLA-A*01:01  A*01:01      32.11  13.77  Bashirova  HLA:HLA00001   \n",
       "1   HLA-A*01:02  A*01:02     109.86  35.04  Bashirova  HLA:HLA00002   \n",
       "2   HLA-A*02:01  A*02:01       2.02   0.22  Bashirova  HLA:HLA00005   \n",
       "3   HLA-A*02:02  A*02:02       1.45   0.16  Bashirova  HLA:HLA00007   \n",
       "4   HLA-A*02:05  A*02:05       1.49   0.12  Bashirova  HLA:HLA00010   \n",
       "..          ...      ...        ...    ...        ...           ...   \n",
       "92  HLA-C*16:01  C*16:01       5.98   1.33  Bashirova  HLA:HLA00475   \n",
       "93  HLA-C*17:01  C*17:01       2.92   0.98  Bashirova  HLA:HLA04311   \n",
       "94  HLA-C*17:03  C*17:03       3.63   1.29  Bashirova  HLA:HLA00993   \n",
       "95  HLA-C*18:01  C*18:01       2.76   0.80  Bashirova  HLA:HLA00483   \n",
       "96  HLA-C*18:02  C*18:02       2.28   0.66  Bashirova  HLA:HLA00484   \n",
       "\n",
       "                                             Sequence  length  \n",
       "0   MAVMAPRTLLLLLSGALALTQTWAGSHSMRYFFTSVSRPGRGEPRF...     365  \n",
       "1   MAVMAPRTLLLLLSGALALTQTWAGSHSMRYFSTSVSRPGSGEPRF...     365  \n",
       "2   MAVMAPRTLVLLLSGALALTQTWAGSHSMRYFFTSVSRPGRGEPRF...     365  \n",
       "3   MAVMAPRTLVLLLSGALALTQTWAGSHSMRYFFTSVSRPGRGEPRF...     365  \n",
       "4   MAVMAPRTLVLLLSGALALTQTWAGSHSMRYFYTSVSRPGRGEPRF...     365  \n",
       "..                                                ...     ...  \n",
       "92  MRVMAPRTLILLLSGALALTETWACSHSMRYFYTAVSRPGRGEPRF...     366  \n",
       "93  MRVMAPQALLLLLSGALALIETWAGSHSMRYFYTAVSRPGRGEPRF...     372  \n",
       "94  MRVMAPQALLLLLSGALALIETWTGSHSMRYFYTAVSRPGRGEPRF...     372  \n",
       "95  MRVMAPRALLLLLSGGLALTETWACSHSMRYFDTAVSRPGRGEPRF...     366  \n",
       "96  MRVMAPRALLLLLSGGLALTETWACSHSMRYFDTAVSRPGRGEPRF...     366  \n",
       "\n",
       "[97 rows x 8 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load full TD dataframe\n",
    "TD_full_df = pd.read_csv('./../../data/TD/processed_data//TD_full.csv',index_col=0)\n",
    "TD_full_df = TD_full_df.rename(columns={'HLA_full':'allele'})\n",
    "TD_full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6a3d9fb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>allele</th>\n",
       "      <th>HLA</th>\n",
       "      <th>MFI_ratio</th>\n",
       "      <th>SD</th>\n",
       "      <th>Source</th>\n",
       "      <th>ID</th>\n",
       "      <th>Sequence</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>HLA-C*07:01</td>\n",
       "      <td>C*07:01</td>\n",
       "      <td>1.38</td>\n",
       "      <td>0.45</td>\n",
       "      <td>Bashirova</td>\n",
       "      <td>HLA:HLA00433</td>\n",
       "      <td>MRVMAPRALLLLLSGGLALTETWACSHSMRYFDTAVSRPGRGEPRF...</td>\n",
       "      <td>366</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         allele      HLA  MFI_ratio    SD     Source            ID  \\\n",
       "82  HLA-C*07:01  C*07:01       1.38  0.45  Bashirova  HLA:HLA00433   \n",
       "\n",
       "                                             Sequence  length  \n",
       "82  MRVMAPRALLLLLSGGLALTETWACSHSMRYFDTAVSRPGRGEPRF...     366  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TD_full_df[TD_full_df['HLA']=='C*07:01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be6baf58",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'HLA-A*01:01': tensor([[-0.0175, -0.0270, -0.0234,  ..., -0.0569,  0.0393,  0.0693]]),\n",
       " 'HLA-A*01:02': tensor([[-0.0160, -0.0260, -0.0257,  ..., -0.0601,  0.0384,  0.0687]]),\n",
       " 'HLA-A*02:01': tensor([[-0.0016, -0.0314, -0.0237,  ..., -0.0590,  0.0384,  0.0710]]),\n",
       " 'HLA-A*02:02': tensor([[-0.0020, -0.0312, -0.0239,  ..., -0.0593,  0.0410,  0.0700]]),\n",
       " 'HLA-A*02:05': tensor([[-0.0019, -0.0322, -0.0257,  ..., -0.0591,  0.0420,  0.0692]]),\n",
       " 'HLA-A*03:01': tensor([[-0.0115, -0.0268, -0.0182,  ..., -0.0563,  0.0385,  0.0768]]),\n",
       " 'HLA-A*11:01': tensor([[-0.0127, -0.0270, -0.0204,  ..., -0.0585,  0.0396,  0.0772]]),\n",
       " 'HLA-A*11:02': tensor([[-0.0161, -0.0275, -0.0226,  ..., -0.0567,  0.0384,  0.0760]]),\n",
       " 'HLA-A*23:01': tensor([[-0.0117, -0.0215, -0.0158,  ..., -0.0574,  0.0455,  0.0724]]),\n",
       " 'HLA-A*24:02': tensor([[-0.0135, -0.0240, -0.0174,  ..., -0.0590,  0.0413,  0.0787]]),\n",
       " 'HLA-A*25:01': tensor([[-0.0043, -0.0157, -0.0223,  ..., -0.0545,  0.0368,  0.0696]]),\n",
       " 'HLA-A*26:01': tensor([[-0.0055, -0.0220, -0.0240,  ..., -0.0554,  0.0370,  0.0679]]),\n",
       " 'HLA-A*29:02': tensor([[-0.0056, -0.0254, -0.0166,  ..., -0.0574,  0.0339,  0.0714]]),\n",
       " 'HLA-A*30:01': tensor([[-0.0056, -0.0236, -0.0194,  ..., -0.0611,  0.0404,  0.0706]]),\n",
       " 'HLA-A*30:02': tensor([[-0.0086, -0.0247, -0.0208,  ..., -0.0629,  0.0387,  0.0661]]),\n",
       " 'HLA-A*31:01': tensor([[-0.0035, -0.0217, -0.0181,  ..., -0.0598,  0.0366,  0.0733]]),\n",
       " 'HLA-A*32:01': tensor([[-0.0037, -0.0206, -0.0148,  ..., -0.0589,  0.0375,  0.0709]]),\n",
       " 'HLA-A*33:01': tensor([[-0.0067, -0.0226, -0.0151,  ..., -0.0588,  0.0413,  0.0721]]),\n",
       " 'HLA-A*33:03': tensor([[-0.0068, -0.0243, -0.0174,  ..., -0.0596,  0.0385,  0.0738]]),\n",
       " 'HLA-A*34:02': tensor([[-0.0018, -0.0228, -0.0202,  ..., -0.0503,  0.0343,  0.0708]]),\n",
       " 'HLA-A*36:01': tensor([[-0.0164, -0.0307, -0.0247,  ..., -0.0598,  0.0381,  0.0710]]),\n",
       " 'HLA-A*66:01': tensor([[-0.0023, -0.0219, -0.0233,  ..., -0.0530,  0.0368,  0.0726]]),\n",
       " 'HLA-A*66:02': tensor([[-0.0006, -0.0243, -0.0232,  ..., -0.0546,  0.0359,  0.0747]]),\n",
       " 'HLA-A*68:01': tensor([[-0.0025, -0.0294, -0.0236,  ..., -0.0534,  0.0372,  0.0687]]),\n",
       " 'HLA-A*68:02': tensor([[-0.0044, -0.0306, -0.0264,  ..., -0.0567,  0.0365,  0.0667]]),\n",
       " 'HLA-A*74:01': tensor([[-0.0037, -0.0257, -0.0149,  ..., -0.0570,  0.0392,  0.0710]]),\n",
       " 'HLA-A*74:03': tensor([[-0.0038, -0.0243, -0.0154,  ..., -0.0584,  0.0376,  0.0714]]),\n",
       " 'HLA-A*80:01': tensor([[-0.0131, -0.0131, -0.0217,  ..., -0.0601,  0.0343,  0.0613]]),\n",
       " 'HLA-B*07:02': tensor([[-0.0175, -0.0218, -0.0190,  ..., -0.0561,  0.0523,  0.0716]]),\n",
       " 'HLA-B*07:05': tensor([[-0.0179, -0.0222, -0.0194,  ..., -0.0565,  0.0494,  0.0703]]),\n",
       " 'HLA-B*08:01': tensor([[-0.0163, -0.0233, -0.0136,  ..., -0.0565,  0.0519,  0.0766]]),\n",
       " 'HLA-B*13:02': tensor([[-0.0097, -0.0211, -0.0094,  ..., -0.0577,  0.0445,  0.0701]]),\n",
       " 'HLA-B*14:01': tensor([[-0.0117, -0.0183, -0.0164,  ..., -0.0487,  0.0509,  0.0676]]),\n",
       " 'HLA-B*14:02': tensor([[-0.0122, -0.0190, -0.0169,  ..., -0.0489,  0.0513,  0.0688]]),\n",
       " 'HLA-B*15:01': tensor([[-0.0068, -0.0216, -0.0161,  ..., -0.0533,  0.0443,  0.0656]]),\n",
       " 'HLA-B*15:03': tensor([[-0.0024, -0.0204, -0.0170,  ..., -0.0511,  0.0466,  0.0689]]),\n",
       " 'HLA-B*15:10': tensor([[-0.0060, -0.0212, -0.0186,  ..., -0.0543,  0.0470,  0.0662]]),\n",
       " 'HLA-B*15:16': tensor([[-0.0092, -0.0187, -0.0125,  ..., -0.0554,  0.0399,  0.0662]]),\n",
       " 'HLA-B*18:01': tensor([[-0.0121, -0.0200, -0.0190,  ..., -0.0515,  0.0491,  0.0620]]),\n",
       " 'HLA-B*27:05': tensor([[-0.0158, -0.0222, -0.0153,  ..., -0.0531,  0.0523,  0.0759]]),\n",
       " 'HLA-B*35:01': tensor([[-0.0082, -0.0209, -0.0175,  ..., -0.0522,  0.0448,  0.0700]]),\n",
       " 'HLA-B*35:02': tensor([[-0.0102, -0.0233, -0.0188,  ..., -0.0532,  0.0424,  0.0698]]),\n",
       " 'HLA-B*35:03': tensor([[-0.0099, -0.0226, -0.0164,  ..., -0.0526,  0.0444,  0.0714]]),\n",
       " 'HLA-B*37:01': tensor([[-0.0102, -0.0241, -0.0194,  ..., -0.0507,  0.0404,  0.0727]]),\n",
       " 'HLA-B*38:01': tensor([[-0.0163, -0.0196, -0.0176,  ..., -0.0511,  0.0482,  0.0684]]),\n",
       " 'HLA-B*39:01': tensor([[-0.0151, -0.0207, -0.0167,  ..., -0.0503,  0.0488,  0.0713]]),\n",
       " 'HLA-B*39:06': tensor([[-0.0131, -0.0191, -0.0154,  ..., -0.0518,  0.0478,  0.0716]]),\n",
       " 'HLA-B*39:10': tensor([[-0.0139, -0.0215, -0.0169,  ..., -0.0505,  0.0493,  0.0706]]),\n",
       " 'HLA-B*40:01': tensor([[-0.0157, -0.0162, -0.0163,  ..., -0.0511,  0.0467,  0.0683]]),\n",
       " 'HLA-B*40:02': tensor([[-0.0134, -0.0253, -0.0177,  ..., -0.0549,  0.0495,  0.0724]]),\n",
       " 'HLA-B*41:02': tensor([[-0.0176, -0.0239, -0.0164,  ..., -0.0555,  0.0488,  0.0708]]),\n",
       " 'HLA-B*42:01': tensor([[-0.0172, -0.0250, -0.0171,  ..., -0.0566,  0.0532,  0.0753]]),\n",
       " 'HLA-B*42:02': tensor([[-0.0178, -0.0234, -0.0178,  ..., -0.0582,  0.0534,  0.0755]]),\n",
       " 'HLA-B*44:02': tensor([[-0.0165, -0.0240, -0.0152,  ..., -0.0496,  0.0455,  0.0741]]),\n",
       " 'HLA-B*44:03': tensor([[-0.0148, -0.0200, -0.0151,  ..., -0.0486,  0.0460,  0.0708]]),\n",
       " 'HLA-B*44:05': tensor([[-0.0173, -0.0251, -0.0152,  ..., -0.0499,  0.0452,  0.0742]]),\n",
       " 'HLA-B*45:01': tensor([[-0.0082, -0.0182, -0.0154,  ..., -0.0529,  0.0451,  0.0686]]),\n",
       " 'HLA-B*46:01': tensor([[-0.0113, -0.0192, -0.0172,  ..., -0.0529,  0.0462,  0.0654]]),\n",
       " 'HLA-B*49:01': tensor([[-0.0080, -0.0153, -0.0151,  ..., -0.0523,  0.0437,  0.0682]]),\n",
       " 'HLA-B*50:01': tensor([[-0.0059, -0.0164, -0.0152,  ..., -0.0531,  0.0448,  0.0675]]),\n",
       " 'HLA-B*51:01': tensor([[-0.0101, -0.0196, -0.0145,  ..., -0.0504,  0.0459,  0.0659]]),\n",
       " 'HLA-B*52:01': tensor([[-0.0095, -0.0219, -0.0155,  ..., -0.0494,  0.0460,  0.0680]]),\n",
       " 'HLA-B*53:01': tensor([[-0.0110, -0.0187, -0.0171,  ..., -0.0512,  0.0447,  0.0707]]),\n",
       " 'HLA-B*55:01': tensor([[-0.0066, -0.0201, -0.0154,  ..., -0.0572,  0.0467,  0.0696]]),\n",
       " 'HLA-B*56:01': tensor([[-0.0058, -0.0192, -0.0132,  ..., -0.0579,  0.0482,  0.0720]]),\n",
       " 'HLA-B*57:01': tensor([[-0.0166, -0.0180, -0.0111,  ..., -0.0502,  0.0461,  0.0721]]),\n",
       " 'HLA-B*57:02': tensor([[-0.0213, -0.0243, -0.0116,  ..., -0.0509,  0.0448,  0.0691]]),\n",
       " 'HLA-B*57:03': tensor([[-0.0190, -0.0219, -0.0107,  ..., -0.0511,  0.0452,  0.0718]]),\n",
       " 'HLA-B*58:01': tensor([[-0.0116, -0.0206, -0.0156,  ..., -0.0499,  0.0445,  0.0721]]),\n",
       " 'HLA-B*58:02': tensor([[-0.0092, -0.0220, -0.0131,  ..., -0.0510,  0.0475,  0.0714]]),\n",
       " 'HLA-B*73:01': tensor([[-0.0132, -0.0155, -0.0175,  ..., -0.0486,  0.0466,  0.0661]]),\n",
       " 'HLA-B*78:01': tensor([[-0.0099, -0.0215, -0.0140,  ..., -0.0496,  0.0469,  0.0686]]),\n",
       " 'HLA-B*81:01': tensor([[-0.0120, -0.0202, -0.0192,  ..., -0.0482,  0.0486,  0.0680]]),\n",
       " 'HLA-C*01:02': tensor([[-0.0015, -0.0257, -0.0120,  ..., -0.0504,  0.0447,  0.0581]]),\n",
       " 'HLA-C*02:02': tensor([[-0.0016, -0.0246, -0.0139,  ..., -0.0537,  0.0544,  0.0602]]),\n",
       " 'HLA-C*02:10': tensor([[-0.0038, -0.0248, -0.0151,  ..., -0.0537,  0.0539,  0.0614]]),\n",
       " 'HLA-C*03:02': tensor([[-0.0034, -0.0239, -0.0167,  ..., -0.0489,  0.0468,  0.0600]]),\n",
       " 'HLA-C*03:03': tensor([[-0.0049, -0.0250, -0.0180,  ..., -0.0498,  0.0461,  0.0593]]),\n",
       " 'HLA-C*03:04': tensor([[-0.0063, -0.0259, -0.0180,  ..., -0.0503,  0.0459,  0.0603]]),\n",
       " 'HLA-C*04:01': tensor([[-0.0084, -0.0243, -0.0124,  ..., -0.0491,  0.0381,  0.0608]]),\n",
       " 'HLA-C*05:01': tensor([[-0.0108, -0.0318, -0.0176,  ..., -0.0507,  0.0442,  0.0576]]),\n",
       " 'HLA-C*06:02': tensor([[-0.0013, -0.0188, -0.0162,  ..., -0.0535,  0.0525,  0.0668]]),\n",
       " 'HLA-C*07:01': tensor([[ 0.0151, -0.0162, -0.0087,  ..., -0.0544,  0.0485,  0.0650]]),\n",
       " 'HLA-C*07:02': tensor([[ 0.0145, -0.0140, -0.0098,  ..., -0.0534,  0.0487,  0.0628]]),\n",
       " 'HLA-C*07:04': tensor([[ 0.0101, -0.0225, -0.0130,  ..., -0.0556,  0.0451,  0.0663]]),\n",
       " 'HLA-C*08:02': tensor([[-0.0085, -0.0309, -0.0168,  ..., -0.0507,  0.0450,  0.0576]]),\n",
       " 'HLA-C*08:04': tensor([[-0.0069, -0.0288, -0.0156,  ..., -0.0499,  0.0457,  0.0593]]),\n",
       " 'HLA-C*12:02': tensor([[-0.0037, -0.0239, -0.0155,  ..., -0.0520,  0.0504,  0.0640]]),\n",
       " 'HLA-C*12:03': tensor([[-0.0015, -0.0230, -0.0151,  ..., -0.0525,  0.0516,  0.0640]]),\n",
       " 'HLA-C*14:02': tensor([[-0.0009, -0.0223, -0.0127,  ..., -0.0496,  0.0463,  0.0601]]),\n",
       " 'HLA-C*15:02': tensor([[-0.0046, -0.0237, -0.0130,  ..., -0.0532,  0.0515,  0.0597]]),\n",
       " 'HLA-C*15:05': tensor([[-0.0054, -0.0247, -0.0139,  ..., -0.0538,  0.0499,  0.0621]]),\n",
       " 'HLA-C*16:01': tensor([[-0.0015, -0.0275, -0.0125,  ..., -0.0464,  0.0523,  0.0630]]),\n",
       " 'HLA-C*17:01': tensor([[ 0.0053, -0.0215, -0.0160,  ..., -0.0361,  0.0420,  0.0679]]),\n",
       " 'HLA-C*17:03': tensor([[ 0.0060, -0.0213, -0.0167,  ..., -0.0348,  0.0413,  0.0659]]),\n",
       " 'HLA-C*18:01': tensor([[-0.0085, -0.0263, -0.0129,  ..., -0.0490,  0.0470,  0.0587]]),\n",
       " 'HLA-C*18:02': tensor([[-0.0092, -0.0252, -0.0126,  ..., -0.0487,  0.0468,  0.0590]])}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load embeddings\n",
    "with open('./../../data/TD/processed_data//allele_esm1b.pkl','rb') as f:\n",
    "    embedding_dict = pickle.load(f)\n",
    "    \n",
    "embedding_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18f85848",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Combined embeddings and y\n",
    "merged_df = pd.DataFrame({'allele':embedding_dict.keys(),\n",
    "                          'embedding':embedding_dict.values()}).merge(TD_full_df, \n",
    "                                                                      on='allele')[['embedding','MFI_ratio']]\n",
    "\n",
    "X = torch.cat(merged_df['embedding'].to_list())\n",
    "y = merged_df['MFI_ratio'].to_numpy()\n",
    "\n",
    "# Scale the data\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(X.squeeze())\n",
    "X = torch.tensor(X, dtype=torch.float32)\n",
    "\n",
    "# Scale y\n",
    "y = np.where(y>2, 1, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f710b6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ef6f7a85",
   "metadata": {},
   "source": [
    "## Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8542fbd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "\n",
    "# best config [128], 3, 32, 0.001, 0\n",
    "\n",
    "config_dict = {\"project\": \"MHCCBM\", \n",
    "                 \"name\": \"CNN_80\", \n",
    "                 \"config\": {\"hidden_channels\": [128], \n",
    "                            \"epochs\": 200,  # determined from number of epochs needed from hyperopts\n",
    "                            \"kernel_size\":13, #13, \n",
    "                            \"pool_kernel_size\": 13, #13, \n",
    "                            \"classes\": 2, \n",
    "                            \"seed\": seed, \n",
    "                            \"batch_size\": 32, \n",
    "                            \"lr\": 1e-03, \n",
    "                            \"dataset\": \"TD bashirova MFI data\", \n",
    "                            \"dropout_p\": 0.0, \n",
    "                            \"architecture\": \"CNN\"}}\n",
    "\n",
    "config = config_dict['config']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f32a21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4852ce55",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2222)\n",
      "epoch:  0\n",
      "epoch:  1 val_loss:  tensor(0.2601) val_f1:  0.6380952380952382 val_auroc:  0.640625 val_auprc:  0.8896827821194113\n",
      "epoch:  1\n",
      "epoch:  2 val_loss:  tensor(0.2849) val_f1:  0.06666666666666668 val_auroc:  0.5 val_auprc:  0.7891616224494031\n",
      "EarlyStopping counter: 1 out of 50\n",
      "epoch:  2\n",
      "epoch:  3 val_loss:  tensor(0.2910) val_f1:  0.06666666666666668 val_auroc:  0.46875 val_auprc:  0.7388081998303555\n",
      "EarlyStopping counter: 2 out of 50\n",
      "epoch:  3\n",
      "epoch:  4 val_loss:  tensor(0.2658) val_f1:  0.06666666666666668 val_auroc:  0.46875 val_auprc:  0.7388081998303555\n",
      "EarlyStopping counter: 3 out of 50\n",
      "epoch:  4\n",
      "epoch:  5 val_loss:  tensor(0.2754) val_f1:  0.7359307359307359 val_auroc:  0.46875 val_auprc:  0.7388081998303555\n",
      "EarlyStopping counter: 4 out of 50\n",
      "epoch:  5\n",
      "epoch:  6 val_loss:  tensor(0.2820) val_f1:  0.6857142857142857 val_auroc:  0.46875 val_auprc:  0.7388081998303555\n",
      "EarlyStopping counter: 5 out of 50\n",
      "epoch:  6\n",
      "epoch:  7 val_loss:  tensor(0.2672) val_f1:  0.6796238244514107 val_auroc:  0.46875 val_auprc:  0.7388081998303555\n",
      "EarlyStopping counter: 6 out of 50\n",
      "epoch:  7\n",
      "epoch:  8 val_loss:  tensor(0.2693) val_f1:  0.14343434343434341 val_auroc:  0.46875 val_auprc:  0.7388081998303555\n",
      "EarlyStopping counter: 7 out of 50\n",
      "epoch:  8\n",
      "epoch:  9 val_loss:  tensor(0.2691) val_f1:  0.22556390977443605 val_auroc:  0.46875 val_auprc:  0.7388081998303555\n",
      "EarlyStopping counter: 8 out of 50\n",
      "epoch:  9\n",
      "epoch:  10 val_loss:  tensor(0.2670) val_f1:  0.5494505494505495 val_auroc:  0.46875 val_auprc:  0.7388081998303555\n",
      "EarlyStopping counter: 9 out of 50\n",
      "epoch:  10\n",
      "epoch:  11 val_loss:  tensor(0.2722) val_f1:  0.663799283154122 val_auroc:  0.46875 val_auprc:  0.7388081998303555\n",
      "EarlyStopping counter: 10 out of 50\n",
      "epoch:  11\n",
      "epoch:  12 val_loss:  tensor(0.2695) val_f1:  0.72 val_auroc:  0.46875 val_auprc:  0.7388081998303555\n",
      "EarlyStopping counter: 11 out of 50\n",
      "epoch:  12\n",
      "epoch:  13 val_loss:  tensor(0.2663) val_f1:  0.5013333333333334 val_auroc:  0.46875 val_auprc:  0.7388081998303555\n",
      "EarlyStopping counter: 12 out of 50\n",
      "epoch:  13\n",
      "epoch:  14 val_loss:  tensor(0.2663) val_f1:  0.3353535353535354 val_auroc:  0.46875 val_auprc:  0.7388081998303555\n",
      "EarlyStopping counter: 13 out of 50\n",
      "epoch:  14\n",
      "epoch:  15 val_loss:  tensor(0.2660) val_f1:  0.5494505494505495 val_auroc:  0.46875 val_auprc:  0.7388081998303555\n",
      "EarlyStopping counter: 14 out of 50\n",
      "epoch:  15\n",
      "epoch:  16 val_loss:  tensor(0.2676) val_f1:  0.72 val_auroc:  0.46875 val_auprc:  0.7388081998303555\n",
      "EarlyStopping counter: 15 out of 50\n",
      "epoch:  16\n",
      "epoch:  17 val_loss:  tensor(0.2673) val_f1:  0.72 val_auroc:  0.46875 val_auprc:  0.7388081998303555\n",
      "EarlyStopping counter: 16 out of 50\n",
      "epoch:  17\n",
      "epoch:  18 val_loss:  tensor(0.2655) val_f1:  0.5494505494505495 val_auroc:  0.46875 val_auprc:  0.7388081998303555\n",
      "EarlyStopping counter: 17 out of 50\n",
      "epoch:  18\n",
      "epoch:  19 val_loss:  tensor(0.2649) val_f1:  0.5013333333333334 val_auroc:  0.5 val_auprc:  0.7537635569732126\n",
      "EarlyStopping counter: 18 out of 50\n",
      "epoch:  19\n",
      "epoch:  20 val_loss:  tensor(0.2649) val_f1:  0.5494505494505495 val_auroc:  0.5 val_auprc:  0.7537635569732126\n",
      "EarlyStopping counter: 19 out of 50\n",
      "epoch:  20\n",
      "epoch:  21 val_loss:  tensor(0.2654) val_f1:  0.6796238244514107 val_auroc:  0.5 val_auprc:  0.7537635569732126\n",
      "EarlyStopping counter: 20 out of 50\n",
      "epoch:  21\n",
      "epoch:  22 val_loss:  tensor(0.2652) val_f1:  0.6796238244514107 val_auroc:  0.5 val_auprc:  0.7537635569732126\n",
      "EarlyStopping counter: 21 out of 50\n",
      "epoch:  22\n",
      "epoch:  23 val_loss:  tensor(0.2643) val_f1:  0.6380952380952382 val_auroc:  0.5 val_auprc:  0.7537635569732126\n",
      "EarlyStopping counter: 22 out of 50\n",
      "epoch:  23\n",
      "epoch:  24 val_loss:  tensor(0.2637) val_f1:  0.5494505494505495 val_auroc:  0.515625 val_auprc:  0.7565639095703919\n",
      "EarlyStopping counter: 23 out of 50\n",
      "epoch:  24\n",
      "epoch:  25 val_loss:  tensor(0.2636) val_f1:  0.6380952380952382 val_auroc:  0.53125 val_auprc:  0.7629503183005506\n",
      "EarlyStopping counter: 24 out of 50\n",
      "epoch:  25\n",
      "epoch:  26 val_loss:  tensor(0.2637) val_f1:  0.6796238244514107 val_auroc:  0.546875 val_auprc:  0.7664287409195982\n",
      "EarlyStopping counter: 25 out of 50\n",
      "epoch:  26\n",
      "epoch:  27 val_loss:  tensor(0.2635) val_f1:  0.6796238244514107 val_auroc:  0.546875 val_auprc:  0.7664287409195982\n",
      "EarlyStopping counter: 26 out of 50\n",
      "epoch:  27\n",
      "epoch:  28 val_loss:  tensor(0.2629) val_f1:  0.6380952380952382 val_auroc:  0.546875 val_auprc:  0.7664287409195982\n",
      "EarlyStopping counter: 27 out of 50\n",
      "epoch:  28\n",
      "epoch:  29 val_loss:  tensor(0.2624) val_f1:  0.6380952380952382 val_auroc:  0.546875 val_auprc:  0.7664287409195982\n",
      "EarlyStopping counter: 28 out of 50\n",
      "epoch:  29\n",
      "epoch:  30 val_loss:  tensor(0.2622) val_f1:  0.6380952380952382 val_auroc:  0.546875 val_auprc:  0.7664287409195982\n",
      "EarlyStopping counter: 29 out of 50\n",
      "epoch:  30\n",
      "epoch:  31 val_loss:  tensor(0.2621) val_f1:  0.6796238244514107 val_auroc:  0.546875 val_auprc:  0.7664287409195982\n",
      "EarlyStopping counter: 30 out of 50\n",
      "epoch:  31\n",
      "epoch:  32 val_loss:  tensor(0.2618) val_f1:  0.6796238244514107 val_auroc:  0.546875 val_auprc:  0.7664287409195982\n",
      "EarlyStopping counter: 31 out of 50\n",
      "epoch:  32\n",
      "epoch:  33 val_loss:  tensor(0.2614) val_f1:  0.6796238244514107 val_auroc:  0.546875 val_auprc:  0.7664287409195982\n",
      "EarlyStopping counter: 32 out of 50\n",
      "epoch:  33\n",
      "epoch:  34 val_loss:  tensor(0.2610) val_f1:  0.6796238244514107 val_auroc:  0.578125 val_auprc:  0.7775793091014164\n",
      "EarlyStopping counter: 33 out of 50\n",
      "epoch:  34\n",
      "epoch:  35 val_loss:  tensor(0.2607) val_f1:  0.6796238244514107 val_auroc:  0.59375 val_auprc:  0.7825035515256589\n",
      "EarlyStopping counter: 34 out of 50\n",
      "epoch:  35\n",
      "epoch:  36 val_loss:  tensor(0.2605) val_f1:  0.72 val_auroc:  0.59375 val_auprc:  0.7825035515256589\n",
      "EarlyStopping counter: 35 out of 50\n",
      "epoch:  36\n",
      "epoch:  37 val_loss:  tensor(0.2602) val_f1:  0.72 val_auroc:  0.59375 val_auprc:  0.7825035515256589\n",
      "EarlyStopping counter: 36 out of 50\n",
      "epoch:  37\n",
      "epoch:  38 val_loss:  tensor(0.2598) val_f1:  0.72 val_auroc:  0.59375 val_auprc:  0.7825035515256589\n",
      "Validation loss improved to 0.259795\n",
      "epoch:  38\n",
      "epoch:  39 val_loss:  tensor(0.2595) val_f1:  0.72 val_auroc:  0.609375 val_auprc:  0.7870745014091087\n",
      "Validation loss improved to 0.259452\n",
      "epoch:  39\n",
      "epoch:  40 val_loss:  tensor(0.2592) val_f1:  0.72 val_auroc:  0.609375 val_auprc:  0.7870745014091087\n",
      "Validation loss improved to 0.259180\n",
      "epoch:  40\n",
      "epoch:  41 val_loss:  tensor(0.2589) val_f1:  0.72 val_auroc:  0.625 val_auprc:  0.7913384666105738\n",
      "Validation loss improved to 0.258917\n",
      "epoch:  41\n",
      "epoch:  42 val_loss:  tensor(0.2586) val_f1:  0.72 val_auroc:  0.625 val_auprc:  0.7913384666105738\n",
      "Validation loss improved to 0.258605\n",
      "epoch:  42\n",
      "epoch:  43 val_loss:  tensor(0.2583) val_f1:  0.7711598746081505 val_auroc:  0.625 val_auprc:  0.7913384666105738\n",
      "Validation loss improved to 0.258263\n",
      "epoch:  43\n",
      "epoch:  44 val_loss:  tensor(0.2579) val_f1:  0.7711598746081505 val_auroc:  0.625 val_auprc:  0.7913384666105738\n",
      "Validation loss improved to 0.257942\n",
      "epoch:  44\n",
      "epoch:  45 val_loss:  tensor(0.2577) val_f1:  0.7711598746081505 val_auroc:  0.625 val_auprc:  0.7913384666105738\n",
      "Validation loss improved to 0.257651\n",
      "epoch:  45\n",
      "epoch:  46 val_loss:  tensor(0.2574) val_f1:  0.7711598746081505 val_auroc:  0.625 val_auprc:  0.7913384666105738\n",
      "Validation loss improved to 0.257356\n",
      "epoch:  46\n",
      "epoch:  47 val_loss:  tensor(0.2570) val_f1:  0.7711598746081505 val_auroc:  0.625 val_auprc:  0.7913384666105738\n",
      "Validation loss improved to 0.257036\n",
      "epoch:  47\n",
      "epoch:  48 val_loss:  tensor(0.2567) val_f1:  0.7711598746081505 val_auroc:  0.625 val_auprc:  0.7913384666105738\n",
      "Validation loss improved to 0.256706\n",
      "epoch:  48\n",
      "epoch:  49 val_loss:  tensor(0.2564) val_f1:  0.7711598746081505 val_auroc:  0.625 val_auprc:  0.7913384666105738\n",
      "Validation loss improved to 0.256390\n",
      "epoch:  49\n",
      "epoch:  50 val_loss:  tensor(0.2561) val_f1:  0.7711598746081505 val_auroc:  0.625 val_auprc:  0.7913384666105738\n",
      "Validation loss improved to 0.256085\n",
      "epoch:  50\n",
      "epoch:  51 val_loss:  tensor(0.2558) val_f1:  0.7711598746081505 val_auroc:  0.640625 val_auprc:  0.7940248701193457\n",
      "Validation loss improved to 0.255774\n",
      "epoch:  51\n",
      "epoch:  52 val_loss:  tensor(0.2555) val_f1:  0.7711598746081505 val_auroc:  0.65625 val_auprc:  0.7980198334893092\n",
      "Validation loss improved to 0.255451\n",
      "epoch:  52\n",
      "epoch:  53 val_loss:  tensor(0.2551) val_f1:  0.7711598746081505 val_auroc:  0.65625 val_auprc:  0.7980198334893092\n",
      "Validation loss improved to 0.255125\n",
      "epoch:  53\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  54 val_loss:  tensor(0.2548) val_f1:  0.7711598746081505 val_auroc:  0.65625 val_auprc:  0.7980198334893092\n",
      "Validation loss improved to 0.254808\n",
      "epoch:  54\n",
      "epoch:  55 val_loss:  tensor(0.2545) val_f1:  0.7711598746081505 val_auroc:  0.65625 val_auprc:  0.7980198334893092\n",
      "Validation loss improved to 0.254493\n",
      "epoch:  55\n",
      "epoch:  56 val_loss:  tensor(0.2542) val_f1:  0.7711598746081505 val_auroc:  0.65625 val_auprc:  0.7980198334893092\n",
      "Validation loss improved to 0.254173\n",
      "epoch:  56\n",
      "epoch:  57 val_loss:  tensor(0.2538) val_f1:  0.7711598746081505 val_auroc:  0.65625 val_auprc:  0.7980198334893092\n",
      "Validation loss improved to 0.253847\n",
      "epoch:  57\n",
      "epoch:  58 val_loss:  tensor(0.2535) val_f1:  0.7711598746081505 val_auroc:  0.65625 val_auprc:  0.7980198334893092\n",
      "Validation loss improved to 0.253520\n",
      "epoch:  58\n",
      "epoch:  59 val_loss:  tensor(0.2532) val_f1:  0.7711598746081505 val_auroc:  0.65625 val_auprc:  0.7980198334893092\n",
      "Validation loss improved to 0.253198\n",
      "epoch:  59\n",
      "epoch:  60 val_loss:  tensor(0.2529) val_f1:  0.7711598746081505 val_auroc:  0.65625 val_auprc:  0.7980198334893092\n",
      "Validation loss improved to 0.252876\n",
      "epoch:  60\n",
      "epoch:  61 val_loss:  tensor(0.2526) val_f1:  0.7711598746081505 val_auroc:  0.65625 val_auprc:  0.7980198334893092\n",
      "Validation loss improved to 0.252551\n",
      "epoch:  61\n",
      "epoch:  62 val_loss:  tensor(0.2522) val_f1:  0.7711598746081505 val_auroc:  0.65625 val_auprc:  0.7980198334893092\n",
      "Validation loss improved to 0.252226\n",
      "epoch:  62\n",
      "epoch:  63 val_loss:  tensor(0.2519) val_f1:  0.7711598746081505 val_auroc:  0.671875 val_auprc:  0.8013209977049954\n",
      "Validation loss improved to 0.251902\n",
      "epoch:  63\n",
      "epoch:  64 val_loss:  tensor(0.2516) val_f1:  0.8133333333333332 val_auroc:  0.671875 val_auprc:  0.8013209977049954\n",
      "Validation loss improved to 0.251576\n",
      "epoch:  64\n",
      "epoch:  65 val_loss:  tensor(0.2512) val_f1:  0.8133333333333332 val_auroc:  0.671875 val_auprc:  0.8013209977049954\n",
      "Validation loss improved to 0.251249\n",
      "epoch:  65\n",
      "epoch:  66 val_loss:  tensor(0.2509) val_f1:  0.8133333333333332 val_auroc:  0.671875 val_auprc:  0.8013209977049954\n",
      "Validation loss improved to 0.250917\n",
      "epoch:  66\n",
      "epoch:  67 val_loss:  tensor(0.2506) val_f1:  0.8133333333333332 val_auroc:  0.671875 val_auprc:  0.8013209977049954\n",
      "Validation loss improved to 0.250584\n",
      "epoch:  67\n",
      "epoch:  68 val_loss:  tensor(0.2502) val_f1:  0.8133333333333332 val_auroc:  0.671875 val_auprc:  0.8013209977049954\n",
      "Validation loss improved to 0.250249\n",
      "epoch:  68\n",
      "epoch:  69 val_loss:  tensor(0.2499) val_f1:  0.8133333333333332 val_auroc:  0.671875 val_auprc:  0.8013209977049954\n",
      "Validation loss improved to 0.249916\n",
      "epoch:  69\n",
      "epoch:  70 val_loss:  tensor(0.2496) val_f1:  0.8133333333333332 val_auroc:  0.671875 val_auprc:  0.8013209977049954\n",
      "Validation loss improved to 0.249581\n",
      "epoch:  70\n",
      "epoch:  71 val_loss:  tensor(0.2492) val_f1:  0.8133333333333332 val_auroc:  0.671875 val_auprc:  0.8013209977049954\n",
      "Validation loss improved to 0.249245\n",
      "epoch:  71\n",
      "epoch:  72 val_loss:  tensor(0.2489) val_f1:  0.8133333333333332 val_auroc:  0.671875 val_auprc:  0.8013209977049954\n",
      "Validation loss improved to 0.248908\n",
      "epoch:  72\n",
      "epoch:  73 val_loss:  tensor(0.2486) val_f1:  0.8133333333333332 val_auroc:  0.671875 val_auprc:  0.8013209977049954\n",
      "Validation loss improved to 0.248570\n",
      "epoch:  73\n",
      "epoch:  74 val_loss:  tensor(0.2482) val_f1:  0.8133333333333332 val_auroc:  0.671875 val_auprc:  0.8013209977049954\n",
      "Validation loss improved to 0.248229\n",
      "epoch:  74\n",
      "epoch:  75 val_loss:  tensor(0.2479) val_f1:  0.8133333333333332 val_auroc:  0.671875 val_auprc:  0.8013209977049954\n",
      "Validation loss improved to 0.247887\n",
      "epoch:  75\n",
      "epoch:  76 val_loss:  tensor(0.2475) val_f1:  0.8133333333333332 val_auroc:  0.671875 val_auprc:  0.8013209977049954\n",
      "Validation loss improved to 0.247543\n",
      "epoch:  76\n",
      "epoch:  77 val_loss:  tensor(0.2472) val_f1:  0.8133333333333332 val_auroc:  0.671875 val_auprc:  0.8013209977049954\n",
      "Validation loss improved to 0.247198\n",
      "epoch:  77\n",
      "epoch:  78 val_loss:  tensor(0.2469) val_f1:  0.8133333333333332 val_auroc:  0.671875 val_auprc:  0.8013209977049954\n",
      "Validation loss improved to 0.246851\n",
      "epoch:  78\n",
      "epoch:  79 val_loss:  tensor(0.2465) val_f1:  0.8133333333333332 val_auroc:  0.6875 val_auprc:  0.8044613163324464\n",
      "Validation loss improved to 0.246504\n",
      "epoch:  79\n",
      "epoch:  80 val_loss:  tensor(0.2462) val_f1:  0.8133333333333332 val_auroc:  0.6875 val_auprc:  0.8044613163324464\n",
      "Validation loss improved to 0.246156\n",
      "epoch:  80\n",
      "epoch:  81 val_loss:  tensor(0.2458) val_f1:  0.8133333333333332 val_auroc:  0.6875 val_auprc:  0.8044613163324464\n",
      "Validation loss improved to 0.245807\n",
      "epoch:  81\n",
      "epoch:  82 val_loss:  tensor(0.2455) val_f1:  0.8133333333333332 val_auroc:  0.6875 val_auprc:  0.8044613163324464\n",
      "Validation loss improved to 0.245457\n",
      "epoch:  82\n",
      "epoch:  83 val_loss:  tensor(0.2451) val_f1:  0.8133333333333332 val_auroc:  0.6875 val_auprc:  0.8044613163324464\n",
      "Validation loss improved to 0.245105\n",
      "epoch:  83\n",
      "epoch:  84 val_loss:  tensor(0.2448) val_f1:  0.8133333333333332 val_auroc:  0.6875 val_auprc:  0.8044613163324464\n",
      "Validation loss improved to 0.244751\n",
      "epoch:  84\n",
      "epoch:  85 val_loss:  tensor(0.2444) val_f1:  0.8133333333333332 val_auroc:  0.6875 val_auprc:  0.8044613163324464\n",
      "Validation loss improved to 0.244395\n",
      "epoch:  85\n",
      "epoch:  86 val_loss:  tensor(0.2440) val_f1:  0.8133333333333332 val_auroc:  0.703125 val_auprc:  0.807455167381638\n",
      "Validation loss improved to 0.244035\n",
      "epoch:  86\n",
      "epoch:  87 val_loss:  tensor(0.2437) val_f1:  0.8133333333333332 val_auroc:  0.703125 val_auprc:  0.807455167381638\n",
      "Validation loss improved to 0.243673\n",
      "epoch:  87\n",
      "epoch:  88 val_loss:  tensor(0.2433) val_f1:  0.8133333333333332 val_auroc:  0.703125 val_auprc:  0.807455167381638\n",
      "Validation loss improved to 0.243309\n",
      "epoch:  88\n",
      "epoch:  89 val_loss:  tensor(0.2429) val_f1:  0.8133333333333332 val_auroc:  0.703125 val_auprc:  0.807455167381638\n",
      "Validation loss improved to 0.242941\n",
      "epoch:  89\n",
      "epoch:  90 val_loss:  tensor(0.2426) val_f1:  0.8133333333333332 val_auroc:  0.703125 val_auprc:  0.807455167381638\n",
      "Validation loss improved to 0.242570\n",
      "epoch:  90\n",
      "epoch:  91 val_loss:  tensor(0.2422) val_f1:  0.8133333333333332 val_auroc:  0.703125 val_auprc:  0.807455167381638\n",
      "Validation loss improved to 0.242199\n",
      "epoch:  91\n",
      "epoch:  92 val_loss:  tensor(0.2418) val_f1:  0.8133333333333332 val_auroc:  0.703125 val_auprc:  0.807455167381638\n",
      "Validation loss improved to 0.241826\n",
      "epoch:  92\n",
      "epoch:  93 val_loss:  tensor(0.2415) val_f1:  0.8133333333333332 val_auroc:  0.703125 val_auprc:  0.807455167381638\n",
      "Validation loss improved to 0.241453\n",
      "epoch:  93\n",
      "epoch:  94 val_loss:  tensor(0.2411) val_f1:  0.8133333333333332 val_auroc:  0.703125 val_auprc:  0.807455167381638\n",
      "Validation loss improved to 0.241075\n",
      "epoch:  94\n",
      "epoch:  95 val_loss:  tensor(0.2407) val_f1:  0.7598566308243728 val_auroc:  0.703125 val_auprc:  0.807455167381638\n",
      "Validation loss improved to 0.240696\n",
      "epoch:  95\n",
      "epoch:  96 val_loss:  tensor(0.2403) val_f1:  0.7598566308243728 val_auroc:  0.703125 val_auprc:  0.807455167381638\n",
      "Validation loss improved to 0.240317\n",
      "epoch:  96\n",
      "epoch:  97 val_loss:  tensor(0.2399) val_f1:  0.7598566308243728 val_auroc:  0.703125 val_auprc:  0.807455167381638\n",
      "Validation loss improved to 0.239935\n",
      "epoch:  97\n",
      "epoch:  98 val_loss:  tensor(0.2396) val_f1:  0.7598566308243728 val_auroc:  0.703125 val_auprc:  0.807455167381638\n",
      "Validation loss improved to 0.239551\n",
      "epoch:  98\n",
      "epoch:  99 val_loss:  tensor(0.2392) val_f1:  0.7598566308243728 val_auroc:  0.703125 val_auprc:  0.807455167381638\n",
      "Validation loss improved to 0.239163\n",
      "epoch:  99\n",
      "epoch:  100 val_loss:  tensor(0.2388) val_f1:  0.7598566308243728 val_auroc:  0.703125 val_auprc:  0.807455167381638\n",
      "Validation loss improved to 0.238773\n",
      "epoch:  100\n",
      "epoch:  101 val_loss:  tensor(0.2384) val_f1:  0.7598566308243728 val_auroc:  0.703125 val_auprc:  0.807455167381638\n",
      "Validation loss improved to 0.238383\n",
      "epoch:  101\n",
      "epoch:  102 val_loss:  tensor(0.2380) val_f1:  0.7598566308243728 val_auroc:  0.703125 val_auprc:  0.807455167381638\n",
      "Validation loss improved to 0.237991\n",
      "epoch:  102\n",
      "epoch:  103 val_loss:  tensor(0.2376) val_f1:  0.7598566308243728 val_auroc:  0.703125 val_auprc:  0.807455167381638\n",
      "Validation loss improved to 0.237595\n",
      "epoch:  103\n",
      "epoch:  104 val_loss:  tensor(0.2372) val_f1:  0.7598566308243728 val_auroc:  0.703125 val_auprc:  0.807455167381638\n",
      "Validation loss improved to 0.237198\n",
      "epoch:  104\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  105 val_loss:  tensor(0.2368) val_f1:  0.7598566308243728 val_auroc:  0.703125 val_auprc:  0.807455167381638\n",
      "Validation loss improved to 0.236799\n",
      "epoch:  105\n",
      "epoch:  106 val_loss:  tensor(0.2364) val_f1:  0.7598566308243728 val_auroc:  0.703125 val_auprc:  0.807455167381638\n",
      "Validation loss improved to 0.236398\n",
      "epoch:  106\n",
      "epoch:  107 val_loss:  tensor(0.2360) val_f1:  0.7598566308243728 val_auroc:  0.703125 val_auprc:  0.807455167381638\n",
      "Validation loss improved to 0.235994\n",
      "epoch:  107\n",
      "epoch:  108 val_loss:  tensor(0.2356) val_f1:  0.7598566308243728 val_auroc:  0.703125 val_auprc:  0.807455167381638\n",
      "Validation loss improved to 0.235589\n",
      "epoch:  108\n",
      "epoch:  109 val_loss:  tensor(0.2352) val_f1:  0.7598566308243728 val_auroc:  0.703125 val_auprc:  0.807455167381638\n",
      "Validation loss improved to 0.235179\n",
      "epoch:  109\n",
      "epoch:  110 val_loss:  tensor(0.2348) val_f1:  0.7598566308243728 val_auroc:  0.703125 val_auprc:  0.807455167381638\n",
      "Validation loss improved to 0.234767\n",
      "epoch:  110\n",
      "epoch:  111 val_loss:  tensor(0.2344) val_f1:  0.7598566308243728 val_auroc:  0.703125 val_auprc:  0.807455167381638\n",
      "Validation loss improved to 0.234354\n",
      "epoch:  111\n",
      "epoch:  112 val_loss:  tensor(0.2339) val_f1:  0.7598566308243728 val_auroc:  0.703125 val_auprc:  0.807455167381638\n",
      "Validation loss improved to 0.233938\n",
      "epoch:  112\n",
      "epoch:  113 val_loss:  tensor(0.2335) val_f1:  0.8 val_auroc:  0.703125 val_auprc:  0.807455167381638\n",
      "Validation loss improved to 0.233519\n",
      "epoch:  113\n",
      "epoch:  114 val_loss:  tensor(0.2331) val_f1:  0.8 val_auroc:  0.703125 val_auprc:  0.807455167381638\n",
      "Validation loss improved to 0.233097\n",
      "epoch:  114\n",
      "epoch:  115 val_loss:  tensor(0.2327) val_f1:  0.8 val_auroc:  0.703125 val_auprc:  0.807455167381638\n",
      "Validation loss improved to 0.232676\n",
      "epoch:  115\n",
      "epoch:  116 val_loss:  tensor(0.2323) val_f1:  0.8 val_auroc:  0.703125 val_auprc:  0.807455167381638\n",
      "Validation loss improved to 0.232254\n",
      "epoch:  116\n",
      "epoch:  117 val_loss:  tensor(0.2318) val_f1:  0.8 val_auroc:  0.71875 val_auprc:  0.854330167381638\n",
      "Validation loss improved to 0.231829\n",
      "epoch:  117\n",
      "epoch:  118 val_loss:  tensor(0.2314) val_f1:  0.8 val_auroc:  0.734375 val_auprc:  0.8580876078578286\n",
      "Validation loss improved to 0.231402\n",
      "epoch:  118\n",
      "epoch:  119 val_loss:  tensor(0.2310) val_f1:  0.8 val_auroc:  0.734375 val_auprc:  0.8580876078578286\n",
      "Validation loss improved to 0.230973\n",
      "epoch:  119\n",
      "epoch:  120 val_loss:  tensor(0.2305) val_f1:  0.8 val_auroc:  0.734375 val_auprc:  0.8580876078578286\n",
      "Validation loss improved to 0.230544\n",
      "epoch:  120\n",
      "epoch:  121 val_loss:  tensor(0.2301) val_f1:  0.8 val_auroc:  0.734375 val_auprc:  0.8580876078578286\n",
      "Validation loss improved to 0.230113\n",
      "epoch:  121\n",
      "epoch:  122 val_loss:  tensor(0.2297) val_f1:  0.8 val_auroc:  0.734375 val_auprc:  0.8580876078578286\n",
      "Validation loss improved to 0.229681\n",
      "epoch:  122\n",
      "epoch:  123 val_loss:  tensor(0.2292) val_f1:  0.8 val_auroc:  0.734375 val_auprc:  0.8580876078578286\n",
      "Validation loss improved to 0.229246\n",
      "epoch:  123\n",
      "epoch:  124 val_loss:  tensor(0.2288) val_f1:  0.8 val_auroc:  0.734375 val_auprc:  0.8580876078578286\n",
      "Validation loss improved to 0.228811\n",
      "epoch:  124\n",
      "epoch:  125 val_loss:  tensor(0.2284) val_f1:  0.8 val_auroc:  0.734375 val_auprc:  0.8580876078578286\n",
      "Validation loss improved to 0.228375\n",
      "epoch:  125\n",
      "epoch:  126 val_loss:  tensor(0.2279) val_f1:  0.8 val_auroc:  0.734375 val_auprc:  0.8580876078578286\n",
      "Validation loss improved to 0.227937\n",
      "epoch:  126\n",
      "epoch:  127 val_loss:  tensor(0.2275) val_f1:  0.8 val_auroc:  0.734375 val_auprc:  0.8580876078578286\n",
      "Validation loss improved to 0.227498\n",
      "epoch:  127\n",
      "epoch:  128 val_loss:  tensor(0.2271) val_f1:  0.8 val_auroc:  0.734375 val_auprc:  0.8580876078578286\n",
      "Validation loss improved to 0.227057\n",
      "epoch:  128\n",
      "epoch:  129 val_loss:  tensor(0.2266) val_f1:  0.8 val_auroc:  0.734375 val_auprc:  0.8580876078578286\n",
      "Validation loss improved to 0.226617\n",
      "epoch:  129\n",
      "epoch:  130 val_loss:  tensor(0.2262) val_f1:  0.8 val_auroc:  0.734375 val_auprc:  0.8580876078578286\n",
      "Validation loss improved to 0.226175\n",
      "epoch:  130\n",
      "epoch:  131 val_loss:  tensor(0.2257) val_f1:  0.8 val_auroc:  0.734375 val_auprc:  0.8580876078578286\n",
      "Validation loss improved to 0.225730\n",
      "epoch:  131\n",
      "epoch:  132 val_loss:  tensor(0.2253) val_f1:  0.8 val_auroc:  0.734375 val_auprc:  0.8580876078578286\n",
      "Validation loss improved to 0.225283\n",
      "epoch:  132\n",
      "epoch:  133 val_loss:  tensor(0.2248) val_f1:  0.8 val_auroc:  0.734375 val_auprc:  0.8580876078578286\n",
      "Validation loss improved to 0.224835\n",
      "epoch:  133\n",
      "epoch:  134 val_loss:  tensor(0.2244) val_f1:  0.8 val_auroc:  0.734375 val_auprc:  0.8580876078578286\n",
      "Validation loss improved to 0.224386\n",
      "epoch:  134\n",
      "epoch:  135 val_loss:  tensor(0.2239) val_f1:  0.8 val_auroc:  0.734375 val_auprc:  0.8580876078578286\n",
      "Validation loss improved to 0.223937\n",
      "epoch:  135\n",
      "epoch:  136 val_loss:  tensor(0.2235) val_f1:  0.8 val_auroc:  0.75 val_auprc:  0.8841292745244952\n",
      "Validation loss improved to 0.223487\n",
      "epoch:  136\n",
      "epoch:  137 val_loss:  tensor(0.2230) val_f1:  0.8 val_auroc:  0.75 val_auprc:  0.8841292745244952\n",
      "Validation loss improved to 0.223036\n",
      "epoch:  137\n",
      "epoch:  138 val_loss:  tensor(0.2226) val_f1:  0.8 val_auroc:  0.75 val_auprc:  0.8841292745244952\n",
      "Validation loss improved to 0.222587\n",
      "epoch:  138\n",
      "epoch:  139 val_loss:  tensor(0.2221) val_f1:  0.8 val_auroc:  0.75 val_auprc:  0.8841292745244952\n",
      "Validation loss improved to 0.222136\n",
      "epoch:  139\n",
      "epoch:  140 val_loss:  tensor(0.2217) val_f1:  0.8 val_auroc:  0.75 val_auprc:  0.8841292745244952\n",
      "Validation loss improved to 0.221685\n",
      "epoch:  140\n",
      "epoch:  141 val_loss:  tensor(0.2212) val_f1:  0.8 val_auroc:  0.75 val_auprc:  0.8841292745244952\n",
      "Validation loss improved to 0.221234\n",
      "epoch:  141\n",
      "epoch:  142 val_loss:  tensor(0.2208) val_f1:  0.8 val_auroc:  0.75 val_auprc:  0.8841292745244952\n",
      "Validation loss improved to 0.220781\n",
      "epoch:  142\n",
      "epoch:  143 val_loss:  tensor(0.2203) val_f1:  0.8 val_auroc:  0.75 val_auprc:  0.8841292745244952\n",
      "Validation loss improved to 0.220328\n",
      "epoch:  143\n",
      "epoch:  144 val_loss:  tensor(0.2199) val_f1:  0.8 val_auroc:  0.75 val_auprc:  0.8841292745244952\n",
      "Validation loss improved to 0.219874\n",
      "epoch:  144\n",
      "epoch:  145 val_loss:  tensor(0.2194) val_f1:  0.8 val_auroc:  0.75 val_auprc:  0.8841292745244952\n",
      "Validation loss improved to 0.219420\n",
      "epoch:  145\n",
      "epoch:  146 val_loss:  tensor(0.2190) val_f1:  0.8 val_auroc:  0.75 val_auprc:  0.8841292745244952\n",
      "Validation loss improved to 0.218967\n",
      "epoch:  146\n",
      "epoch:  147 val_loss:  tensor(0.2185) val_f1:  0.8 val_auroc:  0.765625 val_auprc:  0.9023584411911618\n",
      "Validation loss improved to 0.218516\n",
      "epoch:  147\n",
      "epoch:  148 val_loss:  tensor(0.2181) val_f1:  0.8 val_auroc:  0.765625 val_auprc:  0.9023584411911618\n",
      "Validation loss improved to 0.218066\n",
      "epoch:  148\n",
      "epoch:  149 val_loss:  tensor(0.2176) val_f1:  0.8 val_auroc:  0.765625 val_auprc:  0.9023584411911618\n",
      "Validation loss improved to 0.217617\n",
      "epoch:  149\n",
      "epoch:  150 val_loss:  tensor(0.2172) val_f1:  0.8 val_auroc:  0.765625 val_auprc:  0.9023584411911618\n",
      "Validation loss improved to 0.217171\n",
      "epoch:  150\n",
      "epoch:  151 val_loss:  tensor(0.2167) val_f1:  0.8 val_auroc:  0.765625 val_auprc:  0.9023584411911618\n",
      "Validation loss improved to 0.216725\n",
      "epoch:  151\n",
      "epoch:  152 val_loss:  tensor(0.2163) val_f1:  0.8 val_auroc:  0.765625 val_auprc:  0.9023584411911618\n",
      "Validation loss improved to 0.216279\n",
      "epoch:  152\n",
      "epoch:  153 val_loss:  tensor(0.2158) val_f1:  0.8 val_auroc:  0.765625 val_auprc:  0.9023584411911618\n",
      "Validation loss improved to 0.215835\n",
      "epoch:  153\n",
      "epoch:  154 val_loss:  tensor(0.2154) val_f1:  0.8 val_auroc:  0.78125 val_auprc:  0.9164209411911617\n",
      "Validation loss improved to 0.215395\n",
      "epoch:  154\n",
      "epoch:  155 val_loss:  tensor(0.2150) val_f1:  0.8 val_auroc:  0.78125 val_auprc:  0.9164209411911617\n",
      "Validation loss improved to 0.214956\n",
      "epoch:  155\n",
      "epoch:  156 val_loss:  tensor(0.2145) val_f1:  0.8 val_auroc:  0.78125 val_auprc:  0.9164209411911617\n",
      "Validation loss improved to 0.214516\n",
      "epoch:  156\n",
      "epoch:  157 val_loss:  tensor(0.2141) val_f1:  0.8 val_auroc:  0.78125 val_auprc:  0.9164209411911617\n",
      "Validation loss improved to 0.214076\n",
      "epoch:  157\n",
      "epoch:  158 val_loss:  tensor(0.2136) val_f1:  0.8 val_auroc:  0.78125 val_auprc:  0.9164209411911617\n",
      "Validation loss improved to 0.213638\n",
      "epoch:  158\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  159 val_loss:  tensor(0.2132) val_f1:  0.8 val_auroc:  0.78125 val_auprc:  0.9164209411911617\n",
      "Validation loss improved to 0.213204\n",
      "epoch:  159\n",
      "epoch:  160 val_loss:  tensor(0.2128) val_f1:  0.8 val_auroc:  0.78125 val_auprc:  0.9164209411911617\n",
      "Validation loss improved to 0.212771\n",
      "epoch:  160\n",
      "epoch:  161 val_loss:  tensor(0.2123) val_f1:  0.8 val_auroc:  0.78125 val_auprc:  0.9164209411911617\n",
      "Validation loss improved to 0.212338\n",
      "epoch:  161\n",
      "epoch:  162 val_loss:  tensor(0.2119) val_f1:  0.8 val_auroc:  0.78125 val_auprc:  0.9164209411911617\n",
      "Validation loss improved to 0.211907\n",
      "epoch:  162\n",
      "epoch:  163 val_loss:  tensor(0.2115) val_f1:  0.8 val_auroc:  0.78125 val_auprc:  0.9164209411911617\n",
      "Validation loss improved to 0.211478\n",
      "epoch:  163\n",
      "epoch:  164 val_loss:  tensor(0.2111) val_f1:  0.8 val_auroc:  0.78125 val_auprc:  0.9164209411911617\n",
      "Validation loss improved to 0.211052\n",
      "epoch:  164\n",
      "epoch:  165 val_loss:  tensor(0.2106) val_f1:  0.8 val_auroc:  0.78125 val_auprc:  0.9164209411911617\n",
      "Validation loss improved to 0.210627\n",
      "epoch:  165\n",
      "epoch:  166 val_loss:  tensor(0.2102) val_f1:  0.8 val_auroc:  0.78125 val_auprc:  0.9164209411911617\n",
      "Validation loss improved to 0.210206\n",
      "epoch:  166\n",
      "epoch:  167 val_loss:  tensor(0.2098) val_f1:  0.8 val_auroc:  0.78125 val_auprc:  0.9164209411911617\n",
      "Validation loss improved to 0.209788\n",
      "epoch:  167\n",
      "epoch:  168 val_loss:  tensor(0.2094) val_f1:  0.8 val_auroc:  0.78125 val_auprc:  0.9164209411911617\n",
      "Validation loss improved to 0.209374\n",
      "epoch:  168\n",
      "epoch:  169 val_loss:  tensor(0.2090) val_f1:  0.8 val_auroc:  0.78125 val_auprc:  0.9164209411911617\n",
      "Validation loss improved to 0.208964\n",
      "epoch:  169\n",
      "epoch:  170 val_loss:  tensor(0.2086) val_f1:  0.8 val_auroc:  0.78125 val_auprc:  0.9164209411911617\n",
      "Validation loss improved to 0.208557\n",
      "epoch:  170\n",
      "epoch:  171 val_loss:  tensor(0.2082) val_f1:  0.8 val_auroc:  0.78125 val_auprc:  0.9164209411911617\n",
      "Validation loss improved to 0.208152\n",
      "epoch:  171\n",
      "epoch:  172 val_loss:  tensor(0.2077) val_f1:  0.8 val_auroc:  0.78125 val_auprc:  0.9164209411911617\n",
      "Validation loss improved to 0.207748\n",
      "epoch:  172\n",
      "epoch:  173 val_loss:  tensor(0.2073) val_f1:  0.8 val_auroc:  0.78125 val_auprc:  0.9164209411911617\n",
      "Validation loss improved to 0.207347\n",
      "epoch:  173\n",
      "epoch:  174 val_loss:  tensor(0.2070) val_f1:  0.8 val_auroc:  0.796875 val_auprc:  0.927879274524495\n",
      "Validation loss improved to 0.206950\n",
      "epoch:  174\n",
      "epoch:  175 val_loss:  tensor(0.2066) val_f1:  0.8 val_auroc:  0.8125 val_auprc:  0.9375518935721141\n",
      "Validation loss improved to 0.206558\n",
      "epoch:  175\n",
      "epoch:  176 val_loss:  tensor(0.2062) val_f1:  0.8 val_auroc:  0.8125 val_auprc:  0.9375518935721141\n",
      "Validation loss improved to 0.206166\n",
      "epoch:  176\n",
      "epoch:  177 val_loss:  tensor(0.2058) val_f1:  0.8 val_auroc:  0.8125 val_auprc:  0.9375518935721141\n",
      "Validation loss improved to 0.205777\n",
      "epoch:  177\n",
      "epoch:  178 val_loss:  tensor(0.2054) val_f1:  0.8 val_auroc:  0.8125 val_auprc:  0.9375518935721141\n",
      "Validation loss improved to 0.205390\n",
      "epoch:  178\n",
      "epoch:  179 val_loss:  tensor(0.2050) val_f1:  0.8 val_auroc:  0.8125 val_auprc:  0.9375518935721141\n",
      "Validation loss improved to 0.205007\n",
      "epoch:  179\n",
      "epoch:  180 val_loss:  tensor(0.2046) val_f1:  0.8 val_auroc:  0.8125 val_auprc:  0.9375518935721141\n",
      "Validation loss improved to 0.204626\n",
      "epoch:  180\n",
      "epoch:  181 val_loss:  tensor(0.2042) val_f1:  0.8 val_auroc:  0.8125 val_auprc:  0.9375518935721141\n",
      "Validation loss improved to 0.204248\n",
      "epoch:  181\n",
      "epoch:  182 val_loss:  tensor(0.2039) val_f1:  0.8 val_auroc:  0.8125 val_auprc:  0.9375518935721141\n",
      "Validation loss improved to 0.203873\n",
      "epoch:  182\n",
      "epoch:  183 val_loss:  tensor(0.2035) val_f1:  0.8 val_auroc:  0.8125 val_auprc:  0.9375518935721141\n",
      "Validation loss improved to 0.203501\n",
      "epoch:  183\n",
      "epoch:  184 val_loss:  tensor(0.2031) val_f1:  0.8 val_auroc:  0.8125 val_auprc:  0.9375518935721141\n",
      "Validation loss improved to 0.203132\n",
      "epoch:  184\n",
      "epoch:  185 val_loss:  tensor(0.2028) val_f1:  0.8 val_auroc:  0.8125 val_auprc:  0.9375518935721141\n",
      "Validation loss improved to 0.202769\n",
      "epoch:  185\n",
      "epoch:  186 val_loss:  tensor(0.2024) val_f1:  0.8 val_auroc:  0.828125 val_auprc:  0.9459224292863999\n",
      "Validation loss improved to 0.202408\n",
      "epoch:  186\n",
      "epoch:  187 val_loss:  tensor(0.2021) val_f1:  0.8 val_auroc:  0.828125 val_auprc:  0.9459224292863999\n",
      "Validation loss improved to 0.202053\n",
      "epoch:  187\n",
      "epoch:  188 val_loss:  tensor(0.2017) val_f1:  0.8 val_auroc:  0.828125 val_auprc:  0.9459224292863999\n",
      "Validation loss improved to 0.201702\n",
      "epoch:  188\n",
      "epoch:  189 val_loss:  tensor(0.2014) val_f1:  0.8 val_auroc:  0.828125 val_auprc:  0.9459224292863999\n",
      "Validation loss improved to 0.201354\n",
      "epoch:  189\n",
      "epoch:  190 val_loss:  tensor(0.2010) val_f1:  0.8 val_auroc:  0.828125 val_auprc:  0.9459224292863999\n",
      "Validation loss improved to 0.201008\n",
      "epoch:  190\n",
      "epoch:  191 val_loss:  tensor(0.2007) val_f1:  0.8 val_auroc:  0.828125 val_auprc:  0.9459224292863999\n",
      "Validation loss improved to 0.200667\n",
      "epoch:  191\n",
      "epoch:  192 val_loss:  tensor(0.2003) val_f1:  0.8 val_auroc:  0.828125 val_auprc:  0.9459224292863999\n",
      "Validation loss improved to 0.200331\n",
      "epoch:  192\n",
      "epoch:  193 val_loss:  tensor(0.2000) val_f1:  0.8 val_auroc:  0.828125 val_auprc:  0.9459224292863999\n",
      "Validation loss improved to 0.199996\n",
      "epoch:  193\n",
      "epoch:  194 val_loss:  tensor(0.1997) val_f1:  0.8 val_auroc:  0.828125 val_auprc:  0.9459224292863999\n",
      "Validation loss improved to 0.199662\n",
      "epoch:  194\n",
      "epoch:  195 val_loss:  tensor(0.1993) val_f1:  0.8 val_auroc:  0.828125 val_auprc:  0.9459224292863999\n",
      "Validation loss improved to 0.199331\n",
      "epoch:  195\n",
      "epoch:  196 val_loss:  tensor(0.1990) val_f1:  0.8 val_auroc:  0.828125 val_auprc:  0.9459224292863999\n",
      "Validation loss improved to 0.199006\n",
      "epoch:  196\n",
      "epoch:  197 val_loss:  tensor(0.1987) val_f1:  0.8 val_auroc:  0.828125 val_auprc:  0.9459224292863999\n",
      "Validation loss improved to 0.198686\n",
      "epoch:  197\n",
      "epoch:  198 val_loss:  tensor(0.1984) val_f1:  0.8 val_auroc:  0.84375 val_auprc:  0.9533009015086221\n",
      "Validation loss improved to 0.198369\n",
      "epoch:  198\n",
      "epoch:  199 val_loss:  tensor(0.1981) val_f1:  0.8 val_auroc:  0.84375 val_auprc:  0.9533009015086221\n",
      "Validation loss improved to 0.198053\n",
      "epoch:  199\n",
      "epoch:  200 val_loss:  tensor(0.1977) val_f1:  0.8 val_auroc:  0.84375 val_auprc:  0.9533009015086221\n",
      "Validation loss improved to 0.197741\n",
      "Time taken:  17.451583862304688\n",
      "tensor(0.2222)\n",
      "epoch:  0\n",
      "epoch:  1 val_loss:  tensor(0.2693) val_f1:  0.7111111111111111 val_auroc:  0.578125 val_auprc:  0.7821363866557849\n",
      "epoch:  1\n",
      "epoch:  2 val_loss:  tensor(0.2674) val_f1:  0.06666666666666668 val_auroc:  0.6875 val_auprc:  0.9248968303583242\n",
      "Validation loss improved to 0.267365\n",
      "epoch:  2\n",
      "epoch:  3 val_loss:  tensor(0.2871) val_f1:  0.06666666666666668 val_auroc:  0.703125 val_auprc:  0.9294677802417741\n",
      "EarlyStopping counter: 1 out of 50\n",
      "epoch:  3\n",
      "epoch:  4 val_loss:  tensor(0.2736) val_f1:  0.06666666666666668 val_auroc:  0.703125 val_auprc:  0.9294677802417741\n",
      "EarlyStopping counter: 2 out of 50\n",
      "epoch:  4\n",
      "epoch:  5 val_loss:  tensor(0.2519) val_f1:  0.25050505050505045 val_auroc:  0.71875 val_auprc:  0.9337317454432392\n",
      "Validation loss improved to 0.251940\n",
      "epoch:  5\n",
      "epoch:  6 val_loss:  tensor(0.2538) val_f1:  0.6 val_auroc:  0.71875 val_auprc:  0.9337317454432392\n",
      "EarlyStopping counter: 1 out of 50\n",
      "epoch:  6\n",
      "epoch:  7 val_loss:  tensor(0.2554) val_f1:  0.6588235294117648 val_auroc:  0.71875 val_auprc:  0.9337317454432392\n",
      "EarlyStopping counter: 2 out of 50\n",
      "epoch:  7\n",
      "epoch:  8 val_loss:  tensor(0.2488) val_f1:  0.7285714285714285 val_auroc:  0.71875 val_auprc:  0.9337317454432392\n",
      "Validation loss improved to 0.248828\n",
      "epoch:  8\n",
      "epoch:  9 val_loss:  tensor(0.2501) val_f1:  0.32882205513784457 val_auroc:  0.703125 val_auprc:  0.9277658363523302\n",
      "EarlyStopping counter: 1 out of 50\n",
      "epoch:  9\n",
      "epoch:  10 val_loss:  tensor(0.2526) val_f1:  0.06666666666666668 val_auroc:  0.703125 val_auprc:  0.9277658363523302\n",
      "EarlyStopping counter: 2 out of 50\n",
      "epoch:  10\n",
      "epoch:  11 val_loss:  tensor(0.2491) val_f1:  0.4651629072681704 val_auroc:  0.703125 val_auprc:  0.9277658363523302\n",
      "EarlyStopping counter: 3 out of 50\n",
      "epoch:  11\n",
      "epoch:  12 val_loss:  tensor(0.2474) val_f1:  0.6849002849002848 val_auroc:  0.6875 val_auprc:  0.923501871150865\n",
      "Validation loss improved to 0.247393\n",
      "epoch:  12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  13 val_loss:  tensor(0.2483) val_f1:  0.7285714285714285 val_auroc:  0.6875 val_auprc:  0.923501871150865\n",
      "EarlyStopping counter: 1 out of 50\n",
      "epoch:  13\n",
      "epoch:  14 val_loss:  tensor(0.2476) val_f1:  0.7285714285714285 val_auroc:  0.6875 val_auprc:  0.923501871150865\n",
      "EarlyStopping counter: 2 out of 50\n",
      "epoch:  14\n",
      "epoch:  15 val_loss:  tensor(0.2472) val_f1:  0.6826666666666666 val_auroc:  0.6875 val_auprc:  0.923501871150865\n",
      "Validation loss improved to 0.247214\n",
      "epoch:  15\n",
      "epoch:  16 val_loss:  tensor(0.2477) val_f1:  0.581074168797954 val_auroc:  0.6875 val_auprc:  0.923501871150865\n",
      "EarlyStopping counter: 1 out of 50\n",
      "epoch:  16\n",
      "epoch:  17 val_loss:  tensor(0.2475) val_f1:  0.6333333333333333 val_auroc:  0.6875 val_auprc:  0.923501871150865\n",
      "EarlyStopping counter: 2 out of 50\n",
      "epoch:  17\n",
      "epoch:  18 val_loss:  tensor(0.2472) val_f1:  0.6849002849002848 val_auroc:  0.6875 val_auprc:  0.923501871150865\n",
      "Validation loss improved to 0.247165\n",
      "epoch:  18\n",
      "epoch:  19 val_loss:  tensor(0.2474) val_f1:  0.6849002849002848 val_auroc:  0.6875 val_auprc:  0.923501871150865\n",
      "EarlyStopping counter: 1 out of 50\n",
      "epoch:  19\n",
      "epoch:  20 val_loss:  tensor(0.2474) val_f1:  0.6849002849002848 val_auroc:  0.6875 val_auprc:  0.923501871150865\n",
      "EarlyStopping counter: 2 out of 50\n",
      "epoch:  20\n",
      "epoch:  21 val_loss:  tensor(0.2473) val_f1:  0.6849002849002848 val_auroc:  0.6875 val_auprc:  0.923501871150865\n",
      "EarlyStopping counter: 3 out of 50\n",
      "epoch:  21\n",
      "epoch:  22 val_loss:  tensor(0.2473) val_f1:  0.6849002849002848 val_auroc:  0.65625 val_auprc:  0.9166280158395097\n",
      "EarlyStopping counter: 4 out of 50\n",
      "epoch:  22\n",
      "epoch:  23 val_loss:  tensor(0.2474) val_f1:  0.6849002849002848 val_auroc:  0.65625 val_auprc:  0.9166280158395097\n",
      "EarlyStopping counter: 5 out of 50\n",
      "epoch:  23\n",
      "epoch:  24 val_loss:  tensor(0.2474) val_f1:  0.6849002849002848 val_auroc:  0.65625 val_auprc:  0.9166280158395097\n",
      "EarlyStopping counter: 6 out of 50\n",
      "epoch:  24\n",
      "epoch:  25 val_loss:  tensor(0.2476) val_f1:  0.6849002849002848 val_auroc:  0.65625 val_auprc:  0.9166280158395097\n",
      "EarlyStopping counter: 7 out of 50\n",
      "epoch:  25\n",
      "epoch:  26 val_loss:  tensor(0.2477) val_f1:  0.6849002849002848 val_auroc:  0.65625 val_auprc:  0.9166280158395097\n",
      "EarlyStopping counter: 8 out of 50\n",
      "epoch:  26\n",
      "epoch:  27 val_loss:  tensor(0.2477) val_f1:  0.6849002849002848 val_auroc:  0.65625 val_auprc:  0.9166280158395097\n",
      "EarlyStopping counter: 9 out of 50\n",
      "epoch:  27\n",
      "epoch:  28 val_loss:  tensor(0.2477) val_f1:  0.6849002849002848 val_auroc:  0.65625 val_auprc:  0.9166280158395097\n",
      "EarlyStopping counter: 10 out of 50\n",
      "epoch:  28\n",
      "epoch:  29 val_loss:  tensor(0.2477) val_f1:  0.6849002849002848 val_auroc:  0.65625 val_auprc:  0.9166280158395097\n",
      "EarlyStopping counter: 11 out of 50\n",
      "epoch:  29\n",
      "epoch:  30 val_loss:  tensor(0.2479) val_f1:  0.6849002849002848 val_auroc:  0.65625 val_auprc:  0.9166280158395097\n",
      "EarlyStopping counter: 12 out of 50\n",
      "epoch:  30\n",
      "epoch:  31 val_loss:  tensor(0.2480) val_f1:  0.7285714285714285 val_auroc:  0.65625 val_auprc:  0.9166280158395097\n",
      "EarlyStopping counter: 13 out of 50\n",
      "epoch:  31\n",
      "epoch:  32 val_loss:  tensor(0.2481) val_f1:  0.7285714285714285 val_auroc:  0.65625 val_auprc:  0.9166280158395097\n",
      "EarlyStopping counter: 14 out of 50\n",
      "epoch:  32\n",
      "epoch:  33 val_loss:  tensor(0.2481) val_f1:  0.7285714285714285 val_auroc:  0.65625 val_auprc:  0.9166280158395097\n",
      "EarlyStopping counter: 15 out of 50\n",
      "epoch:  33\n",
      "epoch:  34 val_loss:  tensor(0.2481) val_f1:  0.7285714285714285 val_auroc:  0.671875 val_auprc:  0.9198274206014144\n",
      "EarlyStopping counter: 16 out of 50\n",
      "epoch:  34\n",
      "epoch:  35 val_loss:  tensor(0.2482) val_f1:  0.7285714285714285 val_auroc:  0.671875 val_auprc:  0.9198274206014144\n",
      "EarlyStopping counter: 17 out of 50\n",
      "epoch:  35\n",
      "epoch:  36 val_loss:  tensor(0.2483) val_f1:  0.7285714285714285 val_auroc:  0.6875 val_auprc:  0.922883486777885\n",
      "EarlyStopping counter: 18 out of 50\n",
      "epoch:  36\n",
      "epoch:  37 val_loss:  tensor(0.2484) val_f1:  0.7285714285714285 val_auroc:  0.6875 val_auprc:  0.922883486777885\n",
      "EarlyStopping counter: 19 out of 50\n",
      "epoch:  37\n",
      "epoch:  38 val_loss:  tensor(0.2485) val_f1:  0.7285714285714285 val_auroc:  0.6875 val_auprc:  0.922883486777885\n",
      "EarlyStopping counter: 20 out of 50\n",
      "epoch:  38\n",
      "epoch:  39 val_loss:  tensor(0.2485) val_f1:  0.7285714285714285 val_auroc:  0.6875 val_auprc:  0.922883486777885\n",
      "EarlyStopping counter: 21 out of 50\n",
      "epoch:  39\n",
      "epoch:  40 val_loss:  tensor(0.2486) val_f1:  0.7285714285714285 val_auroc:  0.6875 val_auprc:  0.922883486777885\n",
      "EarlyStopping counter: 22 out of 50\n",
      "epoch:  40\n",
      "epoch:  41 val_loss:  tensor(0.2487) val_f1:  0.7285714285714285 val_auroc:  0.6875 val_auprc:  0.922883486777885\n",
      "EarlyStopping counter: 23 out of 50\n",
      "epoch:  41\n",
      "epoch:  42 val_loss:  tensor(0.2488) val_f1:  0.7285714285714285 val_auroc:  0.671875 val_auprc:  0.9162862645556628\n",
      "EarlyStopping counter: 24 out of 50\n",
      "epoch:  42\n",
      "epoch:  43 val_loss:  tensor(0.2489) val_f1:  0.7285714285714285 val_auroc:  0.671875 val_auprc:  0.9162862645556628\n",
      "EarlyStopping counter: 25 out of 50\n",
      "epoch:  43\n",
      "epoch:  44 val_loss:  tensor(0.2490) val_f1:  0.7285714285714285 val_auroc:  0.671875 val_auprc:  0.9162862645556628\n",
      "EarlyStopping counter: 26 out of 50\n",
      "epoch:  44\n",
      "epoch:  45 val_loss:  tensor(0.2491) val_f1:  0.7285714285714285 val_auroc:  0.671875 val_auprc:  0.9162862645556628\n",
      "EarlyStopping counter: 27 out of 50\n",
      "epoch:  45\n",
      "epoch:  46 val_loss:  tensor(0.2492) val_f1:  0.7285714285714285 val_auroc:  0.671875 val_auprc:  0.9162862645556628\n",
      "EarlyStopping counter: 28 out of 50\n",
      "epoch:  46\n",
      "epoch:  47 val_loss:  tensor(0.2492) val_f1:  0.7285714285714285 val_auroc:  0.671875 val_auprc:  0.9162862645556628\n",
      "EarlyStopping counter: 29 out of 50\n",
      "epoch:  47\n",
      "epoch:  48 val_loss:  tensor(0.2494) val_f1:  0.7285714285714285 val_auroc:  0.671875 val_auprc:  0.9162862645556628\n",
      "EarlyStopping counter: 30 out of 50\n",
      "epoch:  48\n",
      "epoch:  49 val_loss:  tensor(0.2495) val_f1:  0.7285714285714285 val_auroc:  0.671875 val_auprc:  0.9162862645556628\n",
      "EarlyStopping counter: 31 out of 50\n",
      "epoch:  49\n",
      "epoch:  50 val_loss:  tensor(0.2495) val_f1:  0.7285714285714285 val_auroc:  0.671875 val_auprc:  0.9162862645556628\n",
      "EarlyStopping counter: 32 out of 50\n",
      "epoch:  50\n",
      "epoch:  51 val_loss:  tensor(0.2496) val_f1:  0.7285714285714285 val_auroc:  0.671875 val_auprc:  0.9162862645556628\n",
      "EarlyStopping counter: 33 out of 50\n",
      "epoch:  51\n",
      "epoch:  52 val_loss:  tensor(0.2497) val_f1:  0.7285714285714285 val_auroc:  0.671875 val_auprc:  0.9162862645556628\n",
      "EarlyStopping counter: 34 out of 50\n",
      "epoch:  52\n",
      "epoch:  53 val_loss:  tensor(0.2498) val_f1:  0.7285714285714285 val_auroc:  0.65625 val_auprc:  0.9089077923334405\n",
      "EarlyStopping counter: 35 out of 50\n",
      "epoch:  53\n",
      "epoch:  54 val_loss:  tensor(0.2499) val_f1:  0.7285714285714285 val_auroc:  0.65625 val_auprc:  0.9089077923334405\n",
      "EarlyStopping counter: 36 out of 50\n",
      "epoch:  54\n",
      "epoch:  55 val_loss:  tensor(0.2500) val_f1:  0.7285714285714285 val_auroc:  0.65625 val_auprc:  0.9089077923334405\n",
      "EarlyStopping counter: 37 out of 50\n",
      "epoch:  55\n",
      "epoch:  56 val_loss:  tensor(0.2502) val_f1:  0.7285714285714285 val_auroc:  0.65625 val_auprc:  0.9089077923334405\n",
      "EarlyStopping counter: 38 out of 50\n",
      "epoch:  56\n",
      "epoch:  57 val_loss:  tensor(0.2503) val_f1:  0.7285714285714285 val_auroc:  0.65625 val_auprc:  0.9089077923334405\n",
      "EarlyStopping counter: 39 out of 50\n",
      "epoch:  57\n",
      "epoch:  58 val_loss:  tensor(0.2504) val_f1:  0.7285714285714285 val_auroc:  0.65625 val_auprc:  0.9089077923334405\n",
      "EarlyStopping counter: 40 out of 50\n",
      "epoch:  58\n",
      "epoch:  59 val_loss:  tensor(0.2505) val_f1:  0.7285714285714285 val_auroc:  0.65625 val_auprc:  0.9089077923334405\n",
      "EarlyStopping counter: 41 out of 50\n",
      "epoch:  59\n",
      "epoch:  60 val_loss:  tensor(0.2506) val_f1:  0.6796238244514107 val_auroc:  0.65625 val_auprc:  0.9089077923334405\n",
      "EarlyStopping counter: 42 out of 50\n",
      "epoch:  60\n",
      "epoch:  61 val_loss:  tensor(0.2507) val_f1:  0.6796238244514107 val_auroc:  0.65625 val_auprc:  0.9089077923334405\n",
      "EarlyStopping counter: 43 out of 50\n",
      "epoch:  61\n",
      "epoch:  62 val_loss:  tensor(0.2509) val_f1:  0.6266666666666667 val_auroc:  0.65625 val_auprc:  0.9089077923334405\n",
      "EarlyStopping counter: 44 out of 50\n",
      "epoch:  62\n",
      "epoch:  63 val_loss:  tensor(0.2510) val_f1:  0.6266666666666667 val_auroc:  0.65625 val_auprc:  0.9089077923334405\n",
      "EarlyStopping counter: 45 out of 50\n",
      "epoch:  63\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  64 val_loss:  tensor(0.2511) val_f1:  0.6266666666666667 val_auroc:  0.65625 val_auprc:  0.9089077923334405\n",
      "EarlyStopping counter: 46 out of 50\n",
      "epoch:  64\n",
      "epoch:  65 val_loss:  tensor(0.2512) val_f1:  0.6266666666666667 val_auroc:  0.65625 val_auprc:  0.9089077923334405\n",
      "EarlyStopping counter: 47 out of 50\n",
      "epoch:  65\n",
      "epoch:  66 val_loss:  tensor(0.2514) val_f1:  0.6266666666666667 val_auroc:  0.65625 val_auprc:  0.9089077923334405\n",
      "EarlyStopping counter: 48 out of 50\n",
      "epoch:  66\n",
      "epoch:  67 val_loss:  tensor(0.2515) val_f1:  0.6266666666666667 val_auroc:  0.65625 val_auprc:  0.9089077923334405\n",
      "EarlyStopping counter: 49 out of 50\n",
      "epoch:  67\n",
      "epoch:  68 val_loss:  tensor(0.2516) val_f1:  0.6266666666666667 val_auroc:  0.65625 val_auprc:  0.9089077923334405\n",
      "EarlyStopping counter: 50 out of 50\n",
      "Early stopping triggered\n",
      "Early stopping triggered!\n",
      "Time taken:  5.928755760192871\n",
      "tensor(0.2381)\n",
      "epoch:  0\n",
      "epoch:  1 val_loss:  tensor(0.2466) val_f1:  0.7699248120300751 val_auroc:  0.3541666666666667 val_auprc:  0.8175321354234861\n",
      "epoch:  1\n",
      "epoch:  2 val_loss:  tensor(0.2628) val_f1:  0.043062200956937795 val_auroc:  0.7083333333333334 val_auprc:  0.9314177238954716\n",
      "EarlyStopping counter: 1 out of 50\n",
      "epoch:  2\n",
      "epoch:  3 val_loss:  tensor(0.2740) val_f1:  0.043062200956937795 val_auroc:  0.7291666666666667 val_auprc:  0.9345580425229225\n",
      "EarlyStopping counter: 2 out of 50\n",
      "epoch:  3\n",
      "epoch:  4 val_loss:  tensor(0.2547) val_f1:  0.043062200956937795 val_auroc:  0.7500000000000001 val_auprc:  0.9381043047778246\n",
      "EarlyStopping counter: 3 out of 50\n",
      "epoch:  4\n",
      "epoch:  5 val_loss:  tensor(0.2374) val_f1:  0.8508367693427116 val_auroc:  0.7500000000000001 val_auprc:  0.9381043047778246\n",
      "Validation loss improved to 0.237405\n",
      "epoch:  5\n",
      "epoch:  6 val_loss:  tensor(0.2378) val_f1:  0.7430340557275542 val_auroc:  0.7500000000000001 val_auprc:  0.9381043047778246\n",
      "EarlyStopping counter: 1 out of 50\n",
      "epoch:  6\n",
      "epoch:  7 val_loss:  tensor(0.2356) val_f1:  0.7430340557275542 val_auroc:  0.7500000000000001 val_auprc:  0.9381043047778246\n",
      "Validation loss improved to 0.235631\n",
      "epoch:  7\n",
      "epoch:  8 val_loss:  tensor(0.2377) val_f1:  0.724812030075188 val_auroc:  0.7500000000000001 val_auprc:  0.9381043047778246\n",
      "EarlyStopping counter: 1 out of 50\n",
      "epoch:  8\n",
      "epoch:  9 val_loss:  tensor(0.2438) val_f1:  0.48146453089244845 val_auroc:  0.7500000000000001 val_auprc:  0.9381043047778246\n",
      "EarlyStopping counter: 2 out of 50\n",
      "epoch:  9\n",
      "epoch:  10 val_loss:  tensor(0.2390) val_f1:  0.681197944355839 val_auroc:  0.7500000000000001 val_auprc:  0.9381043047778246\n",
      "EarlyStopping counter: 3 out of 50\n",
      "epoch:  10\n",
      "epoch:  11 val_loss:  tensor(0.2337) val_f1:  0.7670901391409558 val_auroc:  0.7500000000000001 val_auprc:  0.9381043047778246\n",
      "Validation loss improved to 0.233710\n",
      "epoch:  11\n",
      "epoch:  12 val_loss:  tensor(0.2330) val_f1:  0.8508367693427116 val_auroc:  0.7500000000000001 val_auprc:  0.9381043047778246\n",
      "Validation loss improved to 0.233000\n",
      "epoch:  12\n",
      "epoch:  13 val_loss:  tensor(0.2332) val_f1:  0.724812030075188 val_auroc:  0.7500000000000001 val_auprc:  0.9381043047778246\n",
      "EarlyStopping counter: 1 out of 50\n",
      "epoch:  13\n",
      "epoch:  14 val_loss:  tensor(0.2355) val_f1:  0.724812030075188 val_auroc:  0.7500000000000001 val_auprc:  0.9381043047778246\n",
      "EarlyStopping counter: 2 out of 50\n",
      "epoch:  14\n",
      "epoch:  15 val_loss:  tensor(0.2353) val_f1:  0.724812030075188 val_auroc:  0.7708333333333335 val_auprc:  0.9464748404921103\n",
      "EarlyStopping counter: 3 out of 50\n",
      "epoch:  15\n",
      "epoch:  16 val_loss:  tensor(0.2327) val_f1:  0.724812030075188 val_auroc:  0.75 val_auprc:  0.9429285782372083\n",
      "Validation loss improved to 0.232735\n",
      "epoch:  16\n",
      "epoch:  17 val_loss:  tensor(0.2316) val_f1:  0.7670901391409558 val_auroc:  0.75 val_auprc:  0.9429285782372083\n",
      "Validation loss improved to 0.231627\n",
      "epoch:  17\n",
      "epoch:  18 val_loss:  tensor(0.2317) val_f1:  0.724812030075188 val_auroc:  0.75 val_auprc:  0.9429285782372083\n",
      "EarlyStopping counter: 1 out of 50\n",
      "epoch:  18\n",
      "epoch:  19 val_loss:  tensor(0.2325) val_f1:  0.724812030075188 val_auroc:  0.75 val_auprc:  0.9429285782372083\n",
      "EarlyStopping counter: 2 out of 50\n",
      "epoch:  19\n",
      "epoch:  20 val_loss:  tensor(0.2324) val_f1:  0.724812030075188 val_auroc:  0.7708333333333334 val_auprc:  0.9503070504594305\n",
      "EarlyStopping counter: 3 out of 50\n",
      "epoch:  20\n",
      "epoch:  21 val_loss:  tensor(0.2312) val_f1:  0.724812030075188 val_auroc:  0.7708333333333334 val_auprc:  0.9503070504594305\n",
      "Validation loss improved to 0.231183\n",
      "epoch:  21\n",
      "epoch:  22 val_loss:  tensor(0.2304) val_f1:  0.724812030075188 val_auroc:  0.7708333333333334 val_auprc:  0.9503070504594305\n",
      "Validation loss improved to 0.230414\n",
      "epoch:  22\n",
      "epoch:  23 val_loss:  tensor(0.2303) val_f1:  0.724812030075188 val_auroc:  0.7916666666666667 val_auprc:  0.9569042726816528\n",
      "Validation loss improved to 0.230326\n",
      "epoch:  23\n",
      "epoch:  24 val_loss:  tensor(0.2305) val_f1:  0.724812030075188 val_auroc:  0.7708333333333334 val_auprc:  0.9537639540542018\n",
      "EarlyStopping counter: 1 out of 50\n",
      "epoch:  24\n",
      "epoch:  25 val_loss:  tensor(0.2303) val_f1:  0.724812030075188 val_auroc:  0.7916666666666667 val_auprc:  0.9597298631451109\n",
      "Validation loss improved to 0.230263\n",
      "epoch:  25\n",
      "epoch:  26 val_loss:  tensor(0.2296) val_f1:  0.724812030075188 val_auroc:  0.7916666666666667 val_auprc:  0.9597298631451109\n",
      "Validation loss improved to 0.229572\n",
      "epoch:  26\n",
      "epoch:  27 val_loss:  tensor(0.2291) val_f1:  0.724812030075188 val_auroc:  0.7916666666666667 val_auprc:  0.9597298631451109\n",
      "Validation loss improved to 0.229078\n",
      "epoch:  27\n",
      "epoch:  28 val_loss:  tensor(0.2289) val_f1:  0.724812030075188 val_auroc:  0.7916666666666667 val_auprc:  0.9597298631451109\n",
      "Validation loss improved to 0.228919\n",
      "epoch:  28\n",
      "epoch:  29 val_loss:  tensor(0.2288) val_f1:  0.724812030075188 val_auroc:  0.7916666666666667 val_auprc:  0.9597298631451109\n",
      "Validation loss improved to 0.228824\n",
      "epoch:  29\n",
      "epoch:  30 val_loss:  tensor(0.2285) val_f1:  0.724812030075188 val_auroc:  0.7916666666666667 val_auprc:  0.9597298631451109\n",
      "Validation loss improved to 0.228482\n",
      "epoch:  30\n",
      "epoch:  31 val_loss:  tensor(0.2280) val_f1:  0.724812030075188 val_auroc:  0.7916666666666667 val_auprc:  0.9597298631451109\n",
      "Validation loss improved to 0.227990\n",
      "epoch:  31\n",
      "epoch:  32 val_loss:  tensor(0.2276) val_f1:  0.724812030075188 val_auroc:  0.7916666666666667 val_auprc:  0.9597298631451109\n",
      "Validation loss improved to 0.227620\n",
      "epoch:  32\n",
      "epoch:  33 val_loss:  tensor(0.2274) val_f1:  0.724812030075188 val_auroc:  0.7916666666666667 val_auprc:  0.9597298631451109\n",
      "Validation loss improved to 0.227393\n",
      "epoch:  33\n",
      "epoch:  34 val_loss:  tensor(0.2271) val_f1:  0.724812030075188 val_auroc:  0.7916666666666667 val_auprc:  0.9597298631451109\n",
      "Validation loss improved to 0.227143\n",
      "epoch:  34\n",
      "epoch:  35 val_loss:  tensor(0.2268) val_f1:  0.724812030075188 val_auroc:  0.7916666666666667 val_auprc:  0.9597298631451109\n",
      "Validation loss improved to 0.226767\n",
      "epoch:  35\n",
      "epoch:  36 val_loss:  tensor(0.2264) val_f1:  0.724812030075188 val_auroc:  0.7916666666666667 val_auprc:  0.9597298631451109\n",
      "Validation loss improved to 0.226363\n",
      "epoch:  36\n",
      "epoch:  37 val_loss:  tensor(0.2260) val_f1:  0.724812030075188 val_auroc:  0.7916666666666667 val_auprc:  0.9597298631451109\n",
      "Validation loss improved to 0.226033\n",
      "epoch:  37\n",
      "epoch:  38 val_loss:  tensor(0.2258) val_f1:  0.724812030075188 val_auroc:  0.7916666666666667 val_auprc:  0.9597298631451109\n",
      "Validation loss improved to 0.225753\n",
      "epoch:  38\n",
      "epoch:  39 val_loss:  tensor(0.2254) val_f1:  0.724812030075188 val_auroc:  0.7916666666666667 val_auprc:  0.9597298631451109\n",
      "Validation loss improved to 0.225438\n",
      "epoch:  39\n",
      "epoch:  40 val_loss:  tensor(0.2251) val_f1:  0.724812030075188 val_auroc:  0.7916666666666667 val_auprc:  0.9597298631451109\n",
      "Validation loss improved to 0.225069\n",
      "epoch:  40\n",
      "epoch:  41 val_loss:  tensor(0.2247) val_f1:  0.724812030075188 val_auroc:  0.7916666666666667 val_auprc:  0.9597298631451109\n",
      "Validation loss improved to 0.224700\n",
      "epoch:  41\n",
      "epoch:  42 val_loss:  tensor(0.2244) val_f1:  0.724812030075188 val_auroc:  0.7916666666666667 val_auprc:  0.9597298631451109\n",
      "Validation loss improved to 0.224363\n",
      "epoch:  42\n",
      "epoch:  43 val_loss:  tensor(0.2240) val_f1:  0.724812030075188 val_auroc:  0.7916666666666667 val_auprc:  0.9597298631451109\n",
      "Validation loss improved to 0.224032\n",
      "epoch:  43\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  44 val_loss:  tensor(0.2237) val_f1:  0.724812030075188 val_auroc:  0.7916666666666667 val_auprc:  0.9597298631451109\n",
      "Validation loss improved to 0.223678\n",
      "epoch:  44\n",
      "epoch:  45 val_loss:  tensor(0.2233) val_f1:  0.724812030075188 val_auroc:  0.7916666666666667 val_auprc:  0.9597298631451109\n",
      "Validation loss improved to 0.223312\n",
      "epoch:  45\n",
      "epoch:  46 val_loss:  tensor(0.2230) val_f1:  0.724812030075188 val_auroc:  0.7916666666666667 val_auprc:  0.9597298631451109\n",
      "Validation loss improved to 0.222956\n",
      "epoch:  46\n",
      "epoch:  47 val_loss:  tensor(0.2226) val_f1:  0.724812030075188 val_auroc:  0.7916666666666667 val_auprc:  0.9597298631451109\n",
      "Validation loss improved to 0.222618\n",
      "epoch:  47\n",
      "epoch:  48 val_loss:  tensor(0.2223) val_f1:  0.724812030075188 val_auroc:  0.7916666666666667 val_auprc:  0.9597298631451109\n",
      "Validation loss improved to 0.222279\n",
      "epoch:  48\n",
      "epoch:  49 val_loss:  tensor(0.2219) val_f1:  0.724812030075188 val_auroc:  0.7916666666666667 val_auprc:  0.9597298631451109\n",
      "Validation loss improved to 0.221927\n",
      "epoch:  49\n",
      "epoch:  50 val_loss:  tensor(0.2216) val_f1:  0.724812030075188 val_auroc:  0.7916666666666667 val_auprc:  0.9597298631451109\n",
      "Validation loss improved to 0.221569\n",
      "epoch:  50\n",
      "epoch:  51 val_loss:  tensor(0.2212) val_f1:  0.724812030075188 val_auroc:  0.7916666666666667 val_auprc:  0.9597298631451109\n",
      "Validation loss improved to 0.221217\n",
      "epoch:  51\n",
      "epoch:  52 val_loss:  tensor(0.2209) val_f1:  0.724812030075188 val_auroc:  0.7916666666666667 val_auprc:  0.9597298631451109\n",
      "Validation loss improved to 0.220867\n",
      "epoch:  52\n",
      "epoch:  53 val_loss:  tensor(0.2205) val_f1:  0.724812030075188 val_auroc:  0.7916666666666667 val_auprc:  0.9597298631451109\n",
      "Validation loss improved to 0.220509\n",
      "epoch:  53\n",
      "epoch:  54 val_loss:  tensor(0.2201) val_f1:  0.724812030075188 val_auroc:  0.7708333333333333 val_auprc:  0.9559724226689204\n",
      "Validation loss improved to 0.220143\n",
      "epoch:  54\n",
      "epoch:  55 val_loss:  tensor(0.2198) val_f1:  0.7670901391409558 val_auroc:  0.7708333333333333 val_auprc:  0.9559724226689204\n",
      "Validation loss improved to 0.219776\n",
      "epoch:  55\n",
      "epoch:  56 val_loss:  tensor(0.2194) val_f1:  0.7670901391409558 val_auroc:  0.7708333333333333 val_auprc:  0.9559724226689204\n",
      "Validation loss improved to 0.219410\n",
      "epoch:  56\n",
      "epoch:  57 val_loss:  tensor(0.2190) val_f1:  0.7670901391409558 val_auroc:  0.7708333333333333 val_auprc:  0.9559724226689204\n",
      "Validation loss improved to 0.219044\n",
      "epoch:  57\n",
      "epoch:  58 val_loss:  tensor(0.2187) val_f1:  0.7670901391409558 val_auroc:  0.7708333333333333 val_auprc:  0.9559724226689204\n",
      "Validation loss improved to 0.218671\n",
      "epoch:  58\n",
      "epoch:  59 val_loss:  tensor(0.2183) val_f1:  0.7670901391409558 val_auroc:  0.7708333333333333 val_auprc:  0.9559724226689204\n",
      "Validation loss improved to 0.218292\n",
      "epoch:  59\n",
      "epoch:  60 val_loss:  tensor(0.2179) val_f1:  0.7670901391409558 val_auroc:  0.7916666666666666 val_auprc:  0.9614174984264962\n",
      "Validation loss improved to 0.217907\n",
      "epoch:  60\n",
      "epoch:  61 val_loss:  tensor(0.2175) val_f1:  0.7670901391409558 val_auroc:  0.7916666666666666 val_auprc:  0.9614174984264962\n",
      "Validation loss improved to 0.217514\n",
      "epoch:  61\n",
      "epoch:  62 val_loss:  tensor(0.2171) val_f1:  0.7670901391409558 val_auroc:  0.7916666666666666 val_auprc:  0.9614174984264962\n",
      "Validation loss improved to 0.217113\n",
      "epoch:  62\n",
      "epoch:  63 val_loss:  tensor(0.2167) val_f1:  0.7670901391409558 val_auroc:  0.7916666666666666 val_auprc:  0.9614174984264962\n",
      "Validation loss improved to 0.216702\n",
      "epoch:  63\n",
      "epoch:  64 val_loss:  tensor(0.2163) val_f1:  0.7670901391409558 val_auroc:  0.7916666666666666 val_auprc:  0.9614174984264962\n",
      "Validation loss improved to 0.216286\n",
      "epoch:  64\n",
      "epoch:  65 val_loss:  tensor(0.2159) val_f1:  0.7670901391409558 val_auroc:  0.7916666666666666 val_auprc:  0.9614174984264962\n",
      "Validation loss improved to 0.215867\n",
      "epoch:  65\n",
      "epoch:  66 val_loss:  tensor(0.2154) val_f1:  0.7670901391409558 val_auroc:  0.7916666666666666 val_auprc:  0.9614174984264962\n",
      "Validation loss improved to 0.215443\n",
      "epoch:  66\n",
      "epoch:  67 val_loss:  tensor(0.2150) val_f1:  0.7670901391409558 val_auroc:  0.7916666666666666 val_auprc:  0.9614174984264962\n",
      "Validation loss improved to 0.215013\n",
      "epoch:  67\n",
      "epoch:  68 val_loss:  tensor(0.2146) val_f1:  0.7670901391409558 val_auroc:  0.7916666666666666 val_auprc:  0.9614174984264962\n",
      "Validation loss improved to 0.214575\n",
      "epoch:  68\n",
      "epoch:  69 val_loss:  tensor(0.2141) val_f1:  0.7670901391409558 val_auroc:  0.7916666666666666 val_auprc:  0.9614174984264962\n",
      "Validation loss improved to 0.214133\n",
      "epoch:  69\n",
      "epoch:  70 val_loss:  tensor(0.2137) val_f1:  0.7670901391409558 val_auroc:  0.7916666666666666 val_auprc:  0.9614174984264962\n",
      "Validation loss improved to 0.213688\n",
      "epoch:  70\n",
      "epoch:  71 val_loss:  tensor(0.2132) val_f1:  0.7670901391409558 val_auroc:  0.7916666666666666 val_auprc:  0.9614174984264962\n",
      "Validation loss improved to 0.213238\n",
      "epoch:  71\n",
      "epoch:  72 val_loss:  tensor(0.2128) val_f1:  0.7670901391409558 val_auroc:  0.7916666666666666 val_auprc:  0.9614174984264962\n",
      "Validation loss improved to 0.212781\n",
      "epoch:  72\n",
      "epoch:  73 val_loss:  tensor(0.2123) val_f1:  0.7670901391409558 val_auroc:  0.7916666666666666 val_auprc:  0.9614174984264962\n",
      "Validation loss improved to 0.212315\n",
      "epoch:  73\n",
      "epoch:  74 val_loss:  tensor(0.2118) val_f1:  0.7670901391409558 val_auroc:  0.7916666666666666 val_auprc:  0.9614174984264962\n",
      "Validation loss improved to 0.211843\n",
      "epoch:  74\n",
      "epoch:  75 val_loss:  tensor(0.2114) val_f1:  0.7670901391409558 val_auroc:  0.7916666666666666 val_auprc:  0.9614174984264962\n",
      "Validation loss improved to 0.211364\n",
      "epoch:  75\n",
      "epoch:  76 val_loss:  tensor(0.2109) val_f1:  0.7670901391409558 val_auroc:  0.7916666666666666 val_auprc:  0.9614174984264962\n",
      "Validation loss improved to 0.210880\n",
      "epoch:  76\n",
      "epoch:  77 val_loss:  tensor(0.2104) val_f1:  0.7670901391409558 val_auroc:  0.7916666666666666 val_auprc:  0.9614174984264962\n",
      "Validation loss improved to 0.210389\n",
      "epoch:  77\n",
      "epoch:  78 val_loss:  tensor(0.2099) val_f1:  0.7670901391409558 val_auroc:  0.7916666666666666 val_auprc:  0.9614174984264962\n",
      "Validation loss improved to 0.209892\n",
      "epoch:  78\n",
      "epoch:  79 val_loss:  tensor(0.2094) val_f1:  0.7670901391409558 val_auroc:  0.7916666666666666 val_auprc:  0.9614174984264962\n",
      "Validation loss improved to 0.209388\n",
      "epoch:  79\n",
      "epoch:  80 val_loss:  tensor(0.2089) val_f1:  0.7670901391409558 val_auroc:  0.7916666666666666 val_auprc:  0.9614174984264962\n",
      "Validation loss improved to 0.208879\n",
      "epoch:  80\n",
      "epoch:  81 val_loss:  tensor(0.2084) val_f1:  0.7670901391409558 val_auroc:  0.7916666666666666 val_auprc:  0.9614174984264962\n",
      "Validation loss improved to 0.208365\n",
      "epoch:  81\n",
      "epoch:  82 val_loss:  tensor(0.2078) val_f1:  0.7670901391409558 val_auroc:  0.7916666666666666 val_auprc:  0.9614174984264962\n",
      "Validation loss improved to 0.207848\n",
      "epoch:  82\n",
      "epoch:  83 val_loss:  tensor(0.2073) val_f1:  0.7670901391409558 val_auroc:  0.7916666666666666 val_auprc:  0.9614174984264962\n",
      "Validation loss improved to 0.207328\n",
      "epoch:  83\n",
      "epoch:  84 val_loss:  tensor(0.2068) val_f1:  0.7670901391409558 val_auroc:  0.7916666666666666 val_auprc:  0.9614174984264962\n",
      "Validation loss improved to 0.206802\n",
      "epoch:  84\n",
      "epoch:  85 val_loss:  tensor(0.2063) val_f1:  0.7670901391409558 val_auroc:  0.7916666666666666 val_auprc:  0.9614174984264962\n",
      "Validation loss improved to 0.206269\n",
      "epoch:  85\n",
      "epoch:  86 val_loss:  tensor(0.2057) val_f1:  0.7670901391409558 val_auroc:  0.7916666666666666 val_auprc:  0.9614174984264962\n",
      "Validation loss improved to 0.205732\n",
      "epoch:  86\n",
      "epoch:  87 val_loss:  tensor(0.2052) val_f1:  0.7670901391409558 val_auroc:  0.7916666666666666 val_auprc:  0.9614174984264962\n",
      "Validation loss improved to 0.205191\n",
      "epoch:  87\n",
      "epoch:  88 val_loss:  tensor(0.2046) val_f1:  0.7670901391409558 val_auroc:  0.7916666666666666 val_auprc:  0.9614174984264962\n",
      "Validation loss improved to 0.204644\n",
      "epoch:  88\n",
      "epoch:  89 val_loss:  tensor(0.2041) val_f1:  0.7670901391409558 val_auroc:  0.7916666666666666 val_auprc:  0.9614174984264962\n",
      "Validation loss improved to 0.204091\n",
      "epoch:  89\n",
      "epoch:  90 val_loss:  tensor(0.2035) val_f1:  0.7670901391409558 val_auroc:  0.8125 val_auprc:  0.966425511247009\n",
      "Validation loss improved to 0.203532\n",
      "epoch:  90\n",
      "epoch:  91 val_loss:  tensor(0.2030) val_f1:  0.7670901391409558 val_auroc:  0.8125 val_auprc:  0.966425511247009\n",
      "Validation loss improved to 0.202965\n",
      "epoch:  91\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  92 val_loss:  tensor(0.2024) val_f1:  0.7670901391409558 val_auroc:  0.8125 val_auprc:  0.966425511247009\n",
      "Validation loss improved to 0.202390\n",
      "epoch:  92\n",
      "epoch:  93 val_loss:  tensor(0.2018) val_f1:  0.7670901391409558 val_auroc:  0.8125 val_auprc:  0.966425511247009\n",
      "Validation loss improved to 0.201807\n",
      "epoch:  93\n",
      "epoch:  94 val_loss:  tensor(0.2012) val_f1:  0.7670901391409558 val_auroc:  0.8125 val_auprc:  0.966425511247009\n",
      "Validation loss improved to 0.201220\n",
      "epoch:  94\n",
      "epoch:  95 val_loss:  tensor(0.2006) val_f1:  0.8165413533834586 val_auroc:  0.8125 val_auprc:  0.966425511247009\n",
      "Validation loss improved to 0.200623\n",
      "epoch:  95\n",
      "epoch:  96 val_loss:  tensor(0.2000) val_f1:  0.8165413533834586 val_auroc:  0.8125 val_auprc:  0.966425511247009\n",
      "Validation loss improved to 0.200017\n",
      "epoch:  96\n",
      "epoch:  97 val_loss:  tensor(0.1994) val_f1:  0.8165413533834586 val_auroc:  0.8125 val_auprc:  0.966425511247009\n",
      "Validation loss improved to 0.199403\n",
      "epoch:  97\n",
      "epoch:  98 val_loss:  tensor(0.1988) val_f1:  0.8165413533834586 val_auroc:  0.8125 val_auprc:  0.966425511247009\n",
      "Validation loss improved to 0.198781\n",
      "epoch:  98\n",
      "epoch:  99 val_loss:  tensor(0.1981) val_f1:  0.8165413533834586 val_auroc:  0.8125 val_auprc:  0.966425511247009\n",
      "Validation loss improved to 0.198150\n",
      "epoch:  99\n",
      "epoch:  100 val_loss:  tensor(0.1975) val_f1:  0.8165413533834586 val_auroc:  0.8125 val_auprc:  0.966425511247009\n",
      "Validation loss improved to 0.197509\n",
      "epoch:  100\n",
      "epoch:  101 val_loss:  tensor(0.1969) val_f1:  0.8165413533834586 val_auroc:  0.8125 val_auprc:  0.966425511247009\n",
      "Validation loss improved to 0.196861\n",
      "epoch:  101\n",
      "epoch:  102 val_loss:  tensor(0.1962) val_f1:  0.8165413533834586 val_auroc:  0.8125 val_auprc:  0.966425511247009\n",
      "Validation loss improved to 0.196204\n",
      "epoch:  102\n",
      "epoch:  103 val_loss:  tensor(0.1955) val_f1:  0.8165413533834586 val_auroc:  0.8125 val_auprc:  0.966425511247009\n",
      "Validation loss improved to 0.195541\n",
      "epoch:  103\n",
      "epoch:  104 val_loss:  tensor(0.1949) val_f1:  0.8165413533834586 val_auroc:  0.8125 val_auprc:  0.966425511247009\n",
      "Validation loss improved to 0.194870\n",
      "epoch:  104\n",
      "epoch:  105 val_loss:  tensor(0.1942) val_f1:  0.8165413533834586 val_auroc:  0.8125 val_auprc:  0.966425511247009\n",
      "Validation loss improved to 0.194191\n",
      "epoch:  105\n",
      "epoch:  106 val_loss:  tensor(0.1935) val_f1:  0.8165413533834586 val_auroc:  0.8125 val_auprc:  0.966425511247009\n",
      "Validation loss improved to 0.193502\n",
      "epoch:  106\n",
      "epoch:  107 val_loss:  tensor(0.1928) val_f1:  0.8165413533834586 val_auroc:  0.8125 val_auprc:  0.966425511247009\n",
      "Validation loss improved to 0.192807\n",
      "epoch:  107\n",
      "epoch:  108 val_loss:  tensor(0.1921) val_f1:  0.8165413533834586 val_auroc:  0.8125 val_auprc:  0.966425511247009\n",
      "Validation loss improved to 0.192106\n",
      "epoch:  108\n",
      "epoch:  109 val_loss:  tensor(0.1914) val_f1:  0.8165413533834586 val_auroc:  0.8125 val_auprc:  0.966425511247009\n",
      "Validation loss improved to 0.191397\n",
      "epoch:  109\n",
      "epoch:  110 val_loss:  tensor(0.1907) val_f1:  0.8165413533834586 val_auroc:  0.8125 val_auprc:  0.966425511247009\n",
      "Validation loss improved to 0.190680\n",
      "epoch:  110\n",
      "epoch:  111 val_loss:  tensor(0.1900) val_f1:  0.8165413533834586 val_auroc:  0.8125 val_auprc:  0.966425511247009\n",
      "Validation loss improved to 0.189956\n",
      "epoch:  111\n",
      "epoch:  112 val_loss:  tensor(0.1892) val_f1:  0.8165413533834586 val_auroc:  0.8125 val_auprc:  0.966425511247009\n",
      "Validation loss improved to 0.189226\n",
      "epoch:  112\n",
      "epoch:  113 val_loss:  tensor(0.1885) val_f1:  0.8165413533834586 val_auroc:  0.8125 val_auprc:  0.966425511247009\n",
      "Validation loss improved to 0.188489\n",
      "epoch:  113\n",
      "epoch:  114 val_loss:  tensor(0.1877) val_f1:  0.8165413533834586 val_auroc:  0.8125 val_auprc:  0.966425511247009\n",
      "Validation loss improved to 0.187743\n",
      "epoch:  114\n",
      "epoch:  115 val_loss:  tensor(0.1870) val_f1:  0.8165413533834586 val_auroc:  0.8333333333333333 val_auprc:  0.971061500257998\n",
      "Validation loss improved to 0.186991\n",
      "epoch:  115\n",
      "epoch:  116 val_loss:  tensor(0.1862) val_f1:  0.8165413533834586 val_auroc:  0.8333333333333333 val_auprc:  0.971061500257998\n",
      "Validation loss improved to 0.186230\n",
      "epoch:  116\n",
      "epoch:  117 val_loss:  tensor(0.1855) val_f1:  0.8165413533834586 val_auroc:  0.8333333333333333 val_auprc:  0.971061500257998\n",
      "Validation loss improved to 0.185463\n",
      "epoch:  117\n",
      "epoch:  118 val_loss:  tensor(0.1847) val_f1:  0.8165413533834586 val_auroc:  0.8541666666666667 val_auprc:  0.9742018188854489\n",
      "Validation loss improved to 0.184691\n",
      "epoch:  118\n",
      "epoch:  119 val_loss:  tensor(0.1839) val_f1:  0.8165413533834586 val_auroc:  0.8541666666666667 val_auprc:  0.9742018188854489\n",
      "Validation loss improved to 0.183913\n",
      "epoch:  119\n",
      "epoch:  120 val_loss:  tensor(0.1831) val_f1:  0.8165413533834586 val_auroc:  0.8541666666666667 val_auprc:  0.9742018188854489\n",
      "Validation loss improved to 0.183127\n",
      "epoch:  120\n",
      "epoch:  121 val_loss:  tensor(0.1823) val_f1:  0.8165413533834586 val_auroc:  0.8541666666666667 val_auprc:  0.9742018188854489\n",
      "Validation loss improved to 0.182334\n",
      "epoch:  121\n",
      "epoch:  122 val_loss:  tensor(0.1815) val_f1:  0.8165413533834586 val_auroc:  0.8541666666666667 val_auprc:  0.9742018188854489\n",
      "Validation loss improved to 0.181535\n",
      "epoch:  122\n",
      "epoch:  123 val_loss:  tensor(0.1807) val_f1:  0.8165413533834586 val_auroc:  0.8541666666666667 val_auprc:  0.9742018188854489\n",
      "Validation loss improved to 0.180732\n",
      "epoch:  123\n",
      "epoch:  124 val_loss:  tensor(0.1799) val_f1:  0.8165413533834586 val_auroc:  0.8541666666666667 val_auprc:  0.9742018188854489\n",
      "Validation loss improved to 0.179923\n",
      "epoch:  124\n",
      "epoch:  125 val_loss:  tensor(0.1791) val_f1:  0.8165413533834586 val_auroc:  0.8541666666666667 val_auprc:  0.9742018188854489\n",
      "Validation loss improved to 0.179108\n",
      "epoch:  125\n",
      "epoch:  126 val_loss:  tensor(0.1783) val_f1:  0.8165413533834586 val_auroc:  0.8541666666666667 val_auprc:  0.9742018188854489\n",
      "Validation loss improved to 0.178288\n",
      "epoch:  126\n",
      "epoch:  127 val_loss:  tensor(0.1775) val_f1:  0.8165413533834586 val_auroc:  0.8541666666666667 val_auprc:  0.9742018188854489\n",
      "Validation loss improved to 0.177465\n",
      "epoch:  127\n",
      "epoch:  128 val_loss:  tensor(0.1766) val_f1:  0.8165413533834586 val_auroc:  0.8541666666666667 val_auprc:  0.9742018188854489\n",
      "Validation loss improved to 0.176638\n",
      "epoch:  128\n",
      "epoch:  129 val_loss:  tensor(0.1758) val_f1:  0.8165413533834586 val_auroc:  0.8541666666666667 val_auprc:  0.9742018188854489\n",
      "Validation loss improved to 0.175807\n",
      "epoch:  129\n",
      "epoch:  130 val_loss:  tensor(0.1750) val_f1:  0.8165413533834586 val_auroc:  0.8958333333333333 val_auprc:  0.9822747355521155\n",
      "Validation loss improved to 0.174971\n",
      "epoch:  130\n",
      "epoch:  131 val_loss:  tensor(0.1741) val_f1:  0.8165413533834586 val_auroc:  0.8958333333333333 val_auprc:  0.9822747355521155\n",
      "Validation loss improved to 0.174130\n",
      "epoch:  131\n",
      "epoch:  132 val_loss:  tensor(0.1733) val_f1:  0.8165413533834586 val_auroc:  0.8958333333333333 val_auprc:  0.9822747355521155\n",
      "Validation loss improved to 0.173286\n",
      "epoch:  132\n",
      "epoch:  133 val_loss:  tensor(0.1724) val_f1:  0.8165413533834586 val_auroc:  0.8958333333333333 val_auprc:  0.9822747355521155\n",
      "Validation loss improved to 0.172440\n",
      "epoch:  133\n",
      "epoch:  134 val_loss:  tensor(0.1716) val_f1:  0.8165413533834586 val_auroc:  0.8958333333333333 val_auprc:  0.9822747355521155\n",
      "Validation loss improved to 0.171590\n",
      "epoch:  134\n",
      "epoch:  135 val_loss:  tensor(0.1707) val_f1:  0.8165413533834586 val_auroc:  0.8958333333333333 val_auprc:  0.9822747355521155\n",
      "Validation loss improved to 0.170735\n",
      "epoch:  135\n",
      "epoch:  136 val_loss:  tensor(0.1699) val_f1:  0.8165413533834586 val_auroc:  0.8958333333333333 val_auprc:  0.9822747355521155\n",
      "Validation loss improved to 0.169877\n",
      "epoch:  136\n",
      "epoch:  137 val_loss:  tensor(0.1690) val_f1:  0.8165413533834586 val_auroc:  0.8958333333333333 val_auprc:  0.9822747355521155\n",
      "Validation loss improved to 0.169016\n",
      "epoch:  137\n",
      "epoch:  138 val_loss:  tensor(0.1682) val_f1:  0.8165413533834586 val_auroc:  0.8958333333333333 val_auprc:  0.9822747355521155\n",
      "Validation loss improved to 0.168154\n",
      "epoch:  138\n",
      "epoch:  139 val_loss:  tensor(0.1673) val_f1:  0.8165413533834586 val_auroc:  0.8958333333333333 val_auprc:  0.9822747355521155\n",
      "Validation loss improved to 0.167289\n",
      "epoch:  139\n",
      "epoch:  140 val_loss:  tensor(0.1664) val_f1:  0.8165413533834586 val_auroc:  0.9166666666666667 val_auprc:  0.9858209978070176\n",
      "Validation loss improved to 0.166422\n",
      "epoch:  140\n",
      "epoch:  141 val_loss:  tensor(0.1656) val_f1:  0.8165413533834586 val_auroc:  0.9166666666666667 val_auprc:  0.9858209978070176\n",
      "Validation loss improved to 0.165554\n",
      "epoch:  141\n",
      "epoch:  142 val_loss:  tensor(0.1647) val_f1:  0.8165413533834586 val_auroc:  0.9166666666666667 val_auprc:  0.9858209978070176\n",
      "Validation loss improved to 0.164684\n",
      "epoch:  142\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  143 val_loss:  tensor(0.1638) val_f1:  0.8165413533834586 val_auroc:  0.9166666666666667 val_auprc:  0.9858209978070176\n",
      "Validation loss improved to 0.163811\n",
      "epoch:  143\n",
      "epoch:  144 val_loss:  tensor(0.1629) val_f1:  0.8165413533834586 val_auroc:  0.9166666666666667 val_auprc:  0.9858209978070176\n",
      "Validation loss improved to 0.162938\n",
      "epoch:  144\n",
      "epoch:  145 val_loss:  tensor(0.1621) val_f1:  0.8165413533834586 val_auroc:  0.9166666666666667 val_auprc:  0.9858209978070176\n",
      "Validation loss improved to 0.162063\n",
      "epoch:  145\n",
      "epoch:  146 val_loss:  tensor(0.1612) val_f1:  0.8165413533834586 val_auroc:  0.9166666666666667 val_auprc:  0.9858209978070176\n",
      "Validation loss improved to 0.161187\n",
      "epoch:  146\n",
      "epoch:  147 val_loss:  tensor(0.1603) val_f1:  0.8165413533834586 val_auroc:  0.9166666666666667 val_auprc:  0.9858209978070176\n",
      "Validation loss improved to 0.160310\n",
      "epoch:  147\n",
      "epoch:  148 val_loss:  tensor(0.1594) val_f1:  0.8165413533834586 val_auroc:  0.9166666666666667 val_auprc:  0.9858209978070176\n",
      "Validation loss improved to 0.159434\n",
      "epoch:  148\n",
      "epoch:  149 val_loss:  tensor(0.1586) val_f1:  0.8165413533834586 val_auroc:  0.9166666666666667 val_auprc:  0.9858209978070176\n",
      "Validation loss improved to 0.158558\n",
      "epoch:  149\n",
      "epoch:  150 val_loss:  tensor(0.1577) val_f1:  0.8165413533834586 val_auroc:  0.9166666666666667 val_auprc:  0.9858209978070176\n",
      "Validation loss improved to 0.157683\n",
      "epoch:  150\n",
      "epoch:  151 val_loss:  tensor(0.1568) val_f1:  0.8165413533834586 val_auroc:  0.9166666666666667 val_auprc:  0.9858209978070176\n",
      "Validation loss improved to 0.156810\n",
      "epoch:  151\n",
      "epoch:  152 val_loss:  tensor(0.1559) val_f1:  0.8165413533834586 val_auroc:  0.9166666666666667 val_auprc:  0.9858209978070176\n",
      "Validation loss improved to 0.155938\n",
      "epoch:  152\n",
      "epoch:  153 val_loss:  tensor(0.1551) val_f1:  0.8165413533834586 val_auroc:  0.9166666666666667 val_auprc:  0.9858209978070176\n",
      "Validation loss improved to 0.155065\n",
      "epoch:  153\n",
      "epoch:  154 val_loss:  tensor(0.1542) val_f1:  0.8165413533834586 val_auroc:  0.9166666666666667 val_auprc:  0.9858209978070176\n",
      "Validation loss improved to 0.154193\n",
      "epoch:  154\n",
      "epoch:  155 val_loss:  tensor(0.1533) val_f1:  0.8165413533834586 val_auroc:  0.9166666666666667 val_auprc:  0.9858209978070176\n",
      "Validation loss improved to 0.153325\n",
      "epoch:  155\n",
      "epoch:  156 val_loss:  tensor(0.1525) val_f1:  0.8165413533834586 val_auroc:  0.9166666666666667 val_auprc:  0.9858209978070176\n",
      "Validation loss improved to 0.152461\n",
      "epoch:  156\n",
      "epoch:  157 val_loss:  tensor(0.1516) val_f1:  0.8165413533834586 val_auroc:  0.9166666666666667 val_auprc:  0.9858209978070176\n",
      "Validation loss improved to 0.151602\n",
      "epoch:  157\n",
      "epoch:  158 val_loss:  tensor(0.1507) val_f1:  0.8165413533834586 val_auroc:  0.9166666666666667 val_auprc:  0.9858209978070176\n",
      "Validation loss improved to 0.150747\n",
      "epoch:  158\n",
      "epoch:  159 val_loss:  tensor(0.1499) val_f1:  0.8165413533834586 val_auroc:  0.9166666666666667 val_auprc:  0.9858209978070176\n",
      "Validation loss improved to 0.149895\n",
      "epoch:  159\n",
      "epoch:  160 val_loss:  tensor(0.1490) val_f1:  0.8165413533834586 val_auroc:  0.9166666666666667 val_auprc:  0.9858209978070176\n",
      "Validation loss improved to 0.149048\n",
      "epoch:  160\n",
      "epoch:  161 val_loss:  tensor(0.1482) val_f1:  0.8165413533834586 val_auroc:  0.9166666666666667 val_auprc:  0.9858209978070176\n",
      "Validation loss improved to 0.148205\n",
      "epoch:  161\n",
      "epoch:  162 val_loss:  tensor(0.1474) val_f1:  0.8165413533834586 val_auroc:  0.9166666666666667 val_auprc:  0.9858209978070176\n",
      "Validation loss improved to 0.147364\n",
      "epoch:  162\n",
      "epoch:  163 val_loss:  tensor(0.1465) val_f1:  0.8165413533834586 val_auroc:  0.9166666666666667 val_auprc:  0.9858209978070176\n",
      "Validation loss improved to 0.146527\n",
      "epoch:  163\n",
      "epoch:  164 val_loss:  tensor(0.1457) val_f1:  0.8165413533834586 val_auroc:  0.9166666666666667 val_auprc:  0.9858209978070176\n",
      "Validation loss improved to 0.145696\n",
      "epoch:  164\n",
      "epoch:  165 val_loss:  tensor(0.1449) val_f1:  0.8165413533834586 val_auroc:  0.9375 val_auprc:  0.9898574561403508\n",
      "Validation loss improved to 0.144871\n",
      "epoch:  165\n",
      "epoch:  166 val_loss:  tensor(0.1440) val_f1:  0.8165413533834586 val_auroc:  0.9375 val_auprc:  0.9898574561403508\n",
      "Validation loss improved to 0.144049\n",
      "epoch:  166\n",
      "epoch:  167 val_loss:  tensor(0.1432) val_f1:  0.8165413533834586 val_auroc:  0.9375 val_auprc:  0.9898574561403508\n",
      "Validation loss improved to 0.143230\n",
      "epoch:  167\n",
      "epoch:  168 val_loss:  tensor(0.1424) val_f1:  0.8165413533834586 val_auroc:  0.9375 val_auprc:  0.9898574561403508\n",
      "Validation loss improved to 0.142419\n",
      "epoch:  168\n",
      "epoch:  169 val_loss:  tensor(0.1416) val_f1:  0.8165413533834586 val_auroc:  0.9375 val_auprc:  0.9898574561403508\n",
      "Validation loss improved to 0.141618\n",
      "epoch:  169\n",
      "epoch:  170 val_loss:  tensor(0.1408) val_f1:  0.8165413533834586 val_auroc:  0.9375 val_auprc:  0.9898574561403508\n",
      "Validation loss improved to 0.140824\n",
      "epoch:  170\n",
      "epoch:  171 val_loss:  tensor(0.1400) val_f1:  0.8165413533834586 val_auroc:  0.9375 val_auprc:  0.9898574561403508\n",
      "Validation loss improved to 0.140034\n",
      "epoch:  171\n",
      "epoch:  172 val_loss:  tensor(0.1392) val_f1:  0.8165413533834586 val_auroc:  0.9375 val_auprc:  0.9898574561403508\n",
      "Validation loss improved to 0.139248\n",
      "epoch:  172\n",
      "epoch:  173 val_loss:  tensor(0.1385) val_f1:  0.8602540834845736 val_auroc:  0.9375 val_auprc:  0.9898574561403508\n",
      "Validation loss improved to 0.138468\n",
      "epoch:  173\n",
      "epoch:  174 val_loss:  tensor(0.1377) val_f1:  0.8602540834845736 val_auroc:  0.9375 val_auprc:  0.9898574561403508\n",
      "Validation loss improved to 0.137695\n",
      "epoch:  174\n",
      "epoch:  175 val_loss:  tensor(0.1369) val_f1:  0.8602540834845736 val_auroc:  0.9375 val_auprc:  0.9898574561403508\n",
      "Validation loss improved to 0.136930\n",
      "epoch:  175\n",
      "epoch:  176 val_loss:  tensor(0.1362) val_f1:  0.8602540834845736 val_auroc:  0.9375 val_auprc:  0.9898574561403508\n",
      "Validation loss improved to 0.136170\n",
      "epoch:  176\n",
      "epoch:  177 val_loss:  tensor(0.1354) val_f1:  0.8602540834845736 val_auroc:  0.9375 val_auprc:  0.9898574561403508\n",
      "Validation loss improved to 0.135418\n",
      "epoch:  177\n",
      "epoch:  178 val_loss:  tensor(0.1347) val_f1:  0.8602540834845736 val_auroc:  0.9375 val_auprc:  0.9898574561403508\n",
      "Validation loss improved to 0.134674\n",
      "epoch:  178\n",
      "epoch:  179 val_loss:  tensor(0.1339) val_f1:  0.8602540834845736 val_auroc:  0.9375 val_auprc:  0.9898574561403508\n",
      "Validation loss improved to 0.133936\n",
      "epoch:  179\n",
      "epoch:  180 val_loss:  tensor(0.1332) val_f1:  0.8602540834845736 val_auroc:  0.9375 val_auprc:  0.9898574561403508\n",
      "Validation loss improved to 0.133207\n",
      "epoch:  180\n",
      "epoch:  181 val_loss:  tensor(0.1325) val_f1:  0.8602540834845736 val_auroc:  0.9375 val_auprc:  0.9898574561403508\n",
      "Validation loss improved to 0.132486\n",
      "epoch:  181\n",
      "epoch:  182 val_loss:  tensor(0.1318) val_f1:  0.8602540834845736 val_auroc:  0.9375 val_auprc:  0.9898574561403508\n",
      "Validation loss improved to 0.131776\n",
      "epoch:  182\n",
      "epoch:  183 val_loss:  tensor(0.1311) val_f1:  0.8602540834845736 val_auroc:  0.9375 val_auprc:  0.9898574561403508\n",
      "Validation loss improved to 0.131072\n",
      "epoch:  183\n",
      "epoch:  184 val_loss:  tensor(0.1304) val_f1:  0.8602540834845736 val_auroc:  0.9375 val_auprc:  0.9898574561403508\n",
      "Validation loss improved to 0.130375\n",
      "epoch:  184\n",
      "epoch:  185 val_loss:  tensor(0.1297) val_f1:  0.8602540834845736 val_auroc:  0.9375 val_auprc:  0.9898574561403508\n",
      "Validation loss improved to 0.129684\n",
      "epoch:  185\n",
      "epoch:  186 val_loss:  tensor(0.1290) val_f1:  0.8602540834845736 val_auroc:  0.9375 val_auprc:  0.9898574561403508\n",
      "Validation loss improved to 0.129001\n",
      "epoch:  186\n",
      "epoch:  187 val_loss:  tensor(0.1283) val_f1:  0.8602540834845736 val_auroc:  0.9375 val_auprc:  0.9898574561403508\n",
      "Validation loss improved to 0.128327\n",
      "epoch:  187\n",
      "epoch:  188 val_loss:  tensor(0.1277) val_f1:  0.8602540834845736 val_auroc:  0.9375 val_auprc:  0.9898574561403508\n",
      "Validation loss improved to 0.127660\n",
      "epoch:  188\n",
      "epoch:  189 val_loss:  tensor(0.1270) val_f1:  0.8602540834845736 val_auroc:  0.9375 val_auprc:  0.9898574561403508\n",
      "Validation loss improved to 0.127002\n",
      "epoch:  189\n",
      "epoch:  190 val_loss:  tensor(0.1264) val_f1:  0.8602540834845736 val_auroc:  0.9375 val_auprc:  0.9898574561403508\n",
      "Validation loss improved to 0.126352\n",
      "epoch:  190\n",
      "epoch:  191 val_loss:  tensor(0.1257) val_f1:  0.8602540834845736 val_auroc:  0.9375 val_auprc:  0.9898574561403508\n",
      "Validation loss improved to 0.125712\n",
      "epoch:  191\n",
      "epoch:  192 val_loss:  tensor(0.1251) val_f1:  0.8602540834845736 val_auroc:  0.9375 val_auprc:  0.9898574561403508\n",
      "Validation loss improved to 0.125081\n",
      "epoch:  192\n",
      "epoch:  193 val_loss:  tensor(0.1245) val_f1:  0.8602540834845736 val_auroc:  0.9375 val_auprc:  0.9898574561403508\n",
      "Validation loss improved to 0.124458\n",
      "epoch:  193\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  194 val_loss:  tensor(0.1238) val_f1:  0.8602540834845736 val_auroc:  0.9375 val_auprc:  0.9898574561403508\n",
      "Validation loss improved to 0.123843\n",
      "epoch:  194\n",
      "epoch:  195 val_loss:  tensor(0.1232) val_f1:  0.8602540834845736 val_auroc:  0.9375 val_auprc:  0.9898574561403508\n",
      "Validation loss improved to 0.123234\n",
      "epoch:  195\n",
      "epoch:  196 val_loss:  tensor(0.1226) val_f1:  0.8602540834845736 val_auroc:  0.9375 val_auprc:  0.9898574561403508\n",
      "Validation loss improved to 0.122631\n",
      "epoch:  196\n",
      "epoch:  197 val_loss:  tensor(0.1220) val_f1:  0.8602540834845736 val_auroc:  0.9375 val_auprc:  0.9898574561403508\n",
      "Validation loss improved to 0.122038\n",
      "epoch:  197\n",
      "epoch:  198 val_loss:  tensor(0.1215) val_f1:  0.8602540834845736 val_auroc:  0.9375 val_auprc:  0.9898574561403508\n",
      "Validation loss improved to 0.121458\n",
      "epoch:  198\n",
      "epoch:  199 val_loss:  tensor(0.1209) val_f1:  0.8602540834845736 val_auroc:  0.9375 val_auprc:  0.9898574561403508\n",
      "Validation loss improved to 0.120888\n",
      "epoch:  199\n",
      "epoch:  200 val_loss:  tensor(0.1203) val_f1:  0.8602540834845736 val_auroc:  0.9375 val_auprc:  0.9898574561403508\n",
      "Validation loss improved to 0.120325\n",
      "Time taken:  17.303699016571045\n",
      "tensor(0.2381)\n",
      "epoch:  0\n",
      "epoch:  1 val_loss:  tensor(0.2474) val_f1:  0.7699248120300751 val_auroc:  0.25 val_auprc:  0.8042047510023516\n",
      "epoch:  1\n",
      "epoch:  2 val_loss:  tensor(0.2619) val_f1:  0.7699248120300751 val_auroc:  0.4791666666666667 val_auprc:  0.8251072808662786\n",
      "EarlyStopping counter: 1 out of 50\n",
      "epoch:  2\n",
      "epoch:  3 val_loss:  tensor(0.2514) val_f1:  0.7699248120300751 val_auroc:  0.5 val_auprc:  0.8304418768258744\n",
      "EarlyStopping counter: 2 out of 50\n",
      "epoch:  3\n",
      "epoch:  4 val_loss:  tensor(0.2666) val_f1:  0.14418398938522778 val_auroc:  0.5 val_auprc:  0.8304418768258744\n",
      "EarlyStopping counter: 3 out of 50\n",
      "epoch:  4\n",
      "epoch:  5 val_loss:  tensor(0.3101) val_f1:  0.14418398938522778 val_auroc:  0.5 val_auprc:  0.8304418768258744\n",
      "EarlyStopping counter: 4 out of 50\n",
      "epoch:  5\n",
      "epoch:  6 val_loss:  tensor(0.3011) val_f1:  0.14418398938522778 val_auroc:  0.5 val_auprc:  0.8304418768258744\n",
      "EarlyStopping counter: 5 out of 50\n",
      "epoch:  6\n",
      "epoch:  7 val_loss:  tensor(0.2652) val_f1:  0.12514619883040937 val_auroc:  0.5 val_auprc:  0.8304418768258744\n",
      "EarlyStopping counter: 6 out of 50\n",
      "epoch:  7\n",
      "epoch:  8 val_loss:  tensor(0.2528) val_f1:  0.6356275303643725 val_auroc:  0.5 val_auprc:  0.8304418768258744\n",
      "EarlyStopping counter: 7 out of 50\n",
      "epoch:  8\n",
      "epoch:  9 val_loss:  tensor(0.2531) val_f1:  0.5875303643724696 val_auroc:  0.5 val_auprc:  0.8304418768258744\n",
      "EarlyStopping counter: 8 out of 50\n",
      "epoch:  9\n",
      "epoch:  10 val_loss:  tensor(0.2619) val_f1:  0.21052631578947367 val_auroc:  0.5 val_auprc:  0.8304418768258744\n",
      "EarlyStopping counter: 9 out of 50\n",
      "epoch:  10\n",
      "epoch:  11 val_loss:  tensor(0.2745) val_f1:  0.14418398938522778 val_auroc:  0.5 val_auprc:  0.8304418768258744\n",
      "EarlyStopping counter: 10 out of 50\n",
      "epoch:  11\n",
      "epoch:  12 val_loss:  tensor(0.2727) val_f1:  0.14418398938522778 val_auroc:  0.5 val_auprc:  0.8304418768258744\n",
      "EarlyStopping counter: 11 out of 50\n",
      "epoch:  12\n",
      "epoch:  13 val_loss:  tensor(0.2616) val_f1:  0.21052631578947367 val_auroc:  0.5 val_auprc:  0.8304418768258744\n",
      "EarlyStopping counter: 12 out of 50\n",
      "epoch:  13\n",
      "epoch:  14 val_loss:  tensor(0.2551) val_f1:  0.48146453089244845 val_auroc:  0.4791666666666667 val_auprc:  0.8251072808662786\n",
      "EarlyStopping counter: 13 out of 50\n",
      "epoch:  14\n",
      "epoch:  15 val_loss:  tensor(0.2545) val_f1:  0.48146453089244845 val_auroc:  0.4791666666666667 val_auprc:  0.8251072808662786\n",
      "EarlyStopping counter: 14 out of 50\n",
      "epoch:  15\n",
      "epoch:  16 val_loss:  tensor(0.2577) val_f1:  0.357953707798909 val_auroc:  0.4791666666666667 val_auprc:  0.8251072808662786\n",
      "EarlyStopping counter: 15 out of 50\n",
      "epoch:  16\n",
      "epoch:  17 val_loss:  tensor(0.2610) val_f1:  0.21052631578947367 val_auroc:  0.45833333333333337 val_auprc:  0.8192913086440563\n",
      "EarlyStopping counter: 16 out of 50\n",
      "epoch:  17\n",
      "epoch:  18 val_loss:  tensor(0.2602) val_f1:  0.21052631578947367 val_auroc:  0.45833333333333337 val_auprc:  0.8192913086440563\n",
      "EarlyStopping counter: 17 out of 50\n",
      "epoch:  18\n",
      "epoch:  19 val_loss:  tensor(0.2565) val_f1:  0.28771929824561404 val_auroc:  0.45833333333333337 val_auprc:  0.8192913086440563\n",
      "EarlyStopping counter: 18 out of 50\n",
      "epoch:  19\n",
      "epoch:  20 val_loss:  tensor(0.2537) val_f1:  0.357953707798909 val_auroc:  0.45833333333333337 val_auprc:  0.8192913086440563\n",
      "EarlyStopping counter: 19 out of 50\n",
      "epoch:  20\n",
      "epoch:  21 val_loss:  tensor(0.2530) val_f1:  0.4222488038277512 val_auroc:  0.45833333333333337 val_auprc:  0.8192913086440563\n",
      "EarlyStopping counter: 20 out of 50\n",
      "epoch:  21\n",
      "epoch:  22 val_loss:  tensor(0.2538) val_f1:  0.357953707798909 val_auroc:  0.45833333333333337 val_auprc:  0.8192913086440563\n",
      "EarlyStopping counter: 21 out of 50\n",
      "epoch:  22\n",
      "epoch:  23 val_loss:  tensor(0.2544) val_f1:  0.28771929824561404 val_auroc:  0.47916666666666674 val_auprc:  0.8224316272715073\n",
      "EarlyStopping counter: 22 out of 50\n",
      "epoch:  23\n",
      "epoch:  24 val_loss:  tensor(0.2539) val_f1:  0.28771929824561404 val_auroc:  0.47916666666666674 val_auprc:  0.8224316272715073\n",
      "EarlyStopping counter: 23 out of 50\n",
      "epoch:  24\n",
      "epoch:  25 val_loss:  tensor(0.2525) val_f1:  0.357953707798909 val_auroc:  0.47916666666666674 val_auprc:  0.8224316272715073\n",
      "EarlyStopping counter: 24 out of 50\n",
      "epoch:  25\n",
      "epoch:  26 val_loss:  tensor(0.2512) val_f1:  0.48146453089244845 val_auroc:  0.47916666666666674 val_auprc:  0.8224316272715073\n",
      "EarlyStopping counter: 25 out of 50\n",
      "epoch:  26\n",
      "epoch:  27 val_loss:  tensor(0.2506) val_f1:  0.5363408521303259 val_auroc:  0.47916666666666674 val_auprc:  0.8224316272715073\n",
      "EarlyStopping counter: 26 out of 50\n",
      "epoch:  27\n",
      "epoch:  28 val_loss:  tensor(0.2506) val_f1:  0.5363408521303259 val_auroc:  0.47916666666666674 val_auprc:  0.8224316272715073\n",
      "EarlyStopping counter: 27 out of 50\n",
      "epoch:  28\n",
      "epoch:  29 val_loss:  tensor(0.2505) val_f1:  0.48146453089244845 val_auroc:  0.47916666666666674 val_auprc:  0.8224316272715073\n",
      "EarlyStopping counter: 28 out of 50\n",
      "epoch:  29\n",
      "epoch:  30 val_loss:  tensor(0.2501) val_f1:  0.48146453089244845 val_auroc:  0.5 val_auprc:  0.8254254783206989\n",
      "EarlyStopping counter: 29 out of 50\n",
      "epoch:  30\n",
      "epoch:  31 val_loss:  tensor(0.2494) val_f1:  0.5363408521303259 val_auroc:  0.5 val_auprc:  0.8254254783206989\n",
      "EarlyStopping counter: 30 out of 50\n",
      "epoch:  31\n",
      "epoch:  32 val_loss:  tensor(0.2487) val_f1:  0.5445344129554656 val_auroc:  0.5 val_auprc:  0.8254254783206989\n",
      "EarlyStopping counter: 31 out of 50\n",
      "epoch:  32\n",
      "epoch:  33 val_loss:  tensor(0.2483) val_f1:  0.5445344129554656 val_auroc:  0.5 val_auprc:  0.8254254783206989\n",
      "EarlyStopping counter: 32 out of 50\n",
      "epoch:  33\n",
      "epoch:  34 val_loss:  tensor(0.2480) val_f1:  0.5445344129554656 val_auroc:  0.5 val_auprc:  0.8254254783206989\n",
      "EarlyStopping counter: 33 out of 50\n",
      "epoch:  34\n",
      "epoch:  35 val_loss:  tensor(0.2477) val_f1:  0.5901116427432216 val_auroc:  0.5 val_auprc:  0.8254254783206989\n",
      "EarlyStopping counter: 34 out of 50\n",
      "epoch:  35\n",
      "epoch:  36 val_loss:  tensor(0.2474) val_f1:  0.6330827067669172 val_auroc:  0.45833333333333337 val_auprc:  0.7721640695905402\n",
      "Validation loss improved to 0.247367\n",
      "epoch:  36\n",
      "epoch:  37 val_loss:  tensor(0.2469) val_f1:  0.6330827067669172 val_auroc:  0.45833333333333337 val_auprc:  0.7721640695905402\n",
      "Validation loss improved to 0.246921\n",
      "epoch:  37\n",
      "epoch:  38 val_loss:  tensor(0.2465) val_f1:  0.6739261947973381 val_auroc:  0.4375 val_auprc:  0.7650956172095879\n",
      "Validation loss improved to 0.246486\n",
      "epoch:  38\n",
      "epoch:  39 val_loss:  tensor(0.2461) val_f1:  0.7131578947368421 val_auroc:  0.4375 val_auprc:  0.7650956172095879\n",
      "Validation loss improved to 0.246126\n",
      "epoch:  39\n",
      "epoch:  40 val_loss:  tensor(0.2458) val_f1:  0.7131578947368421 val_auroc:  0.45833333333333337 val_auprc:  0.8119706172095879\n",
      "Validation loss improved to 0.245826\n",
      "epoch:  40\n",
      "epoch:  41 val_loss:  tensor(0.2455) val_f1:  0.7131578947368421 val_auroc:  0.45833333333333337 val_auprc:  0.8119706172095879\n",
      "Validation loss improved to 0.245532\n",
      "epoch:  41\n",
      "epoch:  42 val_loss:  tensor(0.2452) val_f1:  0.751394615571186 val_auroc:  0.45833333333333337 val_auprc:  0.8119706172095879\n",
      "Validation loss improved to 0.245208\n",
      "epoch:  42\n",
      "epoch:  43 val_loss:  tensor(0.2449) val_f1:  0.751394615571186 val_auroc:  0.4375 val_auprc:  0.8040837124476831\n",
      "Validation loss improved to 0.244859\n",
      "epoch:  43\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  44 val_loss:  tensor(0.2445) val_f1:  0.751394615571186 val_auroc:  0.4375 val_auprc:  0.8040837124476831\n",
      "Validation loss improved to 0.244515\n",
      "epoch:  44\n",
      "epoch:  45 val_loss:  tensor(0.2442) val_f1:  0.751394615571186 val_auroc:  0.4375 val_auprc:  0.8040837124476831\n",
      "Validation loss improved to 0.244194\n",
      "epoch:  45\n",
      "epoch:  46 val_loss:  tensor(0.2439) val_f1:  0.751394615571186 val_auroc:  0.4375 val_auprc:  0.8040837124476831\n",
      "Validation loss improved to 0.243895\n",
      "epoch:  46\n",
      "epoch:  47 val_loss:  tensor(0.2436) val_f1:  0.751394615571186 val_auroc:  0.4375 val_auprc:  0.8040837124476831\n",
      "Validation loss improved to 0.243602\n",
      "epoch:  47\n",
      "epoch:  48 val_loss:  tensor(0.2433) val_f1:  0.751394615571186 val_auroc:  0.4375 val_auprc:  0.8040837124476831\n",
      "Validation loss improved to 0.243308\n",
      "epoch:  48\n",
      "epoch:  49 val_loss:  tensor(0.2430) val_f1:  0.7894736842105263 val_auroc:  0.4375 val_auprc:  0.8040837124476831\n",
      "Validation loss improved to 0.243015\n",
      "epoch:  49\n",
      "epoch:  50 val_loss:  tensor(0.2427) val_f1:  0.828708133971292 val_auroc:  0.4375 val_auprc:  0.8040837124476831\n",
      "Validation loss improved to 0.242729\n",
      "epoch:  50\n",
      "epoch:  51 val_loss:  tensor(0.2425) val_f1:  0.828708133971292 val_auroc:  0.4375 val_auprc:  0.8040837124476831\n",
      "Validation loss improved to 0.242451\n",
      "epoch:  51\n",
      "epoch:  52 val_loss:  tensor(0.2422) val_f1:  0.7894736842105263 val_auroc:  0.45833333333333337 val_auprc:  0.8301253791143497\n",
      "Validation loss improved to 0.242180\n",
      "epoch:  52\n",
      "epoch:  53 val_loss:  tensor(0.2419) val_f1:  0.7894736842105263 val_auroc:  0.4375 val_auprc:  0.8212712124476831\n",
      "Validation loss improved to 0.241914\n",
      "epoch:  53\n",
      "epoch:  54 val_loss:  tensor(0.2416) val_f1:  0.7894736842105263 val_auroc:  0.4375 val_auprc:  0.8212712124476831\n",
      "Validation loss improved to 0.241649\n",
      "epoch:  54\n",
      "epoch:  55 val_loss:  tensor(0.2414) val_f1:  0.7894736842105263 val_auroc:  0.4375 val_auprc:  0.8212712124476831\n",
      "Validation loss improved to 0.241385\n",
      "epoch:  55\n",
      "epoch:  56 val_loss:  tensor(0.2411) val_f1:  0.7894736842105263 val_auroc:  0.4375 val_auprc:  0.8212712124476831\n",
      "Validation loss improved to 0.241125\n",
      "epoch:  56\n",
      "epoch:  57 val_loss:  tensor(0.2409) val_f1:  0.7894736842105263 val_auroc:  0.4375 val_auprc:  0.8212712124476831\n",
      "Validation loss improved to 0.240870\n",
      "epoch:  57\n",
      "epoch:  58 val_loss:  tensor(0.2406) val_f1:  0.7894736842105263 val_auroc:  0.45833333333333337 val_auprc:  0.8395003791143497\n",
      "Validation loss improved to 0.240619\n",
      "epoch:  58\n",
      "epoch:  59 val_loss:  tensor(0.2404) val_f1:  0.7894736842105263 val_auroc:  0.45833333333333337 val_auprc:  0.8395003791143497\n",
      "Validation loss improved to 0.240372\n",
      "epoch:  59\n",
      "epoch:  60 val_loss:  tensor(0.2401) val_f1:  0.828708133971292 val_auroc:  0.45833333333333337 val_auprc:  0.8395003791143497\n",
      "Validation loss improved to 0.240126\n",
      "epoch:  60\n",
      "epoch:  61 val_loss:  tensor(0.2399) val_f1:  0.828708133971292 val_auroc:  0.45833333333333337 val_auprc:  0.8395003791143497\n",
      "Validation loss improved to 0.239883\n",
      "epoch:  61\n",
      "epoch:  62 val_loss:  tensor(0.2396) val_f1:  0.828708133971292 val_auroc:  0.45833333333333337 val_auprc:  0.8395003791143497\n",
      "Validation loss improved to 0.239640\n",
      "epoch:  62\n",
      "epoch:  63 val_loss:  tensor(0.2394) val_f1:  0.828708133971292 val_auroc:  0.45833333333333337 val_auprc:  0.8395003791143497\n",
      "Validation loss improved to 0.239397\n",
      "epoch:  63\n",
      "epoch:  64 val_loss:  tensor(0.2392) val_f1:  0.828708133971292 val_auroc:  0.4791666666666667 val_auprc:  0.8483545457810164\n",
      "Validation loss improved to 0.239154\n",
      "epoch:  64\n",
      "epoch:  65 val_loss:  tensor(0.2389) val_f1:  0.828708133971292 val_auroc:  0.4791666666666667 val_auprc:  0.8483545457810164\n",
      "Validation loss improved to 0.238910\n",
      "epoch:  65\n",
      "epoch:  66 val_loss:  tensor(0.2387) val_f1:  0.828708133971292 val_auroc:  0.4791666666666667 val_auprc:  0.8483545457810164\n",
      "Validation loss improved to 0.238666\n",
      "epoch:  66\n",
      "epoch:  67 val_loss:  tensor(0.2384) val_f1:  0.828708133971292 val_auroc:  0.5 val_auprc:  0.8562414505429211\n",
      "Validation loss improved to 0.238424\n",
      "epoch:  67\n",
      "epoch:  68 val_loss:  tensor(0.2382) val_f1:  0.828708133971292 val_auroc:  0.5 val_auprc:  0.8562414505429211\n",
      "Validation loss improved to 0.238179\n",
      "epoch:  68\n",
      "epoch:  69 val_loss:  tensor(0.2379) val_f1:  0.828708133971292 val_auroc:  0.5 val_auprc:  0.8562414505429211\n",
      "Validation loss improved to 0.237932\n",
      "epoch:  69\n",
      "epoch:  70 val_loss:  tensor(0.2377) val_f1:  0.828708133971292 val_auroc:  0.5208333333333334 val_auprc:  0.8703039505429211\n",
      "Validation loss improved to 0.237682\n",
      "epoch:  70\n",
      "epoch:  71 val_loss:  tensor(0.2374) val_f1:  0.828708133971292 val_auroc:  0.5416666666666667 val_auprc:  0.8773724029238735\n",
      "Validation loss improved to 0.237433\n",
      "epoch:  71\n",
      "epoch:  72 val_loss:  tensor(0.2372) val_f1:  0.828708133971292 val_auroc:  0.5416666666666667 val_auprc:  0.8773724029238735\n",
      "Validation loss improved to 0.237182\n",
      "epoch:  72\n",
      "epoch:  73 val_loss:  tensor(0.2369) val_f1:  0.828708133971292 val_auroc:  0.5416666666666667 val_auprc:  0.8773724029238735\n",
      "Validation loss improved to 0.236934\n",
      "epoch:  73\n",
      "epoch:  74 val_loss:  tensor(0.2367) val_f1:  0.828708133971292 val_auroc:  0.5416666666666667 val_auprc:  0.8773724029238735\n",
      "Validation loss improved to 0.236687\n",
      "epoch:  74\n",
      "epoch:  75 val_loss:  tensor(0.2364) val_f1:  0.828708133971292 val_auroc:  0.5416666666666667 val_auprc:  0.8773724029238735\n",
      "Validation loss improved to 0.236442\n",
      "epoch:  75\n",
      "epoch:  76 val_loss:  tensor(0.2362) val_f1:  0.828708133971292 val_auroc:  0.5416666666666667 val_auprc:  0.8773724029238735\n",
      "Validation loss improved to 0.236197\n",
      "epoch:  76\n",
      "epoch:  77 val_loss:  tensor(0.2359) val_f1:  0.828708133971292 val_auroc:  0.5416666666666667 val_auprc:  0.8773724029238735\n",
      "Validation loss improved to 0.235950\n",
      "epoch:  77\n",
      "epoch:  78 val_loss:  tensor(0.2357) val_f1:  0.828708133971292 val_auroc:  0.5625 val_auprc:  0.8837588116540323\n",
      "Validation loss improved to 0.235703\n",
      "epoch:  78\n",
      "epoch:  79 val_loss:  tensor(0.2355) val_f1:  0.828708133971292 val_auroc:  0.5625 val_auprc:  0.8837588116540323\n",
      "Validation loss improved to 0.235457\n",
      "epoch:  79\n",
      "epoch:  80 val_loss:  tensor(0.2352) val_f1:  0.828708133971292 val_auroc:  0.5625 val_auprc:  0.8837588116540323\n",
      "Validation loss improved to 0.235209\n",
      "epoch:  80\n",
      "epoch:  81 val_loss:  tensor(0.2350) val_f1:  0.828708133971292 val_auroc:  0.5625 val_auprc:  0.8837588116540323\n",
      "Validation loss improved to 0.234960\n",
      "epoch:  81\n",
      "epoch:  82 val_loss:  tensor(0.2347) val_f1:  0.828708133971292 val_auroc:  0.5625 val_auprc:  0.8837588116540323\n",
      "Validation loss improved to 0.234710\n",
      "epoch:  82\n",
      "epoch:  83 val_loss:  tensor(0.2345) val_f1:  0.828708133971292 val_auroc:  0.5625 val_auprc:  0.8837588116540323\n",
      "Validation loss improved to 0.234463\n",
      "epoch:  83\n",
      "epoch:  84 val_loss:  tensor(0.2342) val_f1:  0.828708133971292 val_auroc:  0.5625 val_auprc:  0.8837588116540323\n",
      "Validation loss improved to 0.234218\n",
      "epoch:  84\n",
      "epoch:  85 val_loss:  tensor(0.2340) val_f1:  0.828708133971292 val_auroc:  0.5625 val_auprc:  0.8837588116540323\n",
      "Validation loss improved to 0.233972\n",
      "epoch:  85\n",
      "epoch:  86 val_loss:  tensor(0.2337) val_f1:  0.828708133971292 val_auroc:  0.5625 val_auprc:  0.8837588116540323\n",
      "Validation loss improved to 0.233725\n",
      "epoch:  86\n",
      "epoch:  87 val_loss:  tensor(0.2335) val_f1:  0.828708133971292 val_auroc:  0.5625 val_auprc:  0.8837588116540323\n",
      "Validation loss improved to 0.233477\n",
      "epoch:  87\n",
      "epoch:  88 val_loss:  tensor(0.2332) val_f1:  0.828708133971292 val_auroc:  0.5625 val_auprc:  0.8837588116540323\n",
      "Validation loss improved to 0.233227\n",
      "epoch:  88\n",
      "epoch:  89 val_loss:  tensor(0.2330) val_f1:  0.828708133971292 val_auroc:  0.5833333333333334 val_auprc:  0.8895747838762544\n",
      "Validation loss improved to 0.232981\n",
      "epoch:  89\n",
      "epoch:  90 val_loss:  tensor(0.2327) val_f1:  0.828708133971292 val_auroc:  0.5833333333333334 val_auprc:  0.8895747838762544\n",
      "Validation loss improved to 0.232734\n",
      "epoch:  90\n",
      "epoch:  91 val_loss:  tensor(0.2325) val_f1:  0.828708133971292 val_auroc:  0.5833333333333334 val_auprc:  0.8895747838762544\n",
      "Validation loss improved to 0.232489\n",
      "epoch:  91\n",
      "epoch:  92 val_loss:  tensor(0.2322) val_f1:  0.828708133971292 val_auroc:  0.5833333333333334 val_auprc:  0.8895747838762544\n",
      "Validation loss improved to 0.232247\n",
      "epoch:  92\n",
      "epoch:  93 val_loss:  tensor(0.2320) val_f1:  0.828708133971292 val_auroc:  0.5833333333333334 val_auprc:  0.8895747838762544\n",
      "Validation loss improved to 0.232007\n",
      "epoch:  93\n",
      "epoch:  94 val_loss:  tensor(0.2318) val_f1:  0.828708133971292 val_auroc:  0.6041666666666667 val_auprc:  0.9010331172095878\n",
      "Validation loss improved to 0.231767\n",
      "epoch:  94\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  95 val_loss:  tensor(0.2315) val_f1:  0.828708133971292 val_auroc:  0.6041666666666667 val_auprc:  0.9010331172095878\n",
      "Validation loss improved to 0.231528\n",
      "epoch:  95\n",
      "epoch:  96 val_loss:  tensor(0.2313) val_f1:  0.828708133971292 val_auroc:  0.625 val_auprc:  0.9063677131691839\n",
      "Validation loss improved to 0.231292\n",
      "epoch:  96\n",
      "epoch:  97 val_loss:  tensor(0.2311) val_f1:  0.828708133971292 val_auroc:  0.625 val_auprc:  0.9063677131691839\n",
      "Validation loss improved to 0.231059\n",
      "epoch:  97\n",
      "epoch:  98 val_loss:  tensor(0.2308) val_f1:  0.828708133971292 val_auroc:  0.625 val_auprc:  0.9063677131691839\n",
      "Validation loss improved to 0.230825\n",
      "epoch:  98\n",
      "epoch:  99 val_loss:  tensor(0.2306) val_f1:  0.828708133971292 val_auroc:  0.625 val_auprc:  0.9063677131691839\n",
      "Validation loss improved to 0.230589\n",
      "epoch:  99\n",
      "epoch:  100 val_loss:  tensor(0.2304) val_f1:  0.828708133971292 val_auroc:  0.625 val_auprc:  0.9063677131691839\n",
      "Validation loss improved to 0.230356\n",
      "epoch:  100\n",
      "epoch:  101 val_loss:  tensor(0.2301) val_f1:  0.828708133971292 val_auroc:  0.625 val_auprc:  0.9063677131691839\n",
      "Validation loss improved to 0.230127\n",
      "epoch:  101\n",
      "epoch:  102 val_loss:  tensor(0.2299) val_f1:  0.828708133971292 val_auroc:  0.625 val_auprc:  0.9063677131691839\n",
      "Validation loss improved to 0.229902\n",
      "epoch:  102\n",
      "epoch:  103 val_loss:  tensor(0.2297) val_f1:  0.828708133971292 val_auroc:  0.625 val_auprc:  0.9063677131691839\n",
      "Validation loss improved to 0.229680\n",
      "epoch:  103\n",
      "epoch:  104 val_loss:  tensor(0.2295) val_f1:  0.828708133971292 val_auroc:  0.625 val_auprc:  0.9063677131691839\n",
      "Validation loss improved to 0.229458\n",
      "epoch:  104\n",
      "epoch:  105 val_loss:  tensor(0.2292) val_f1:  0.828708133971292 val_auroc:  0.625 val_auprc:  0.9063677131691839\n",
      "Validation loss improved to 0.229241\n",
      "epoch:  105\n",
      "epoch:  106 val_loss:  tensor(0.2290) val_f1:  0.828708133971292 val_auroc:  0.625 val_auprc:  0.9063677131691839\n",
      "Validation loss improved to 0.229029\n",
      "epoch:  106\n",
      "epoch:  107 val_loss:  tensor(0.2288) val_f1:  0.828708133971292 val_auroc:  0.625 val_auprc:  0.9063677131691839\n",
      "Validation loss improved to 0.228821\n",
      "epoch:  107\n",
      "epoch:  108 val_loss:  tensor(0.2286) val_f1:  0.828708133971292 val_auroc:  0.625 val_auprc:  0.9063677131691839\n",
      "Validation loss improved to 0.228618\n",
      "epoch:  108\n",
      "epoch:  109 val_loss:  tensor(0.2284) val_f1:  0.828708133971292 val_auroc:  0.625 val_auprc:  0.9063677131691839\n",
      "Validation loss improved to 0.228424\n",
      "epoch:  109\n",
      "epoch:  110 val_loss:  tensor(0.2282) val_f1:  0.828708133971292 val_auroc:  0.625 val_auprc:  0.9063677131691839\n",
      "Validation loss improved to 0.228241\n",
      "epoch:  110\n",
      "epoch:  111 val_loss:  tensor(0.2281) val_f1:  0.828708133971292 val_auroc:  0.625 val_auprc:  0.9063677131691839\n",
      "Validation loss improved to 0.228063\n",
      "epoch:  111\n",
      "epoch:  112 val_loss:  tensor(0.2279) val_f1:  0.828708133971292 val_auroc:  0.625 val_auprc:  0.9063677131691839\n",
      "Validation loss improved to 0.227891\n",
      "epoch:  112\n",
      "epoch:  113 val_loss:  tensor(0.2277) val_f1:  0.828708133971292 val_auroc:  0.625 val_auprc:  0.9063677131691839\n",
      "Validation loss improved to 0.227725\n",
      "epoch:  113\n",
      "epoch:  114 val_loss:  tensor(0.2276) val_f1:  0.828708133971292 val_auroc:  0.625 val_auprc:  0.9063677131691839\n",
      "Validation loss improved to 0.227567\n",
      "epoch:  114\n",
      "epoch:  115 val_loss:  tensor(0.2274) val_f1:  0.828708133971292 val_auroc:  0.625 val_auprc:  0.9063677131691839\n",
      "Validation loss improved to 0.227415\n",
      "epoch:  115\n",
      "epoch:  116 val_loss:  tensor(0.2273) val_f1:  0.7894736842105263 val_auroc:  0.625 val_auprc:  0.9063677131691839\n",
      "Validation loss improved to 0.227273\n",
      "epoch:  116\n",
      "epoch:  117 val_loss:  tensor(0.2271) val_f1:  0.7894736842105263 val_auroc:  0.625 val_auprc:  0.9063677131691839\n",
      "Validation loss improved to 0.227138\n",
      "epoch:  117\n",
      "epoch:  118 val_loss:  tensor(0.2270) val_f1:  0.7894736842105263 val_auroc:  0.625 val_auprc:  0.9063677131691839\n",
      "Validation loss improved to 0.227013\n",
      "epoch:  118\n",
      "epoch:  119 val_loss:  tensor(0.2269) val_f1:  0.7894736842105263 val_auroc:  0.625 val_auprc:  0.9063677131691839\n",
      "Validation loss improved to 0.226897\n",
      "epoch:  119\n",
      "epoch:  120 val_loss:  tensor(0.2268) val_f1:  0.828708133971292 val_auroc:  0.625 val_auprc:  0.9063677131691839\n",
      "Validation loss improved to 0.226788\n",
      "epoch:  120\n",
      "epoch:  121 val_loss:  tensor(0.2267) val_f1:  0.828708133971292 val_auroc:  0.625 val_auprc:  0.9063677131691839\n",
      "Validation loss improved to 0.226685\n",
      "epoch:  121\n",
      "epoch:  122 val_loss:  tensor(0.2266) val_f1:  0.828708133971292 val_auroc:  0.625 val_auprc:  0.9063677131691839\n",
      "Validation loss improved to 0.226592\n",
      "epoch:  122\n",
      "epoch:  123 val_loss:  tensor(0.2265) val_f1:  0.828708133971292 val_auroc:  0.625 val_auprc:  0.9063677131691839\n",
      "Validation loss improved to 0.226511\n",
      "epoch:  123\n",
      "epoch:  124 val_loss:  tensor(0.2264) val_f1:  0.828708133971292 val_auroc:  0.6041666666666667 val_auprc:  0.9010331172095878\n",
      "Validation loss improved to 0.226440\n",
      "epoch:  124\n",
      "epoch:  125 val_loss:  tensor(0.2264) val_f1:  0.828708133971292 val_auroc:  0.6041666666666667 val_auprc:  0.9010331172095878\n",
      "Validation loss improved to 0.226377\n",
      "epoch:  125\n",
      "epoch:  126 val_loss:  tensor(0.2263) val_f1:  0.828708133971292 val_auroc:  0.6041666666666667 val_auprc:  0.9010331172095878\n",
      "Validation loss improved to 0.226322\n",
      "epoch:  126\n",
      "epoch:  127 val_loss:  tensor(0.2263) val_f1:  0.828708133971292 val_auroc:  0.5833333333333334 val_auprc:  0.8952171449873656\n",
      "Validation loss improved to 0.226283\n",
      "epoch:  127\n",
      "epoch:  128 val_loss:  tensor(0.2263) val_f1:  0.828708133971292 val_auroc:  0.5833333333333334 val_auprc:  0.8952171449873656\n",
      "Validation loss improved to 0.226259\n",
      "epoch:  128\n",
      "epoch:  129 val_loss:  tensor(0.2262) val_f1:  0.828708133971292 val_auroc:  0.6041666666666667 val_auprc:  0.9048897640349847\n",
      "Validation loss improved to 0.226247\n",
      "epoch:  129\n",
      "epoch:  130 val_loss:  tensor(0.2262) val_f1:  0.828708133971292 val_auroc:  0.6041666666666667 val_auprc:  0.9048897640349847\n",
      "EarlyStopping counter: 1 out of 50\n",
      "epoch:  130\n",
      "epoch:  131 val_loss:  tensor(0.2263) val_f1:  0.828708133971292 val_auroc:  0.6041666666666667 val_auprc:  0.9048897640349847\n",
      "EarlyStopping counter: 2 out of 50\n",
      "epoch:  131\n",
      "epoch:  132 val_loss:  tensor(0.2263) val_f1:  0.828708133971292 val_auroc:  0.6041666666666667 val_auprc:  0.9048897640349847\n",
      "EarlyStopping counter: 3 out of 50\n",
      "epoch:  132\n",
      "epoch:  133 val_loss:  tensor(0.2263) val_f1:  0.828708133971292 val_auroc:  0.6041666666666667 val_auprc:  0.9048897640349847\n",
      "EarlyStopping counter: 4 out of 50\n",
      "epoch:  133\n",
      "epoch:  134 val_loss:  tensor(0.2264) val_f1:  0.828708133971292 val_auroc:  0.6041666666666667 val_auprc:  0.9048897640349847\n",
      "EarlyStopping counter: 5 out of 50\n",
      "epoch:  134\n",
      "epoch:  135 val_loss:  tensor(0.2265) val_f1:  0.828708133971292 val_auroc:  0.6041666666666667 val_auprc:  0.9048897640349847\n",
      "EarlyStopping counter: 6 out of 50\n",
      "epoch:  135\n",
      "epoch:  136 val_loss:  tensor(0.2265) val_f1:  0.828708133971292 val_auroc:  0.6041666666666667 val_auprc:  0.9048897640349847\n",
      "EarlyStopping counter: 7 out of 50\n",
      "epoch:  136\n",
      "epoch:  137 val_loss:  tensor(0.2267) val_f1:  0.828708133971292 val_auroc:  0.6041666666666667 val_auprc:  0.9048897640349847\n",
      "EarlyStopping counter: 8 out of 50\n",
      "epoch:  137\n",
      "epoch:  138 val_loss:  tensor(0.2268) val_f1:  0.828708133971292 val_auroc:  0.625 val_auprc:  0.9107057362572069\n",
      "EarlyStopping counter: 9 out of 50\n",
      "epoch:  138\n",
      "epoch:  139 val_loss:  tensor(0.2269) val_f1:  0.828708133971292 val_auroc:  0.625 val_auprc:  0.9107057362572069\n",
      "EarlyStopping counter: 10 out of 50\n",
      "epoch:  139\n",
      "epoch:  140 val_loss:  tensor(0.2270) val_f1:  0.828708133971292 val_auroc:  0.625 val_auprc:  0.9107057362572069\n",
      "EarlyStopping counter: 11 out of 50\n",
      "epoch:  140\n",
      "epoch:  141 val_loss:  tensor(0.2272) val_f1:  0.828708133971292 val_auroc:  0.625 val_auprc:  0.9107057362572069\n",
      "EarlyStopping counter: 12 out of 50\n",
      "epoch:  141\n",
      "epoch:  142 val_loss:  tensor(0.2274) val_f1:  0.828708133971292 val_auroc:  0.625 val_auprc:  0.9107057362572069\n",
      "EarlyStopping counter: 13 out of 50\n",
      "epoch:  142\n",
      "epoch:  143 val_loss:  tensor(0.2276) val_f1:  0.828708133971292 val_auroc:  0.625 val_auprc:  0.9107057362572069\n",
      "EarlyStopping counter: 14 out of 50\n",
      "epoch:  143\n",
      "epoch:  144 val_loss:  tensor(0.2278) val_f1:  0.828708133971292 val_auroc:  0.625 val_auprc:  0.9107057362572069\n",
      "EarlyStopping counter: 15 out of 50\n",
      "epoch:  144\n",
      "epoch:  145 val_loss:  tensor(0.2280) val_f1:  0.828708133971292 val_auroc:  0.625 val_auprc:  0.9107057362572069\n",
      "EarlyStopping counter: 16 out of 50\n",
      "epoch:  145\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  146 val_loss:  tensor(0.2282) val_f1:  0.828708133971292 val_auroc:  0.625 val_auprc:  0.9107057362572069\n",
      "EarlyStopping counter: 17 out of 50\n",
      "epoch:  146\n",
      "epoch:  147 val_loss:  tensor(0.2285) val_f1:  0.828708133971292 val_auroc:  0.625 val_auprc:  0.9107057362572069\n",
      "EarlyStopping counter: 18 out of 50\n",
      "epoch:  147\n",
      "epoch:  148 val_loss:  tensor(0.2287) val_f1:  0.828708133971292 val_auroc:  0.625 val_auprc:  0.9107057362572069\n",
      "EarlyStopping counter: 19 out of 50\n",
      "epoch:  148\n",
      "epoch:  149 val_loss:  tensor(0.2290) val_f1:  0.828708133971292 val_auroc:  0.625 val_auprc:  0.9107057362572069\n",
      "EarlyStopping counter: 20 out of 50\n",
      "epoch:  149\n",
      "epoch:  150 val_loss:  tensor(0.2293) val_f1:  0.828708133971292 val_auroc:  0.625 val_auprc:  0.9107057362572069\n",
      "EarlyStopping counter: 21 out of 50\n",
      "epoch:  150\n",
      "epoch:  151 val_loss:  tensor(0.2296) val_f1:  0.828708133971292 val_auroc:  0.6458333333333334 val_auprc:  0.9190762719714926\n",
      "EarlyStopping counter: 22 out of 50\n",
      "epoch:  151\n",
      "epoch:  152 val_loss:  tensor(0.2299) val_f1:  0.828708133971292 val_auroc:  0.6458333333333334 val_auprc:  0.9190762719714926\n",
      "EarlyStopping counter: 23 out of 50\n",
      "epoch:  152\n",
      "epoch:  153 val_loss:  tensor(0.2303) val_f1:  0.828708133971292 val_auroc:  0.6458333333333334 val_auprc:  0.9190762719714926\n",
      "EarlyStopping counter: 24 out of 50\n",
      "epoch:  153\n",
      "epoch:  154 val_loss:  tensor(0.2306) val_f1:  0.828708133971292 val_auroc:  0.6458333333333334 val_auprc:  0.9190762719714926\n",
      "EarlyStopping counter: 25 out of 50\n",
      "epoch:  154\n",
      "epoch:  155 val_loss:  tensor(0.2310) val_f1:  0.828708133971292 val_auroc:  0.6458333333333334 val_auprc:  0.9190762719714926\n",
      "EarlyStopping counter: 26 out of 50\n",
      "epoch:  155\n",
      "epoch:  156 val_loss:  tensor(0.2314) val_f1:  0.828708133971292 val_auroc:  0.6458333333333334 val_auprc:  0.9190762719714926\n",
      "EarlyStopping counter: 27 out of 50\n",
      "epoch:  156\n",
      "epoch:  157 val_loss:  tensor(0.2318) val_f1:  0.828708133971292 val_auroc:  0.6458333333333334 val_auprc:  0.9190762719714926\n",
      "EarlyStopping counter: 28 out of 50\n",
      "epoch:  157\n",
      "epoch:  158 val_loss:  tensor(0.2322) val_f1:  0.828708133971292 val_auroc:  0.6458333333333334 val_auprc:  0.9190762719714926\n",
      "EarlyStopping counter: 29 out of 50\n",
      "epoch:  158\n",
      "epoch:  159 val_loss:  tensor(0.2326) val_f1:  0.828708133971292 val_auroc:  0.6458333333333334 val_auprc:  0.9190762719714926\n",
      "EarlyStopping counter: 30 out of 50\n",
      "epoch:  159\n",
      "epoch:  160 val_loss:  tensor(0.2331) val_f1:  0.828708133971292 val_auroc:  0.6458333333333334 val_auprc:  0.9190762719714926\n",
      "EarlyStopping counter: 31 out of 50\n",
      "epoch:  160\n",
      "epoch:  161 val_loss:  tensor(0.2335) val_f1:  0.828708133971292 val_auroc:  0.6458333333333334 val_auprc:  0.9190762719714926\n",
      "EarlyStopping counter: 32 out of 50\n",
      "epoch:  161\n",
      "epoch:  162 val_loss:  tensor(0.2340) val_f1:  0.828708133971292 val_auroc:  0.6458333333333334 val_auprc:  0.9190762719714926\n",
      "EarlyStopping counter: 33 out of 50\n",
      "epoch:  162\n",
      "epoch:  163 val_loss:  tensor(0.2345) val_f1:  0.871517027863777 val_auroc:  0.6458333333333334 val_auprc:  0.9190762719714926\n",
      "EarlyStopping counter: 34 out of 50\n",
      "epoch:  163\n",
      "epoch:  164 val_loss:  tensor(0.2350) val_f1:  0.871517027863777 val_auroc:  0.6666666666666667 val_auprc:  0.9264547441937148\n",
      "EarlyStopping counter: 35 out of 50\n",
      "epoch:  164\n",
      "epoch:  165 val_loss:  tensor(0.2355) val_f1:  0.871517027863777 val_auroc:  0.6666666666666667 val_auprc:  0.9264547441937148\n",
      "EarlyStopping counter: 36 out of 50\n",
      "epoch:  165\n",
      "epoch:  166 val_loss:  tensor(0.2360) val_f1:  0.871517027863777 val_auroc:  0.6666666666666667 val_auprc:  0.9264547441937148\n",
      "EarlyStopping counter: 37 out of 50\n",
      "epoch:  166\n",
      "epoch:  167 val_loss:  tensor(0.2365) val_f1:  0.871517027863777 val_auroc:  0.6458333333333334 val_auprc:  0.9190762719714926\n",
      "EarlyStopping counter: 38 out of 50\n",
      "epoch:  167\n",
      "epoch:  168 val_loss:  tensor(0.2370) val_f1:  0.871517027863777 val_auroc:  0.6458333333333334 val_auprc:  0.9190762719714926\n",
      "EarlyStopping counter: 39 out of 50\n",
      "epoch:  168\n",
      "epoch:  169 val_loss:  tensor(0.2376) val_f1:  0.871517027863777 val_auroc:  0.6458333333333334 val_auprc:  0.9190762719714926\n",
      "EarlyStopping counter: 40 out of 50\n",
      "epoch:  169\n",
      "epoch:  170 val_loss:  tensor(0.2382) val_f1:  0.871517027863777 val_auroc:  0.6458333333333334 val_auprc:  0.9190762719714926\n",
      "EarlyStopping counter: 41 out of 50\n",
      "epoch:  170\n",
      "epoch:  171 val_loss:  tensor(0.2387) val_f1:  0.871517027863777 val_auroc:  0.6458333333333334 val_auprc:  0.9190762719714926\n",
      "EarlyStopping counter: 42 out of 50\n",
      "epoch:  171\n",
      "epoch:  172 val_loss:  tensor(0.2393) val_f1:  0.871517027863777 val_auroc:  0.6458333333333334 val_auprc:  0.9190762719714926\n",
      "EarlyStopping counter: 43 out of 50\n",
      "epoch:  172\n",
      "epoch:  173 val_loss:  tensor(0.2399) val_f1:  0.871517027863777 val_auroc:  0.6458333333333334 val_auprc:  0.9190762719714926\n",
      "EarlyStopping counter: 44 out of 50\n",
      "epoch:  173\n",
      "epoch:  174 val_loss:  tensor(0.2406) val_f1:  0.871517027863777 val_auroc:  0.6458333333333334 val_auprc:  0.9190762719714926\n",
      "EarlyStopping counter: 45 out of 50\n",
      "epoch:  174\n",
      "epoch:  175 val_loss:  tensor(0.2412) val_f1:  0.871517027863777 val_auroc:  0.6458333333333334 val_auprc:  0.9190762719714926\n",
      "EarlyStopping counter: 46 out of 50\n",
      "epoch:  175\n",
      "epoch:  176 val_loss:  tensor(0.2418) val_f1:  0.871517027863777 val_auroc:  0.6458333333333334 val_auprc:  0.9190762719714926\n",
      "EarlyStopping counter: 47 out of 50\n",
      "epoch:  176\n",
      "epoch:  177 val_loss:  tensor(0.2425) val_f1:  0.871517027863777 val_auroc:  0.6458333333333334 val_auprc:  0.9190762719714926\n",
      "EarlyStopping counter: 48 out of 50\n",
      "epoch:  177\n",
      "epoch:  178 val_loss:  tensor(0.2431) val_f1:  0.871517027863777 val_auroc:  0.6458333333333334 val_auprc:  0.9190762719714926\n",
      "EarlyStopping counter: 49 out of 50\n",
      "epoch:  178\n",
      "epoch:  179 val_loss:  tensor(0.2438) val_f1:  0.871517027863777 val_auroc:  0.6458333333333334 val_auprc:  0.9190762719714926\n",
      "EarlyStopping counter: 50 out of 50\n",
      "Early stopping triggered\n",
      "Early stopping triggered!\n",
      "Time taken:  15.497211933135986\n",
      "tensor(0.2188)\n",
      "epoch:  0\n",
      "epoch:  1 val_loss:  tensor(0.2620) val_f1:  0.07322654462242563 val_auroc:  0.9166666666666666 val_auprc:  0.9770216548157724\n",
      "epoch:  1\n",
      "epoch:  2 val_loss:  tensor(0.3201) val_f1:  0.07322654462242563 val_auroc:  0.9333333333333333 val_auprc:  0.9839589169000933\n",
      "EarlyStopping counter: 1 out of 50\n",
      "epoch:  2\n",
      "epoch:  3 val_loss:  tensor(0.2774) val_f1:  0.07322654462242563 val_auroc:  0.9333333333333333 val_auprc:  0.9839589169000933\n",
      "EarlyStopping counter: 2 out of 50\n",
      "epoch:  3\n",
      "epoch:  4 val_loss:  tensor(0.2072) val_f1:  0.7611336032388664 val_auroc:  0.95 val_auprc:  0.9885620915032679\n",
      "Validation loss improved to 0.207232\n",
      "epoch:  4\n",
      "epoch:  5 val_loss:  tensor(0.2206) val_f1:  0.8333737569730779 val_auroc:  0.95 val_auprc:  0.9885620915032679\n",
      "EarlyStopping counter: 1 out of 50\n",
      "epoch:  5\n",
      "epoch:  6 val_loss:  tensor(0.2044) val_f1:  0.8947368421052632 val_auroc:  0.95 val_auprc:  0.9885620915032679\n",
      "Validation loss improved to 0.204428\n",
      "epoch:  6\n",
      "epoch:  7 val_loss:  tensor(0.2014) val_f1:  0.4883040935672515 val_auroc:  0.95 val_auprc:  0.9885620915032679\n",
      "Validation loss improved to 0.201404\n",
      "epoch:  7\n",
      "epoch:  8 val_loss:  tensor(0.2288) val_f1:  0.07322654462242563 val_auroc:  0.95 val_auprc:  0.9885620915032679\n",
      "EarlyStopping counter: 1 out of 50\n",
      "epoch:  8\n",
      "epoch:  9 val_loss:  tensor(0.2087) val_f1:  0.34736842105263166 val_auroc:  0.95 val_auprc:  0.9885620915032679\n",
      "EarlyStopping counter: 2 out of 50\n",
      "epoch:  9\n",
      "epoch:  10 val_loss:  tensor(0.1893) val_f1:  0.9015037593984964 val_auroc:  0.95 val_auprc:  0.9885620915032679\n",
      "Validation loss improved to 0.189299\n",
      "epoch:  10\n",
      "epoch:  11 val_loss:  tensor(0.1887) val_f1:  0.8947368421052632 val_auroc:  0.95 val_auprc:  0.9885620915032679\n",
      "Validation loss improved to 0.188728\n",
      "epoch:  11\n",
      "epoch:  12 val_loss:  tensor(0.1909) val_f1:  0.8083670715249661 val_auroc:  0.95 val_auprc:  0.9885620915032679\n",
      "EarlyStopping counter: 1 out of 50\n",
      "epoch:  12\n",
      "epoch:  13 val_loss:  tensor(0.2027) val_f1:  0.42105263157894735 val_auroc:  0.95 val_auprc:  0.9885620915032679\n",
      "EarlyStopping counter: 2 out of 50\n",
      "epoch:  13\n",
      "epoch:  14 val_loss:  tensor(0.1991) val_f1:  0.4883040935672515 val_auroc:  0.95 val_auprc:  0.9885620915032679\n",
      "EarlyStopping counter: 3 out of 50\n",
      "epoch:  14\n",
      "epoch:  15 val_loss:  tensor(0.1898) val_f1:  0.8083670715249661 val_auroc:  0.95 val_auprc:  0.9885620915032679\n",
      "EarlyStopping counter: 4 out of 50\n",
      "epoch:  15\n",
      "epoch:  16 val_loss:  tensor(0.1883) val_f1:  0.8548644338118022 val_auroc:  0.95 val_auprc:  0.9885620915032679\n",
      "Validation loss improved to 0.188270\n",
      "epoch:  16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  17 val_loss:  tensor(0.1912) val_f1:  0.7124060150375939 val_auroc:  0.95 val_auprc:  0.9885620915032679\n",
      "EarlyStopping counter: 1 out of 50\n",
      "epoch:  17\n",
      "epoch:  18 val_loss:  tensor(0.1959) val_f1:  0.5501990269792129 val_auroc:  0.95 val_auprc:  0.9885620915032679\n",
      "EarlyStopping counter: 2 out of 50\n",
      "epoch:  18\n",
      "epoch:  19 val_loss:  tensor(0.1941) val_f1:  0.6614797864225782 val_auroc:  0.95 val_auprc:  0.9885620915032679\n",
      "EarlyStopping counter: 3 out of 50\n",
      "epoch:  19\n",
      "epoch:  20 val_loss:  tensor(0.1905) val_f1:  0.8083670715249661 val_auroc:  0.95 val_auprc:  0.9885620915032679\n",
      "EarlyStopping counter: 4 out of 50\n",
      "epoch:  20\n",
      "epoch:  21 val_loss:  tensor(0.1901) val_f1:  0.8083670715249661 val_auroc:  0.95 val_auprc:  0.9885620915032679\n",
      "EarlyStopping counter: 5 out of 50\n",
      "epoch:  21\n",
      "epoch:  22 val_loss:  tensor(0.1921) val_f1:  0.7124060150375939 val_auroc:  0.95 val_auprc:  0.9885620915032679\n",
      "EarlyStopping counter: 6 out of 50\n",
      "epoch:  22\n",
      "epoch:  23 val_loss:  tensor(0.1937) val_f1:  0.7124060150375939 val_auroc:  0.95 val_auprc:  0.9885620915032679\n",
      "EarlyStopping counter: 7 out of 50\n",
      "epoch:  23\n",
      "epoch:  24 val_loss:  tensor(0.1924) val_f1:  0.7124060150375939 val_auroc:  0.95 val_auprc:  0.9885620915032679\n",
      "EarlyStopping counter: 8 out of 50\n",
      "epoch:  24\n",
      "epoch:  25 val_loss:  tensor(0.1912) val_f1:  0.8083670715249661 val_auroc:  0.95 val_auprc:  0.9885620915032679\n",
      "EarlyStopping counter: 9 out of 50\n",
      "epoch:  25\n",
      "epoch:  26 val_loss:  tensor(0.1915) val_f1:  0.8083670715249661 val_auroc:  0.95 val_auprc:  0.9885620915032679\n",
      "EarlyStopping counter: 10 out of 50\n",
      "epoch:  26\n",
      "epoch:  27 val_loss:  tensor(0.1926) val_f1:  0.7124060150375939 val_auroc:  0.95 val_auprc:  0.9885620915032679\n",
      "EarlyStopping counter: 11 out of 50\n",
      "epoch:  27\n",
      "epoch:  28 val_loss:  tensor(0.1928) val_f1:  0.7124060150375939 val_auroc:  0.95 val_auprc:  0.9885620915032679\n",
      "EarlyStopping counter: 12 out of 50\n",
      "epoch:  28\n",
      "epoch:  29 val_loss:  tensor(0.1922) val_f1:  0.8083670715249661 val_auroc:  0.95 val_auprc:  0.9885620915032679\n",
      "EarlyStopping counter: 13 out of 50\n",
      "epoch:  29\n",
      "epoch:  30 val_loss:  tensor(0.1919) val_f1:  0.8083670715249661 val_auroc:  0.95 val_auprc:  0.9885620915032679\n",
      "EarlyStopping counter: 14 out of 50\n",
      "epoch:  30\n",
      "epoch:  31 val_loss:  tensor(0.1924) val_f1:  0.8083670715249661 val_auroc:  0.95 val_auprc:  0.9885620915032679\n",
      "EarlyStopping counter: 15 out of 50\n",
      "epoch:  31\n",
      "epoch:  32 val_loss:  tensor(0.1928) val_f1:  0.8083670715249661 val_auroc:  0.95 val_auprc:  0.9885620915032679\n",
      "EarlyStopping counter: 16 out of 50\n",
      "epoch:  32\n",
      "epoch:  33 val_loss:  tensor(0.1927) val_f1:  0.8083670715249661 val_auroc:  0.95 val_auprc:  0.9885620915032679\n",
      "EarlyStopping counter: 17 out of 50\n",
      "epoch:  33\n",
      "epoch:  34 val_loss:  tensor(0.1925) val_f1:  0.8083670715249661 val_auroc:  0.95 val_auprc:  0.9885620915032679\n",
      "EarlyStopping counter: 18 out of 50\n",
      "epoch:  34\n",
      "epoch:  35 val_loss:  tensor(0.1925) val_f1:  0.8083670715249661 val_auroc:  0.95 val_auprc:  0.9885620915032679\n",
      "EarlyStopping counter: 19 out of 50\n",
      "epoch:  35\n",
      "epoch:  36 val_loss:  tensor(0.1928) val_f1:  0.8083670715249661 val_auroc:  0.95 val_auprc:  0.9885620915032679\n",
      "EarlyStopping counter: 20 out of 50\n",
      "epoch:  36\n",
      "epoch:  37 val_loss:  tensor(0.1929) val_f1:  0.8083670715249661 val_auroc:  0.95 val_auprc:  0.9885620915032679\n",
      "EarlyStopping counter: 21 out of 50\n",
      "epoch:  37\n",
      "epoch:  38 val_loss:  tensor(0.1928) val_f1:  0.8083670715249661 val_auroc:  0.95 val_auprc:  0.9885620915032679\n",
      "EarlyStopping counter: 22 out of 50\n",
      "epoch:  38\n",
      "epoch:  39 val_loss:  tensor(0.1928) val_f1:  0.8083670715249661 val_auroc:  0.95 val_auprc:  0.9885620915032679\n",
      "EarlyStopping counter: 23 out of 50\n",
      "epoch:  39\n",
      "epoch:  40 val_loss:  tensor(0.1930) val_f1:  0.8083670715249661 val_auroc:  0.95 val_auprc:  0.9885620915032679\n",
      "EarlyStopping counter: 24 out of 50\n",
      "epoch:  40\n",
      "epoch:  41 val_loss:  tensor(0.1931) val_f1:  0.8083670715249661 val_auroc:  0.95 val_auprc:  0.9885620915032679\n",
      "EarlyStopping counter: 25 out of 50\n",
      "epoch:  41\n",
      "epoch:  42 val_loss:  tensor(0.1932) val_f1:  0.8083670715249661 val_auroc:  0.95 val_auprc:  0.9885620915032679\n",
      "EarlyStopping counter: 26 out of 50\n",
      "epoch:  42\n",
      "epoch:  43 val_loss:  tensor(0.1932) val_f1:  0.8083670715249661 val_auroc:  0.95 val_auprc:  0.9885620915032679\n",
      "EarlyStopping counter: 27 out of 50\n",
      "epoch:  43\n",
      "epoch:  44 val_loss:  tensor(0.1933) val_f1:  0.8083670715249661 val_auroc:  0.95 val_auprc:  0.9885620915032679\n",
      "EarlyStopping counter: 28 out of 50\n",
      "epoch:  44\n",
      "epoch:  45 val_loss:  tensor(0.1934) val_f1:  0.8083670715249661 val_auroc:  0.95 val_auprc:  0.9885620915032679\n",
      "EarlyStopping counter: 29 out of 50\n",
      "epoch:  45\n",
      "epoch:  46 val_loss:  tensor(0.1934) val_f1:  0.8083670715249661 val_auroc:  0.95 val_auprc:  0.9885620915032679\n",
      "EarlyStopping counter: 30 out of 50\n",
      "epoch:  46\n",
      "epoch:  47 val_loss:  tensor(0.1935) val_f1:  0.8083670715249661 val_auroc:  0.95 val_auprc:  0.9885620915032679\n",
      "EarlyStopping counter: 31 out of 50\n",
      "epoch:  47\n",
      "epoch:  48 val_loss:  tensor(0.1935) val_f1:  0.8083670715249661 val_auroc:  0.95 val_auprc:  0.9885620915032679\n",
      "EarlyStopping counter: 32 out of 50\n",
      "epoch:  48\n",
      "epoch:  49 val_loss:  tensor(0.1936) val_f1:  0.8083670715249661 val_auroc:  0.95 val_auprc:  0.9885620915032679\n",
      "EarlyStopping counter: 33 out of 50\n",
      "epoch:  49\n",
      "epoch:  50 val_loss:  tensor(0.1937) val_f1:  0.8083670715249661 val_auroc:  0.95 val_auprc:  0.9885620915032679\n",
      "EarlyStopping counter: 34 out of 50\n",
      "epoch:  50\n",
      "epoch:  51 val_loss:  tensor(0.1938) val_f1:  0.8083670715249661 val_auroc:  0.95 val_auprc:  0.9885620915032679\n",
      "EarlyStopping counter: 35 out of 50\n",
      "epoch:  51\n",
      "epoch:  52 val_loss:  tensor(0.1939) val_f1:  0.8083670715249661 val_auroc:  0.95 val_auprc:  0.9885620915032679\n",
      "EarlyStopping counter: 36 out of 50\n",
      "epoch:  52\n",
      "epoch:  53 val_loss:  tensor(0.1939) val_f1:  0.8083670715249661 val_auroc:  0.95 val_auprc:  0.9885620915032679\n",
      "EarlyStopping counter: 37 out of 50\n",
      "epoch:  53\n",
      "epoch:  54 val_loss:  tensor(0.1940) val_f1:  0.8083670715249661 val_auroc:  0.95 val_auprc:  0.9885620915032679\n",
      "EarlyStopping counter: 38 out of 50\n",
      "epoch:  54\n",
      "epoch:  55 val_loss:  tensor(0.1941) val_f1:  0.8083670715249661 val_auroc:  0.9666666666666667 val_auprc:  0.9919117647058824\n",
      "EarlyStopping counter: 39 out of 50\n",
      "epoch:  55\n",
      "epoch:  56 val_loss:  tensor(0.1942) val_f1:  0.8083670715249661 val_auroc:  0.9666666666666667 val_auprc:  0.9919117647058824\n",
      "EarlyStopping counter: 40 out of 50\n",
      "epoch:  56\n",
      "epoch:  57 val_loss:  tensor(0.1943) val_f1:  0.8083670715249661 val_auroc:  0.9666666666666667 val_auprc:  0.9919117647058824\n",
      "EarlyStopping counter: 41 out of 50\n",
      "epoch:  57\n",
      "epoch:  58 val_loss:  tensor(0.1944) val_f1:  0.8083670715249661 val_auroc:  0.9666666666666667 val_auprc:  0.9919117647058824\n",
      "EarlyStopping counter: 42 out of 50\n",
      "epoch:  58\n",
      "epoch:  59 val_loss:  tensor(0.1945) val_f1:  0.8548644338118022 val_auroc:  0.9666666666666667 val_auprc:  0.9919117647058824\n",
      "EarlyStopping counter: 43 out of 50\n",
      "epoch:  59\n",
      "epoch:  60 val_loss:  tensor(0.1945) val_f1:  0.8548644338118022 val_auroc:  0.9666666666666667 val_auprc:  0.9919117647058824\n",
      "EarlyStopping counter: 44 out of 50\n",
      "epoch:  60\n",
      "epoch:  61 val_loss:  tensor(0.1946) val_f1:  0.9015037593984964 val_auroc:  0.9833333333333334 val_auprc:  0.9956944444444444\n",
      "EarlyStopping counter: 45 out of 50\n",
      "epoch:  61\n",
      "epoch:  62 val_loss:  tensor(0.1947) val_f1:  0.9015037593984964 val_auroc:  0.9833333333333334 val_auprc:  0.9956944444444444\n",
      "EarlyStopping counter: 46 out of 50\n",
      "epoch:  62\n",
      "epoch:  63 val_loss:  tensor(0.1948) val_f1:  0.9015037593984964 val_auroc:  0.9833333333333334 val_auprc:  0.9956944444444444\n",
      "EarlyStopping counter: 47 out of 50\n",
      "epoch:  63\n",
      "epoch:  64 val_loss:  tensor(0.1949) val_f1:  0.9015037593984964 val_auroc:  0.9833333333333334 val_auprc:  0.9956944444444444\n",
      "EarlyStopping counter: 48 out of 50\n",
      "epoch:  64\n",
      "epoch:  65 val_loss:  tensor(0.1951) val_f1:  0.9015037593984964 val_auroc:  0.9833333333333334 val_auprc:  0.9956944444444444\n",
      "EarlyStopping counter: 49 out of 50\n",
      "epoch:  65\n",
      "epoch:  66 val_loss:  tensor(0.1952) val_f1:  0.9015037593984964 val_auroc:  0.9833333333333334 val_auprc:  0.9956944444444444\n",
      "EarlyStopping counter: 50 out of 50\n",
      "Early stopping triggered\n",
      "Early stopping triggered!\n",
      "Time taken:  5.83185076713562\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(idx              2.000000\n",
       " time_elapsed    12.402620\n",
       " f1               0.811988\n",
       " auroc            0.813333\n",
       " auprc            0.953367\n",
       " dtype: float64,\n",
       " idx             1.581139\n",
       " time_elapsed    6.003646\n",
       " f1              0.109971\n",
       " auroc           0.156504\n",
       " auprc           0.039609\n",
       " dtype: float64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "result = {'idx':[], 'time_elapsed':[],'f1':[],'auroc':[],'auprc':[]}\n",
    "\n",
    "for idx, (train, test) in enumerate(skf.split(X, y)):\n",
    "    result['idx'] = result['idx'] + [idx]\n",
    "\n",
    "    train_sequences, train_labels = X[train], y[train]\n",
    "    test_sequences, test_labels = X[test], y[test]\n",
    "    \n",
    "    # Create dataset and dataloaders\n",
    "    train_dataset = ProteinSequenceDataset(train_sequences.reshape(train_sequences.shape[0],1,-1), train_labels)\n",
    "    test_dataset = ProteinSequenceDataset(test_sequences.reshape(test_sequences.shape[0],1,-1), test_labels)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=config['batch_size'], shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=config['batch_size'], shuffle=False)\n",
    "\n",
    "    # Calculate class weights\n",
    "    labels_tensor = torch.tensor(train_labels)\n",
    "    class_counts = torch.bincount(labels_tensor)\n",
    "    pos_weight = class_counts[0]/class_counts[1]\n",
    "    print(pos_weight)\n",
    "    \n",
    "    input_size = train_sequences.shape[1] #embedding size for esm2_t33_650M_UR50D (HLA)\n",
    "    model = TDPredictor(input_size, \n",
    "                         hidden_channels=config['hidden_channels'],\n",
    "                         dropout_p=config['dropout_p'],\n",
    "                         kernel_size = config['kernel_size'],\n",
    "                         pool_kernel_size = config['pool_kernel_size'])\n",
    "\n",
    "    # model training\n",
    "    start = time.time()\n",
    "    model.train_loop(train_loader=train_loader, \n",
    "                     valid_loader=test_loader, \n",
    "                     pos_weight=pos_weight,\n",
    "                     config_dict=config_dict)\n",
    "    end = time.time()\n",
    "\n",
    "    time_elapsed = end-start\n",
    "    print(\"Time taken: \", time_elapsed)\n",
    "\n",
    "    result['time_elapsed'] =  result['time_elapsed'] + [time_elapsed]\n",
    "    f1,auroc,auprc = model.eval_dataset(test_loader, return_label=False, )\n",
    "    \n",
    "    result['f1'] =  result['f1'] + [f1]\n",
    "    result['auroc'] =  result['auroc'] + [auroc]\n",
    "    result['auprc'] =  result['auprc'] + [auprc]\n",
    "    \n",
    "pd.DataFrame(result).mean(), pd.DataFrame(result).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bd5eea83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9533009015086221,\n",
       " 0.9089077923334405,\n",
       " 0.9898574561403508,\n",
       " 0.9190762719714926,\n",
       " 0.9956944444444444]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['auprc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdec5873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final dataset\n",
    "#### Create dataset and dataloaders\n",
    "train_dataset = ProteinSequenceDataset(X.reshape(X.shape[0],1,-1), y)\n",
    "train_loader = DataLoader(train_dataset, batch_size=config['batch_size'], shuffle=True)\n",
    "\n",
    "\n",
    "##### Calculate class weights\n",
    "labels_tensor = torch.tensor(y)\n",
    "class_counts = torch.bincount(labels_tensor)\n",
    "pos_weight = class_counts[0]/class_counts[1]\n",
    "print(pos_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8df25d4b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0\n",
      "epoch:  1\n",
      "epoch:  2\n",
      "epoch:  3\n",
      "epoch:  4\n",
      "epoch:  5\n",
      "epoch:  6\n",
      "epoch:  7\n",
      "epoch:  8\n",
      "epoch:  9\n",
      "epoch:  10\n",
      "epoch:  11\n",
      "epoch:  12\n",
      "epoch:  13\n",
      "epoch:  14\n",
      "epoch:  15\n",
      "epoch:  16\n",
      "epoch:  17\n",
      "epoch:  18\n",
      "epoch:  19\n",
      "epoch:  20\n",
      "epoch:  21\n",
      "epoch:  22\n",
      "epoch:  23\n",
      "epoch:  24\n",
      "epoch:  25\n",
      "epoch:  26\n",
      "epoch:  27\n",
      "epoch:  28\n",
      "epoch:  29\n",
      "epoch:  30\n",
      "epoch:  31\n",
      "epoch:  32\n",
      "epoch:  33\n",
      "epoch:  34\n",
      "epoch:  35\n",
      "epoch:  36\n",
      "epoch:  37\n",
      "epoch:  38\n",
      "epoch:  39\n",
      "epoch:  40\n",
      "epoch:  41\n",
      "epoch:  42\n",
      "epoch:  43\n",
      "epoch:  44\n",
      "epoch:  45\n",
      "epoch:  46\n",
      "epoch:  47\n",
      "epoch:  48\n",
      "epoch:  49\n",
      "epoch:  50\n",
      "epoch:  51\n",
      "epoch:  52\n",
      "epoch:  53\n",
      "epoch:  54\n",
      "epoch:  55\n",
      "epoch:  56\n",
      "epoch:  57\n",
      "epoch:  58\n",
      "epoch:  59\n",
      "epoch:  60\n",
      "epoch:  61\n",
      "epoch:  62\n",
      "epoch:  63\n",
      "epoch:  64\n",
      "epoch:  65\n",
      "epoch:  66\n",
      "epoch:  67\n",
      "epoch:  68\n",
      "epoch:  69\n",
      "epoch:  70\n",
      "epoch:  71\n",
      "epoch:  72\n",
      "epoch:  73\n",
      "epoch:  74\n",
      "epoch:  75\n",
      "epoch:  76\n",
      "epoch:  77\n",
      "epoch:  78\n",
      "epoch:  79\n",
      "epoch:  80\n",
      "epoch:  81\n",
      "epoch:  82\n",
      "epoch:  83\n",
      "epoch:  84\n",
      "epoch:  85\n",
      "epoch:  86\n",
      "epoch:  87\n",
      "epoch:  88\n",
      "epoch:  89\n",
      "epoch:  90\n",
      "epoch:  91\n",
      "epoch:  92\n",
      "epoch:  93\n",
      "epoch:  94\n",
      "epoch:  95\n",
      "epoch:  96\n",
      "epoch:  97\n",
      "epoch:  98\n",
      "epoch:  99\n",
      "epoch:  100\n",
      "epoch:  101\n",
      "epoch:  102\n",
      "epoch:  103\n",
      "epoch:  104\n",
      "epoch:  105\n",
      "epoch:  106\n",
      "epoch:  107\n",
      "epoch:  108\n",
      "epoch:  109\n",
      "epoch:  110\n",
      "epoch:  111\n",
      "epoch:  112\n",
      "epoch:  113\n",
      "epoch:  114\n",
      "epoch:  115\n",
      "epoch:  116\n",
      "epoch:  117\n",
      "epoch:  118\n",
      "epoch:  119\n",
      "epoch:  120\n",
      "epoch:  121\n",
      "epoch:  122\n",
      "epoch:  123\n",
      "epoch:  124\n",
      "epoch:  125\n",
      "epoch:  126\n",
      "epoch:  127\n",
      "epoch:  128\n",
      "epoch:  129\n",
      "epoch:  130\n",
      "epoch:  131\n",
      "epoch:  132\n",
      "epoch:  133\n",
      "epoch:  134\n",
      "epoch:  135\n",
      "epoch:  136\n",
      "epoch:  137\n",
      "epoch:  138\n",
      "epoch:  139\n",
      "epoch:  140\n",
      "epoch:  141\n",
      "epoch:  142\n",
      "epoch:  143\n",
      "epoch:  144\n",
      "epoch:  145\n",
      "epoch:  146\n",
      "epoch:  147\n",
      "epoch:  148\n",
      "epoch:  149\n",
      "epoch:  150\n",
      "epoch:  151\n",
      "epoch:  152\n",
      "epoch:  153\n",
      "epoch:  154\n",
      "epoch:  155\n",
      "epoch:  156\n",
      "epoch:  157\n",
      "epoch:  158\n",
      "epoch:  159\n",
      "epoch:  160\n",
      "epoch:  161\n",
      "epoch:  162\n",
      "epoch:  163\n",
      "epoch:  164\n",
      "epoch:  165\n",
      "epoch:  166\n",
      "epoch:  167\n",
      "epoch:  168\n",
      "epoch:  169\n",
      "epoch:  170\n",
      "epoch:  171\n",
      "epoch:  172\n",
      "epoch:  173\n",
      "epoch:  174\n",
      "epoch:  175\n",
      "epoch:  176\n",
      "epoch:  177\n",
      "epoch:  178\n",
      "epoch:  179\n",
      "epoch:  180\n",
      "epoch:  181\n",
      "epoch:  182\n",
      "epoch:  183\n",
      "epoch:  184\n",
      "epoch:  185\n",
      "epoch:  186\n",
      "epoch:  187\n",
      "epoch:  188\n",
      "epoch:  189\n",
      "epoch:  190\n",
      "epoch:  191\n",
      "epoch:  192\n",
      "epoch:  193\n",
      "epoch:  194\n",
      "epoch:  195\n",
      "epoch:  196\n",
      "epoch:  197\n",
      "epoch:  198\n",
      "epoch:  199\n",
      "Time taken:  37.840795278549194\n"
     ]
    }
   ],
   "source": [
    "# #### model init\n",
    "# input_size = X.shape[1] #embedding size for esm2_t33_650M_UR50D (HLA)\n",
    "# model = TDPredictor(input_size, \n",
    "#                      hidden_channels=config['hidden_channels'],\n",
    "#                      dropout_p=config['dropout_p'],\n",
    "#                      kernel_size = config['kernel_size'],\n",
    "#                      pool_kernel_size = config['pool_kernel_size'])\n",
    "\n",
    "# model.early_stopping = False\n",
    "\n",
    "\n",
    "# # model training\n",
    "# start = time.time()\n",
    "# model.train_loop(train_loader=train_loader, \n",
    "#                  valid_loader=None, \n",
    "#                  pos_weight=pos_weight,\n",
    "#                  config_dict=config_dict)\n",
    "# end = time.time()\n",
    "\n",
    "# time_elapsed = end-start\n",
    "# print(\"Time taken: \", time_elapsed)\n",
    "\n",
    "# result = {'time_elapsed': [time_elapsed]}\n",
    "# result['random_seed'] = [seed] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ed7a276",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=================================================================\n",
       "Layer (type:depth-idx)                   Param #\n",
       "=================================================================\n",
       "TDPredictor                              --\n",
       "â”œâ”€Sequential: 1-1                        --\n",
       "â”‚    â””â”€Conv1d: 2-1                       1,792\n",
       "â”‚    â””â”€BatchNorm1d: 2-2                  256\n",
       "â”‚    â””â”€Tanh: 2-3                         --\n",
       "â”‚    â””â”€MaxPool1d: 2-4                    --\n",
       "â”‚    â””â”€Dropout: 2-5                      --\n",
       "â”‚    â””â”€Flatten: 2-6                      --\n",
       "â”‚    â””â”€Linear: 2-7                       12,417\n",
       "â”œâ”€BCEWithLogitsLoss: 1-2                 --\n",
       "=================================================================\n",
       "Total params: 14,465\n",
       "Trainable params: 14,465\n",
       "Non-trainable params: 0\n",
       "================================================================="
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d258d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model,'./results/final_model/TD.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b6b4a88e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7300]])\n",
      "tensor([[0.3594]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Model correctly classifies B4402 as tapasin dependent and B4405 as tapasin independent\n",
    "model = torch.load('./results/final_model/TD.pt')\n",
    "\n",
    "with torch.no_grad():\n",
    "    print(torch.sigmoid(model(torch.tensor(scaler.transform(embedding_dict['HLA-B*44:02']).reshape(1,1,-1),dtype=torch.float32))))\n",
    "    print(torch.sigmoid(model(torch.tensor(scaler.transform(embedding_dict['HLA-B*44:05']).reshape(1,1,-1),dtype=torch.float32))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18da3241",
   "metadata": {},
   "source": [
    "## RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fc0c69d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2222)\n",
      "tensor(0.2222)\n",
      "tensor(0.2381)\n",
      "tensor(0.2381)\n",
      "tensor(0.2188)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(idx      2.000000\n",
       " f1       0.789244\n",
       " auroc    0.718333\n",
       " auprc    0.902864\n",
       " dtype: float64,\n",
       " idx      1.581139\n",
       " f1       0.090280\n",
       " auroc    0.185700\n",
       " auprc    0.079007\n",
       " dtype: float64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "result = {'idx':[], 'f1':[],'auroc':[],'auprc':[]}\n",
    "\n",
    "for idx, (train, test) in enumerate(skf.split(X, y)):\n",
    "    result['idx'] = result['idx'] + [idx]\n",
    "    \n",
    "    X_train, y_train = X[train], y[train]\n",
    "    X_test, y_test = X[test], y[test]\n",
    "    \n",
    "    # Calculate class weights\n",
    "    labels_tensor = torch.tensor(y_train)\n",
    "    class_counts = torch.bincount(labels_tensor)\n",
    "    pos_weight = class_counts[0]/class_counts[1]\n",
    "    print(pos_weight)\n",
    "    \n",
    "    # Initialize and train the Random Forest regressor\n",
    "    RF = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=seed, class_weight={1:pos_weight})\n",
    "    RF.fit(X_train.squeeze(), y_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred = RF.predict(X_test.squeeze())\n",
    "    y_proba = RF.predict_proba(X_test.squeeze())\n",
    "\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "        \n",
    "    fpr, tpr, _ = roc_curve(y_test, y_proba[:,1])\n",
    "    auroc = auc(fpr, tpr)\n",
    "\n",
    "    precision, recall, _ = precision_recall_curve(y_test, y_proba[:,1])\n",
    "    auprc = auc(recall, precision)\n",
    "    \n",
    "    result['f1'] =  result['f1'] + [f1]\n",
    "    result['auroc'] =  result['auroc'] + [auroc]\n",
    "    result['auprc'] =  result['auprc'] + [auprc]\n",
    "    \n",
    "pd.DataFrame(result).mean(), pd.DataFrame(result).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a33c67f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.875, 0.5625, 0.9583333333333334, 0.5625, 0.6333333333333333],\n",
       " [0.971515415376677,\n",
       "  0.8106995742529315,\n",
       "  0.992172181372549,\n",
       "  0.8415002889267594,\n",
       "  0.8984314570305283])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['auroc'], result['auprc']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4359f8ae",
   "metadata": {},
   "source": [
    "# LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "85d0c8fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/exports/csce/eddie/inf/groups/ajitha_project/piyush/.conda/envs/MHCex38/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/exports/csce/eddie/inf/groups/ajitha_project/piyush/.conda/envs/MHCex38/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/exports/csce/eddie/inf/groups/ajitha_project/piyush/.conda/envs/MHCex38/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/exports/csce/eddie/inf/groups/ajitha_project/piyush/.conda/envs/MHCex38/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/exports/csce/eddie/inf/groups/ajitha_project/piyush/.conda/envs/MHCex38/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(idx      2.000000\n",
       " f1       0.819686\n",
       " auroc    0.765417\n",
       " auprc    0.918160\n",
       " dtype: float64,\n",
       " idx      1.581139\n",
       " f1       0.073169\n",
       " auroc    0.200193\n",
       " auprc    0.095834\n",
       " dtype: float64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "result = {'idx':[], 'f1':[],'auroc':[],'auprc':[]}\n",
    "\n",
    "for idx, (train, test) in enumerate(skf.split(X, y)):\n",
    "    result['idx'] = result['idx'] + [idx]\n",
    "    \n",
    "    X_train, y_train = X[train], y[train]\n",
    "    X_test, y_test = X[test], y[test]\n",
    "    \n",
    "    clf = LogisticRegression(random_state=42).fit(X_train.squeeze(), y_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred = clf.predict(X_test.squeeze())\n",
    "    y_proba = clf.predict_proba(X_test.squeeze())\n",
    "\n",
    "\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "        \n",
    "    fpr, tpr, _ = roc_curve(y_test, y_proba[:,1])\n",
    "    auroc = auc(fpr, tpr)\n",
    "\n",
    "    precision, recall, _ = precision_recall_curve(y_test, y_proba[:,1])\n",
    "    auprc = auc(recall, precision)\n",
    "    \n",
    "    result['f1'] =  result['f1'] + [f1]\n",
    "    result['auroc'] =  result['auroc'] + [auroc]\n",
    "    result['auprc'] =  result['auprc'] + [auprc]\n",
    "    \n",
    "pd.DataFrame(result).mean(), pd.DataFrame(result).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "10697914",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.9375,\n",
       "  0.71875,\n",
       "  0.9791666666666667,\n",
       "  0.7083333333333334,\n",
       "  0.48333333333333334],\n",
       " [0.9852685866013071,\n",
       "  0.9225698654200976,\n",
       "  0.9962086397058824,\n",
       "  0.9297994897259603,\n",
       "  0.7569555553379084])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['auroc'], result['auprc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f65bd6de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(idx      2.000000\n",
       " f1       0.806487\n",
       " auroc    0.761250\n",
       " auprc    0.933329\n",
       " dtype: float64,\n",
       " idx      1.581139\n",
       " f1       0.063196\n",
       " auroc    0.164778\n",
       " auprc    0.056385\n",
       " dtype: float64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "result = {'idx':[], 'f1':[],'auroc':[],'auprc':[]}\n",
    "\n",
    "for idx, (train, test) in enumerate(skf.split(X, y)):\n",
    "    result['idx'] = result['idx'] + [idx]\n",
    "    \n",
    "    X_train, y_train = X[train], y[train]\n",
    "    X_test, y_test = X[test], y[test]\n",
    "    \n",
    "    # , 'poly', 'rbf', 'sigmoid'\n",
    "    clf = svm.SVC(probability=True, degree=3, kernel='poly').fit(X_train.squeeze(), y_train)\n",
    "\n",
    "    # Make predictions on the test set\n",
    "    y_pred = clf.predict(X_test.squeeze())\n",
    "    y_proba = clf.predict_proba(X_test.squeeze())\n",
    "\n",
    "\n",
    "\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "        \n",
    "    fpr, tpr, _ = roc_curve(y_test, y_proba[:,1])\n",
    "    auroc = auc(fpr, tpr)\n",
    "\n",
    "    precision, recall, _ = precision_recall_curve(y_test, y_proba[:,1])\n",
    "    auprc = auc(recall, precision)\n",
    "    \n",
    "    result['f1'] =  result['f1'] + [f1]\n",
    "    result['auroc'] =  result['auroc'] + [auroc]\n",
    "    result['auprc'] =  result['auprc'] + [auprc]\n",
    "    \n",
    "pd.DataFrame(result).mean(), pd.DataFrame(result).std()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fb9d9f64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.875, 0.78125, 0.9583333333333334, 0.625, 0.5666666666666667],\n",
       " [0.9634443859857463,\n",
       "  0.950719322816846,\n",
       "  0.9928513071895425,\n",
       "  0.9132602997492703,\n",
       "  0.8463694747518277])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['auroc'], result['auprc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12cae97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
